{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from numpy.lib.function_base import vectorize\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import sparse\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from better_profanity import profanity\n",
    "import time\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading user  data \n",
    "USER_DATA = './resources/data/users.json'\n",
    "df_user = pd.read_json(USER_DATA, orient=\"index\")\n",
    "\n",
    "# loading training data .jsonl\n",
    "TRAINING_DATA = './resources/data/train.jsonl'\n",
    "VAL_DATA = './resources/data/val.jsonl'\n",
    "\n",
    "df_train, df_val = pd.read_json(TRAINING_DATA, lines=True), pd.read_json(VAL_DATA, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_identity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "\n",
    "class Transformer_get_length(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None): \n",
    "        '''X should have two columns. One is the document and ther other is the corresponding unigram vector'''\n",
    "        # Count the number if unigrams in a feature\n",
    "        unigram = X[\"unigram\"]\n",
    "        \n",
    "        length = unigram.sum(axis=1)\n",
    "        return length\n",
    "class Transformer_get_reference_to_opponent(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None): \n",
    "        # Count the number of times the opponent's username is mentioned \n",
    "        df = X[\"df\"]\n",
    "        \n",
    "        count = df.apply(lambda row: row[\"document\"].lower().count(row[\"opponent\"]),\n",
    "                         axis=1).values\n",
    "        \n",
    "        count = np.reshape(count, newshape=[-1, 1])\n",
    "        return count \n",
    "    \n",
    "class Transformer_get_swear_words(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.matrix = None\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "    #     perhaps get rid some of the swear words because they look like they are necessary words \n",
    "    #     for discussion such as arian, sodom \n",
    "        unigram = X['unigram']\n",
    "        unigram_vectorizer = X['unigram_vectorizer']\n",
    "        \n",
    "        if not self.matrix:\n",
    "            vector = list(map(lambda x: int(profanity.contains_profanity(x)), \n",
    "                                    unigram_vectorizer.get_feature_names()))\n",
    "            \n",
    "            self.matrix = np.reshape(vector, newshape=[-1, 1])\n",
    "\n",
    "        swear_pro = unigram @ self.matrix\n",
    "        return swear_pro\n",
    "\n",
    "class Transformer_get_personal_pronouns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.personal_pronouns = pd.Series(\n",
    "            [\"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\"])\n",
    "        self.matrix = None\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X, y=None):\n",
    "    #     ================== faster but less accurate ========================\n",
    "\n",
    "        document = X['df'].loc[:, 'document']\n",
    "\n",
    "        all_counts = []\n",
    "\n",
    "        for name in self.personal_pronouns:\n",
    "            count = np.array(list(map(lambda x: x.count(\" {} \".format(name)), document)))\n",
    "            count = np.reshape(count, newshape=[-1, 1])\n",
    "            all_counts.append(count)\n",
    "\n",
    "\n",
    "        personal_pronouns_feature = np.hstack(all_counts)\n",
    "        return personal_pronouns_feature\n",
    "\n",
    "    #     ================== more accurate but slower ========================\n",
    "        # personal_pronouns_vector = unigram_vectorizer.transform(personal_pronouns)\n",
    "        # matrix_person_pronouns = personal_pronouns_vector.T \n",
    "\n",
    "        # document_pro = document_side[:, 0]\n",
    "        # unigram_pro = vectorizer.transform(document_pro)\n",
    "        # personal_pronouns_feature_pro = unigram_pro @ matrix_person_pronouns\n",
    "        # I_count_pro = np.array(list(map(lambda x: x.count(\" I \"), document_pro)))\n",
    "        # I_count_pro = np.reshape(I_count_pro, newshape=[-1, 1])\n",
    "        # personal_pronouns_feature_pro = sparse.hstack([personal_pronouns_feature_pro, I_count_pro])\n",
    "\n",
    "        # document_con = document_side[:, 1]\n",
    "        # unigram_con = vectorizer.transform(document_con)\n",
    "        # personal_pronouns_feature_con = unigram_con @ matrix_person_pronouns\n",
    "        # I_count_con = np.array(list(map(lambda x: x.count(\" I \"), document_con)))\n",
    "        # I_count_con = np.reshape(I_count_con, newshape=[-1, 1])\n",
    "        # personal_pronouns_feature_con = sparse.hstack([personal_pronouns_feature_con, I_count_con])\n",
    "        \n",
    "class Transformer_get_ngrams(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X, side, y=None):\n",
    "        opponent = \"con_debater\" if side == \"Pro\" else \"pro_debater\"\n",
    "        document = X['document'] \n",
    "        df_train = X['df_train'] \n",
    "        unigram_vectorizer = X['unigram_vectorizer']\n",
    "        trigram_vectorizer = X['trigram_vectorizer']\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"document\": document,\n",
    "                \"opponent\": df_train.loc[:, opponent]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        feature = {\"df\": df, \n",
    "                    \"unigram\": unigram_vectorizer.transform(document),\n",
    "                    'trigram': trigram_vectorizer.transform(document),\n",
    "                    \"unigram_vectorizer\": unigram_vectorizer\n",
    "                    }\n",
    "        \n",
    "        return feature\n",
    "\n",
    "class Transformer_separate_document(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.unigram_vectorizer = None\n",
    "        self.trigram_vectorizer = None\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        if not self.unigram_vectorizer:\n",
    "            self.unigram_vectorizer = CountVectorizer()\n",
    "            self.unigram_vectorizer.fit(document)\n",
    "            \n",
    "        if not self.trigram_vectorizer:\n",
    "            self.trigram_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, \n",
    "                                                 min_df=0.2, stop_words='english', ngram_range=(1,3))\n",
    "            self.trigram_vectorizer.fit(document)\n",
    "            \n",
    "        return self \n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        document_side = get_text_by_side(df)\n",
    "        document = [side[0] + side[1] for side in document_side]\n",
    "        \n",
    "        return {\"Pro\": \n",
    "                        {\"df\": df,\n",
    "                        \"unigram\": self.unigram_vectorizer,\n",
    "                        \"trigram\": self.trigram_vectorizer,\n",
    "                        \"document\": document_side[:, d]},\n",
    "               \"Con\": \n",
    "                        {\"df\": df,\n",
    "                        \"unigram\": self.unigram_vectorizer,\n",
    "                        \"trigram\": self.trigram_vectorizer,\n",
    "                        \"document\": document_side[:, 1]}\n",
    "               }\n",
    "        \n",
    "        \n",
    "transformer_get_length = Transformer_get_length()\n",
    "transformer_identity = Transformer_identity()\n",
    "transformer_get_reference_to_opponent = Transformer_get_reference_to_opponent()\n",
    "transformer_get_swear_words = Transformer_get_swear_words()\n",
    "transformer_get_personal_pronouns = Transformer_get_personal_pronouns()\n",
    "transformer_separate_document = Transformer_separate_document()\n",
    "transformer_get_ngrams = Transformer_get_ngrams()\n",
    "\n",
    "linguistic_trans = FeatureUnion(\n",
    "    [\n",
    "        ('length', transformer_get_length),\n",
    "        ('reference_to_opponent', transformer_get_reference_to_opponent),\n",
    "        ('swear_words', transformer_get_swear_words),\n",
    "        ('personal_pronouns', transformer_get_personal_pronouns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "side_trans = Pipeline(\n",
    "    [\n",
    "        ('ngram', transformer_get_ngrams), \n",
    "        ('linguistic', linguistic_trans)\n",
    "    ]\n",
    ")\n",
    "\n",
    "both_trans = ColumnTransformer(\n",
    "    [\n",
    "        ('Pro', side_trans, 'Pro'),\n",
    "        ('Con', side_trans, 'Con')\n",
    "    ]\n",
    ")\n",
    "                \n",
    "big_trans = Pipeline(\n",
    "    [\n",
    "        ('separate_document', transformer_separate_document), \n",
    "        ('get_both_features', both_trans),\n",
    "        ('logistic_regression', sklearn.linear_model.LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# linguistic_feat = linguistic_trans.fit(input_pro).transform(input_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31,  8, 18, ...,  2,  0,  1],\n",
       "       [25, 20,  6, ...,  0,  5,  4],\n",
       "       [32, 22,  0, ...,  0,  2,  0],\n",
       "       ...,\n",
       "       [ 7, 14, 19, ...,  0,  1,  4],\n",
       "       [ 0,  5,  0, ...,  0,  0,  0],\n",
       "       [15, 15,  0, ...,  0,  2,  0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_side_trans.fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document    \\n  \\n  Thank you, Muted, for accepting this d...\n",
      "unigram       (10, 0)\\t1\\n  (14, 0)\\t1\\n  (21, 0)\\t1\\n  (2...\n",
      "opponent                                                Muted\n",
      "Name: 0, dtype: object\n",
      "id                      Atheism-is-more-probable-than-Theism./2/\n",
      "category                                                Religion\n",
      "title                      Atheism is more probable than Theism.\n",
      "rounds         [[{'side': 'Pro', 'text': '\n",
      "  \n",
      "  Thank you, Mu...\n",
      "date                                         2012-11-11 00:00:00\n",
      "pro_debater                                            Microsuck\n",
      "con_debater                                                Muted\n",
      "voters         [truthseeker613, emj32, RationalMadman, Magic8...\n",
      "winner                                                       Pro\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_pro = pd.DataFrame.from_dict({\"document\": document_pro, \n",
    "                                \"unigram\": unigram_vectorizer.transform(document_pro),\n",
    "                                \"opponent\": df_train[\"con_debater\"]})\n",
    "df_pro.loc[0,:][\"opponent\"]\n",
    "print(df_pro.loc[0, :])\n",
    "print(df_train.loc[0, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Transformer length (type Transformer_get_length) does not provide get_feature_names.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-dc63ddecb605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print([row.todense() for row in linguistic_feat])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinguistic_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m                 raise AttributeError(\"Transformer %s (type %s) does not \"\n\u001b[1;32m    932\u001b[0m                                      \u001b[0;34m\"provide get_feature_names.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                                      % (str(name), type(trans).__name__))\n\u001b[0m\u001b[1;32m    934\u001b[0m             feature_names.extend([name + \"__\" + f for f in\n\u001b[1;32m    935\u001b[0m                                   trans.get_feature_names()])\n",
      "\u001b[0;31mAttributeError\u001b[0m: Transformer length (type Transformer_get_length) does not provide get_feature_names."
     ]
    }
   ],
   "source": [
    "# print([row.todense() for row in linguistic_feat])\n",
    "print(linguistic_trans.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Length\n",
    "# (b) Reference to the opponent\n",
    "# (c) Politeness words\n",
    "# (d) Swear words\n",
    "# (e) Personal pronouns\n",
    "# (f) Modal verbs\n",
    "# (g) Misspellings\n",
    "# (h) Links to outside websites\n",
    "# (i) Numbers\n",
    "# (j) Exclamation points\n",
    "# (k) Questions\n",
    "\n",
    "def get_length(document_side, vectorizer): \n",
    "    # Count the number if unigrams in a feature\n",
    "    document_pro = document_side[:, 0]\n",
    "    length_pro = np.sum(vectorizer(document_pro), axis=1)\n",
    "    \n",
    "    document_con = document_side[:, 1]\n",
    "    length_con = np.sum(vectorizer(document_con), axis=1)\n",
    "    \n",
    "    return length_pro, length_con\n",
    "\n",
    "def get_reference_to_opponent(df, document_side, vectorizer): \n",
    "    # Count the number of times the opponent's username is mentioned \n",
    "    pro_count = []\n",
    "    con_count = []\n",
    "    document_pro = document_side[:, 0]\n",
    "    document_con = document_side[:, 1]\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        opponent_name = df.loc[i, \"con_debator\"]\n",
    "        pro_count.append(document_pro.lower().count(opponent_name))\n",
    "        \n",
    "        opponent_name = df.loc[i, \"pro_debator\"]\n",
    "        con_count.append(document_con.lower().count(opponent_name))\n",
    "        \n",
    "    return np.array(pro_count), np.array(con_count) \n",
    "\n",
    "def get_politeness_words(document_side, vectorizer):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_swear_words(document_side, vectorizer):\n",
    "#     perhaps get rid some of the swear words because they look like they are necessary words \n",
    "#     for discussion such as arian, sodom \n",
    "    unigram = vectorizer.get_feature_names() \n",
    "    vector_swear = list(map(lambda x: int(profanity.contains_profanity(x)), unigram))\n",
    "    matrix_swear = np.reshape(vector_swear, newshape=[-1, 1])\n",
    "\n",
    "    document_pro = document_side[:, 0]\n",
    "    unigram_pro = vectorizer.transform(document_pro)\n",
    "    swear_pro = unigram_pro @ matrix_swear\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    unigram_con = vectorizer.transform(document_con)\n",
    "    swear_con = unigram_con @ matrix_swear\n",
    "\n",
    "def get_personal_pronouns(document_side, vectorizer):\n",
    "#     ================== faster but less accurate ========================\n",
    "    personal_pronouns = pd.Series([\"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\"])\n",
    "\n",
    "    document_pro = document_side[:, 0]\n",
    "    document_con = document_side[:, 1]\n",
    "\n",
    "    all_counts_pro = []\n",
    "    all_counts_con = []\n",
    "\n",
    "    for name in personal_pronouns:\n",
    "        count_pro = np.array(list(map(lambda x: x.count(\" {} \".format(name)), document_pro)))\n",
    "        count_pro = np.reshape(count_pro, newshape=[-1, 1])\n",
    "        all_counts_pro.append(count_pro)\n",
    "\n",
    "        count_con = np.array(list(map(lambda x: x.count(\" {} \".format(name)), document_con)))\n",
    "        count_con = np.reshape(count_con, newshape=[-1, 1])\n",
    "        all_counts_con.append(count_con)\n",
    "\n",
    "    personal_pronouns_feature_pro = np.hstack(all_counts_pro)\n",
    "    personal_connouns_feature_con = np.hstack(all_counts_con)\n",
    "\n",
    "#     ================== more accurate but slower ========================\n",
    "    # personal_pronouns_vector = unigram_vectorizer.transform(personal_pronouns)\n",
    "    # matrix_person_pronouns = personal_pronouns_vector.T \n",
    "\n",
    "    # document_pro = document_side[:, 0]\n",
    "    # unigram_pro = vectorizer.transform(document_pro)\n",
    "    # personal_pronouns_feature_pro = unigram_pro @ matrix_person_pronouns\n",
    "    # I_count_pro = np.array(list(map(lambda x: x.count(\" I \"), document_pro)))\n",
    "    # I_count_pro = np.reshape(I_count_pro, newshape=[-1, 1])\n",
    "    # personal_pronouns_feature_pro = sparse.hstack([personal_pronouns_feature_pro, I_count_pro])\n",
    "\n",
    "    # document_con = document_side[:, 1]\n",
    "    # unigram_con = vectorizer.transform(document_con)\n",
    "    # personal_pronouns_feature_con = unigram_con @ matrix_person_pronouns\n",
    "    # I_count_con = np.array(list(map(lambda x: x.count(\" I \"), document_con)))\n",
    "    # I_count_con = np.reshape(I_count_con, newshape=[-1, 1])\n",
    "    # personal_pronouns_feature_con = sparse.hstack([personal_pronouns_feature_con, I_count_con])\n",
    "\n",
    "    return personal_pronouns_feature_pro, personal_pronouns_feature_con\n",
    "    \n",
    "        \n",
    "def get_questions(document_side, vectorizer):\n",
    "    \n",
    "    document_pro = document_side[:, 0]\n",
    "    question_count_pro = np.array(list(map(lambda x: x.count(\"?\"), document_pro)))\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    question_count_con = np.array(list(map(lambda x: x.count(\"?\"), document_con)))\n",
    "    \n",
    "    return question_count_pro, question_count_con\n",
    "    \n",
    "    \n",
    "def get_reference_website(document_side, vectorizer):\n",
    "    \n",
    "    document_pro = document_side[:, 0]\n",
    "    website_count_pro = np.array(list(map(lambda x: x.count(\"http\"), document_pro)))\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    website_count_con = np.array(list(map(lambda x: x.count(\"http\"), document_con)))\n",
    "    \n",
    "    return website_count_pro, website_count_con\n",
    "\n",
    "def get_exclamation(document_side, vectorizer):\n",
    "    \n",
    "    document_pro = document_side[:, 0]\n",
    "    exclamation_count_pro = np.array(list(map(lambda x: x.count(\"!\"), document_pro)))\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    exclamation_count_con = np.array(list(map(lambda x: x.count(\"!\"), document_con)))\n",
    "    \n",
    "    return exclamation_count_pro, exclamation_count_con\n",
    "\n",
    "def get_number(document_side, vectorizer):\n",
    "    \n",
    "    unigram = unigram_vectorizer.get_feature_names()\n",
    "    vector_number = list(map(lambda x: int(x[0].isnumeric()), unigram))\n",
    "    matrix_number = np.reshape(vector_number, newshape=[-1, 1])\n",
    "\n",
    "    document_pro = document_side[:, 0]\n",
    "    unigram_pro = vectorizer.transform(document_pro)\n",
    "    number_pro = unigram_pro @ matrix_number\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    unigram_con = vectorizer.transform(document_con)\n",
    "    number_con = unigram_con @ matrix_number\n",
    "    \n",
    "    return number_pro, number_con\n",
    "\n",
    "def get_modal_verb(document_side, vectorizer):\n",
    "    modal_verbs = set([\"can\", \"could\", \"may\", \"might\", \"shall\", \"should\", \"will\", \"would\", \"must\"])\n",
    "    \n",
    "    unigram = unigram_vectorizer.get_feature_names()\n",
    "    vector_modal_verb = list(map(lambda x: int(x in modal_verbs), unigram))\n",
    "    matrix_modal_verb = np.reshape(vector_modal_verb, newshape=[-1, 1])\n",
    "\n",
    "    document_pro = document_side[:, 0]\n",
    "    unigram_pro = vectorizer.transform(document_pro)\n",
    "    modal_verb_pro = unigram_pro @ matrix_modal_verb\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    unigram_con = vectorizer.transform(document_con)\n",
    "    modal_verb_con = unigram_con @ matrix_modal_verb\n",
    "    \n",
    "    return modal_verb_pro, modal_verb_con\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "spell.existing(\"I'm not sleapy and tehre is no place I'm giong to.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_modal_verb(document_side, unigram_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jsonl(path):\n",
    "\n",
    "    with open(path) as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    data_list = []\n",
    "    for json_str in json_list:\n",
    "        data_list.append(json.loads(json_str))\n",
    "\n",
    "    return pd.DataFrame(data_list)\n",
    "def get_texts(df):\n",
    "    '''\n",
    "    Return a list of statements in df without differentiating the side of the speaker\n",
    "    '''\n",
    "\n",
    "    texts = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round:\n",
    "                texts.append(speech['text'])\n",
    "\n",
    "    return texts\n",
    "\n",
    "def get_text_by_side(df): \n",
    "    '''\n",
    "    Return a list of documents where each document contains all text on one side in a \n",
    "    single debate\n",
    "    \n",
    "    text = [[Pro statement 1, Pro statement 2, ... Pro statement n],\n",
    "            [Con statement 1, Con statement 2, ... Con statement m]]\n",
    "            where n, m is the total number of statements from Pro and Con side across\n",
    "            all debates\n",
    "\n",
    "    size: [n x 2 x # statements in each debate]\n",
    "    '''\n",
    "\n",
    "    text = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        round_text = collections.defaultdict(list)\n",
    "\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round: \n",
    "                round_text[speech['side']].append(speech['text'])\n",
    "\n",
    "        \n",
    "        text.append([\"\".join(round_text['Pro']), \"\".join(round_text['Con'])])\n",
    "\n",
    "    return np.array(text)\n",
    "\n",
    "def get_ngram_feature(document_side, vectorizer): \n",
    "    '''\n",
    "    Return the ngram features associated with a single debate\n",
    "\n",
    "    For pro side, each document is defined as a string that contains all the statements \n",
    "    from the pro side in a single debate (across different subrounds). Con side is \n",
    "    similarly defined. \n",
    "\n",
    "    return [[Pro side n gram vector, Con side n gram vector for 1 debate],\n",
    "            [Pro side n gram vector, Con side n gram vector for 2 debate],\n",
    "            ...]\n",
    "\n",
    "            size: [n, 2 x ngram count]\n",
    "    \n",
    "    Pro side and con side n gram vector are concatenated.\n",
    "    '''\n",
    "\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "\n",
    "    pro_feature = vectorizer.transform(pro_document)\n",
    "    con_feature = vectorizer.transform(con_document)\n",
    "    return sparse.hstack([pro_feature, con_feature])   \n",
    "\n",
    "def get_debate_feature(df):\n",
    "    '''\n",
    "    Return the debate feature such as category, pro_debator user name, etc\n",
    "\n",
    "    feature: [n, # of features] \n",
    "    '''\n",
    "    feature_name = ['category']\n",
    "    feature = []\n",
    "\n",
    "    for name in feature_name: \n",
    "        # TODO: check for data type of the column. If non-numeric, then do this\n",
    "        # otherwise, use the numerical data\n",
    "        encoding, unique_feature_val = pd.factorize(df[name])\n",
    "        feature.append(encoding)\n",
    "\n",
    "    return np.reshape(np.array(feature), [-1, len(feature_name)])\n",
    "\n",
    "def get_connotation_feature(document_side, matrix_connotation, vectorizer):\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "    \n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    \n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    \n",
    "    return np.hstack([feature_pro, feature_con])\n",
    "\n",
    "def get_connotation_percentage_feature(document_side, matrix_connotation, vectorizer):\n",
    "    # create features where count of features are percentage points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    total_feature_count = np.reshape(np.sum(feature_pro, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_pro = np.divide(feature_pro, total_feature_count)\n",
    "    feature_pct_pro[np.isneginf(feature_pct_pro)]=0\n",
    "    feature_pct_pro[np.isnan(feature_pct_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 1]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    total_feature_count = np.reshape(np.sum(feature_con, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_con = np.divide(feature_con, total_feature_count)\n",
    "    feature_pct_con[np.isneginf(feature_pct_con)]=0\n",
    "    feature_pct_con[np.isnan(feature_pct_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_pct_pro, feature_pct_con])\n",
    "\n",
    "def get_connotation_ln_feature(document_side, matrix_connotation, vectorizer):\n",
    "    # create features where count of features are ln points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    feature_ln_pro = np.log(feature_pro)\n",
    "    feature_ln_pro[np.isneginf(feature_ln_pro)]=0\n",
    "    feature_ln_pro[np.isnan(feature_ln_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 0]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    feature_ln_con = np.log(feature_con)\n",
    "    feature_ln_con[np.isneginf(feature_ln_con)]=0\n",
    "    feature_ln_con[np.isnan(feature_ln_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_ln_pro, feature_ln_con])\n",
    "\n",
    "\n",
    "def get_vad_feature(document_side, matrix_vad, vectorizer):\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "    \n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    \n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    \n",
    "    return np.hstack([feature_pro, feature_con])\n",
    "\n",
    "def get_vad_percentage_feature(document_side, matrix_vad, vectorizer):\n",
    "    # create features where count of features are percentage points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    total_feature_count = np.reshape(np.sum(feature_pro, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_pro = np.divide(feature_pro, total_feature_count)\n",
    "    feature_pct_pro[np.isneginf(feature_pct_pro)]=0\n",
    "    feature_pct_pro[np.isnan(feature_pct_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 1]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    total_feature_count = np.reshape(np.sum(feature_con, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_con = np.divide(feature_con, total_feature_count)\n",
    "    feature_pct_con[np.isneginf(feature_pct_con)]=0\n",
    "    feature_pct_con[np.isnan(feature_pct_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_pct_pro, feature_pct_con])\n",
    "\n",
    "def get_vad_ln_feature(document_side, matrix_vad, vectorizer):\n",
    "    # create features where count of features are ln points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    feature_ln_pro = np.log(feature_pro)\n",
    "    feature_ln_pro[np.isneginf(feature_ln_pro)]=0\n",
    "    feature_ln_pro[np.isnan(feature_ln_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 0]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    feature_ln_con = np.log(feature_con)\n",
    "    feature_ln_con[np.isneginf(feature_ln_con)]=0\n",
    "    feature_ln_con[np.isnan(feature_ln_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_ln_pro, feature_ln_con])\n",
    "\n",
    "def get_winner(df): \n",
    "    '''\n",
    "    Cons gets mapped to 0 and pro gets mapped to 1\n",
    "    '''\n",
    "    return df.loc[:, \"winner\"].replace({\"Con\": 0, \"Pro\": 1})\n",
    "\n",
    "def get_all_feature_label(df, vectorizer):\n",
    "    '''\n",
    "    Return the training input and validation input that contains all features, \n",
    "    which are ngram features and debate features\n",
    "    '''\n",
    "    \n",
    "    # Getting two sets of features - ngram and debate related features\n",
    "    ngram_feature = get_ngram_feature(df, vectorizer)\n",
    "\n",
    "    # debate_feature = get_debate_feature(df)\n",
    "\n",
    "    # Combining two sets of features\n",
    "    # X = sparse.hstack([debate_feature, ngram_feature])\n",
    "    X = sparse.hstack([ngram_feature])\n",
    "\n",
    "    y = np.array(get_winner(df))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - lex feature, debate feature, n-gram feature\n",
    "This model should use\n",
    "1. word ngrams\n",
    "2. lexicon based features: implement lexicon based features for a lexicon of your choice\n",
    "   1. Connotation lexicon\n",
    "   2. NRC-VAD lexicon\n",
    "   3. How you extract features is part of the desgin decision that you need to make. One simple example for lexical features could be counting how many words in each debaters language appear in the corresponding lexicon. \n",
    "\n",
    "TODO: \n",
    "1. Read connotation - 1 file\n",
    "2. NRC features - 2 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xhe/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/ipykernel_launcher.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# 1. Read connotation - 1 file\n",
    "# 2. NRC features - 2 files \n",
    "CONNOTATION = \"./resources/lexica/connotation_lexicon_a.0.1.csv\"\n",
    "NRC_LEXICON_VAD = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/NRC-VAD-Lexicon.txt\"\n",
    "NRC_LEXICON_SORTED_VALENCE = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/v-scores.txt\"\n",
    "NRC_LEXICON_SORTED_AROUSAL = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/a-scores.txt\"\n",
    "NRC_LEXICON_SORTED_DOMINANCE = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/d-scores.txt\"\n",
    "\n",
    "df_connotation = pd.read_csv(CONNOTATION, sep=\",|_\", header=None)\n",
    "df_connotation.columns = [\"word\", \"pos\", \"connotation\"] # word, part of speech, connotation\n",
    "df_connotation = df_connotation.dropna() # There are five words in the connotation that are nan \n",
    "df_connotation = df_connotation.set_index(\"word\")\n",
    "df_connotation[\"pos\"] = df_connotation[\"pos\"].astype('category')\n",
    "df_connotation = df_connotation.drop(columns=[\"pos\"]) # drop the part of speech classification because we can't use it now \n",
    "df_connotation[\"connotation\"] = df_connotation[\"connotation\"].astype('category')\n",
    "df_connotation = pd.get_dummies(df_connotation)\n",
    "\n",
    "df_nrc_vad = pd.read_csv(NRC_LEXICON_VAD, sep=\"\t\", header=None)\n",
    "df_nrc_vad.columns = [\"word\", \"valence\", \"arousal\", \"dominance\"]\n",
    "df_nrc_vad = df_nrc_vad.dropna()\n",
    "df_nrc_vad = df_nrc_vad.set_index(\"word\")\n",
    "df_nrc_vad[\"valence\"] = df_nrc_vad[\"valence\"].astype('category')\n",
    "df_nrc_vad[\"arousal\"] = df_nrc_vad[\"arousal\"].astype('category')\n",
    "df_nrc_vad[\"dominance\"] = df_nrc_vad[\"dominance\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, min_df=0.2, ngram_range=(1, 3),\n",
       "                stop_words='english', sublinear_tf=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get features and labels for traininig and validation \n",
    "unigram_vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate the corpus for vectotrizer to fit on \n",
    "document_train_side = get_text_by_side(df_train)\n",
    "document_val_side = get_text_by_side(df_val)\n",
    "document_train = [side[0] + side[1] for side in document_train_side]\n",
    "document_val = [side[0] + side[1] for side in document_val_side]\n",
    "\n",
    "# The vectorizer trains all all the textual corpus regardless of the side \n",
    "# of the debate \n",
    "unigram_vectorizer.fit(document_train)\n",
    "\n",
    "# Get the feature vector of a sentence using ngram @ matrix_connotation\n",
    "# Creating the matrix \n",
    "word_connotation = df_connotation.index\n",
    "word_vector_connotation = unigram_vectorizer.transform(word_connotation)\n",
    "matrix_connotation = word_vector_connotation.T @ df_connotation\n",
    "matrix_connotation_no_neutral = word_vector_connotation.T @ df_connotation.drop(columns=[\"connotation_neutral\"])\n",
    "\n",
    "word_vad = df_nrc_vad.index\n",
    "word_vector_vad = unigram_vectorizer.transform(word_vad)\n",
    "matrix_vad = word_vector_vad.T @ df_nrc_vad\n",
    "# For words with mulitple part of speech, we are counting the total\n",
    "# sum across all part of speech of that word for each feature \n",
    "\n",
    "# Get label \n",
    "label_train = get_winner(df_train)\n",
    "label_val = get_winner(df_val)\n",
    "\n",
    "y_train = np.array(label_train)\n",
    "y_val = np.array(label_val)\n",
    "\n",
    "# Get more grams \n",
    "trigram_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0.2, stop_words='english', ngram_range=(1,3))\n",
    "trigram_vectorizer.fit(document_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== you can run experiments here ======================\n",
    "# Get all TRAINING features:\n",
    "# Get the documents on pro and con side so that we can forming feature \n",
    "# vector on both sides for training \n",
    "\n",
    "trigram_train = get_ngram_feature(document_side=document_train_side, vectorizer=trigram_vectorizer)\n",
    "# ============= using raw number counts of the feature ==========================\n",
    "# feature_connotation_train = get_connotation_feature(document_side=document_train_side,\n",
    "#                                                         matrix_connotation=matrix_connotation,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_vad_train = get_vad_feature(document_side=document_train_side,\n",
    "#                                                         matrix_vad=matrix_vad,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_train, \n",
    "#                     feature_vad_train])\n",
    "\n",
    "# ============= using percentage counts of the feature ==========================\n",
    "# feature_connotation_pct_train = get_connotation_percentage_feature(document_train_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_pct_train = get_vad_percentage_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "#                     feature_vad_pct_train])\n",
    "\n",
    "# ============= using log counts of the feature ==========================\n",
    "# feature_connotation_ln_train = get_connotation_ln_feature(document_train_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_ln_train = get_vad_ln_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_ln_train, \n",
    "#                     feature_vad_ln_train])\n",
    "\n",
    "# ============= using percentage counts of the feature without neutral connotation ==========================\n",
    "feature_connotation_pct_train = get_connotation_percentage_feature(document_train_side, matrix_connotation_no_neutral, unigram_vectorizer)\n",
    "feature_vad_pct_train = get_vad_percentage_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "                    feature_vad_pct_train])\n",
    "\n",
    "# Get all VALIDATION features:\n",
    "trigram_val = get_ngram_feature(document_side=document_val_side, vectorizer=trigram_vectorizer)\n",
    "# ============= using raw counts of of the feature ==========================\n",
    "# feature_connotation_val = get_connotation_feature(document_side=document_val_side,\n",
    "#                                                         matrix_connotation=matrix_connotation,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_vad_val = get_vad_feature(document_side=document_val_side,\n",
    "#                                                         matrix_vad=matrix_vad,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_val, \n",
    "#                     feature_vad_val])\n",
    "\n",
    "# ============= using percentage count of of the feature ==========================\n",
    "# feature_connotation_pct_val = get_connotation_percentage_feature(document_val_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_pct_val = get_vad_percentage_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "#                     feature_vad_pct_train])\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_pct_val, \n",
    "#                     feature_vad_pct_val])\n",
    "\n",
    "# ============= using log counts of the feature ==========================\n",
    "# feature_connotation_ln_val = get_connotation_ln_feature(document_val_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_ln_val = get_vad_ln_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_ln_val, \n",
    "#                     feature_vad_ln_val])\n",
    "\n",
    "# ============= using percentage counts of the feature without neutral connotation ==========================\n",
    "feature_connotation_pct_val = get_connotation_percentage_feature(document_val_side, matrix_connotation_no_neutral, unigram_vectorizer)\n",
    "feature_vad_pct_val = get_vad_percentage_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "\n",
    "feature_val = sparse.hstack([trigram_val, feature_connotation_pct_val, \n",
    "                    feature_vad_pct_val])\n",
    "\n",
    "# Create model\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(feature_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train, clf.predict(feature_train)))\n",
    "print(classification_report(y_val, clf.predict(feature_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Here is the model that only uses debate features and ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting texts from training and testing data\n",
    "label_train = get_winner(df_train)\n",
    "label_val = get_winner(df_val)\n",
    "\n",
    "# Generate the corpus \n",
    "document_train = get_text_by_side(df_train)\n",
    "document_val = get_text_by_side(df_val)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.9, min_df=0.1, stop_words='english', ngram_range=(1,3))\n",
    "vectorizer.fit(document_train)\n",
    "\n",
    "# Getting two sets of features - ngram and debate related features\n",
    "ngram_feature_train = get_ngram_feature(df_train, vectorizer)\n",
    "ngram_feature_val = get_ngram_feature(df_val, vectorizer)\n",
    "\n",
    "debate_feature_train = get_debate_feature(df_train)\n",
    "debate_feture_val = get_debate_feature(df_val)\n",
    "\n",
    "# Combining two sets of features\n",
    "X_train = sparse.hstack([debate_feature_train, ngram_feature_train])\n",
    "X_val = sparse.hstack([debate_feture_val, ngram_feature_val])\n",
    "\n",
    "y_train = np.array(label_train)\n",
    "y_val = np.array(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sanity check')\n",
    "print(df_train.shape[0], 'number of observations in the training set')\n",
    "print(X_train.shape, 'number of observation x the size of ngram vectors in the training set')\n",
    "print(y_train.shape, 'number of labels in the training set')\n",
    "print(df_val.shape[0], 'number of observations in the validation set')\n",
    "print(X_val.shape, 'number of observation x the size of ngram vectors in the validation set')\n",
    "print(y_val.shape, 'number of labels in the validation set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training the model\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(ngram_feature_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression training set report:\")\n",
    "print(classification_report(y_train, clf.predict(ngram_feature_train), target_names=['Pro', 'Con']))\n",
    "print(classification_report(y_val, clf.predict(ngram_feature_val), target_names=['Pro', 'Con']))\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the validation set\n",
    "y_predicted = clf.predict(X_val_religion)\n",
    "print(\"Logistic Regression testing set report:\")\n",
    "print(classification_report(y_val_religion, y_predicted, target_names=['Pro', 'Con']))\n",
    "\n",
    "print(\"Accuracy score: \",accuracy_score(y_val_religion, y_predicted))\n",
    "print(\"Balanced accuracy score: \",accuracy_score(y_val_religion, y_predicted))\n",
    "\n",
    "plot_confusion_matrix(clf, X_val, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning ngram models over max_df and min_df\n",
    "def search_max_df_min_df(df_train, df_val):\n",
    "    highest_acc, best_min_df, best_max_df = 0, -1, -1\n",
    "    report = {}\n",
    "    for min_df in np.arange(0, 1, 0.1):\n",
    "        for diff in np.arange(0.1, 1 - min_df, 0.1):\n",
    "            max_df = min_df + diff\n",
    "\n",
    "            vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=max_df, min_df=min_df, stop_words='english', ngram_range=(1,3))\n",
    "            document_train = get_text_by_side(df_train)\n",
    "            vectorizer.fit(document_train)\n",
    "            X_train, y_train = get_all_feature_label(df_train, vectorizer)\n",
    "            X_val, y_val = get_all_feature_label(df_val, vectorizer)\n",
    "\n",
    "            clf = sklearn.linear_model.LogisticRegression()\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"====================================\")\n",
    "\n",
    "            y_predicted = clf.predict(X_val)\n",
    "            print(\"Logistic Regression testing set report:\")\n",
    "            report[(min_df, max_df)] = classification_report(y_val, y_predicted, target_names=['Pro', 'Con'], output_dict=True)\n",
    "            acc = accuracy_score(y_val, y_predicted)\n",
    "\n",
    "            print(\"max_df: {}, min_df: {}, accuracy: {}\".format(max_df, min_df, acc))\n",
    "\n",
    "            if acc > highest_acc:\n",
    "                highest_acc, best_min_df, best_max_df = acc, min_df, max_df\n",
    "\n",
    "    print(\"************ best min_df, best max_df, acc\", best_min_df, best_max_df, highest_acc)\n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "max_acc, best_min_df, best_max_df = 0, -1, -1\n",
    "gram3_report = report\n",
    "\n",
    "for key, val in report.items():\n",
    "    print(\"====================\")\n",
    "    print(key)\n",
    "    print(val)\n",
    "\n",
    "# The best min df and the best max df are (0.2, 0.8) with validation accuracy of 0.76\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of achieving this is to create two n-gram models. One n-gram model outputs features\n",
    "for religious topics and another n-gram model outputs features for non-religious topics.\n",
    "By limiting the corpus within their topics, the Tf_idf scores may better reflect the \n",
    "proper weighting. For example, certain words that might only appear in winning relgious debates\n",
    "but also appear in all other losing debates may now have a significantly different score from \n",
    "words that appear in only losing religous debates but appear in all other winning debates. \n",
    "Previously, these two sets of words would have similar tf_idf score but are not helpful \n",
    "towards predicting winning debates because their prediciton power within relgious topic is\n",
    "diluted by the non-religous topics. By limiting the corpus scope, we can see that these \n",
    "words become helpful in both religous and non-relgious debates.\n",
    "\n",
    "TODO:\n",
    "1. Define a Tfidfvectorizer for both religous and non-religious topics\n",
    "2. Train the vectorizer using their respective subsets\n",
    "3. Depending the topic of the new data, we should use the two models conditionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data sets\n",
    "df_train_religion = df_train.loc[df_train.category == \"Religion\" ,:]\n",
    "df_train_other = df_train.loc[df_train.category != \"Religion\" ,:]\n",
    "df_val_religion = df_val.loc[df_val.category == \"Religion\" ,:]\n",
    "df_val_other = df_val.loc[df_val.category != \"Religion\" ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sanity check\")\n",
    "print(df_train_religious.shape)\n",
    "print(df_train_other.shape)\n",
    "print(df_train.shape)\n",
    "print(\"validation set\")\n",
    "print(df_val_religious.shape)\n",
    "print(df_val_other.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_religion.shape)\n",
    "print(X_val_religion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_max_df_min_df(df_train_religion, df_val_religion)\n",
    "search_max_df_min_df(df_train_other, df_val_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the vectorizer\n",
    "vectorizer_religion = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0, stop_words='english', ngram_range=(1,3))\n",
    "document_train_religion = get_text_by_side(df_train_religion)\n",
    "vectorizer_religion.fit(document_train_religion)\n",
    "X_train_religion, y_train_religion = get_all_feature_label(df_train_religion, vectorizer_religion)\n",
    "X_val_religion, y_val_religion = get_all_feature_label(df_val_religion, vectorizer_religion)\n",
    "report_religion = search_max_df_min_df(X_train_religion, y_train_religion, X_val_religion, y_val_religion)\n",
    "\n",
    "vectorizer_other = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0, stop_words='english', ngram_range=(1,3))\n",
    "document_train_other = get_text_by_side(df_train_other)\n",
    "vectorizer_other.fit(document_train_other)\n",
    "X_train_other, y_train_other = get_all_feature_label(df_train_other, vectorizer_other)\n",
    "X_val_other, y_val_other = get_all_feature_label(df_val_other, vectorizer_other)\n",
    "report_other = search_max_df_min_df(X_train_other, y_train_other, X_val_other, y_val_other)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f78e94ca1a29e9011c2866c841de859bf08fcc5b57f07b9ffb161018ea406f8e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
