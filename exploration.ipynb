{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#%% \n",
    "import collections\n",
    "from numpy.lib.function_base import vectorize\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import sparse\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# load example data\n",
    "data_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "# this is just a list of strings\n",
    "data_test = fetch_20newsgroups(subset='test', shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# %%\n",
    "def get_jsonl(path):\n",
    "\n",
    "    with open(path) as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    data_list = []\n",
    "    for json_str in json_list:\n",
    "        data_list.append(json.loads(json_str))\n",
    "\n",
    "    return pd.DataFrame(data_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# %%\n",
    "# loading user  data \n",
    "USER_DATA = './resources/data/users.json'\n",
    "df_user = pd.read_json(USER_DATA, orient=\"index\")\n",
    "\n",
    "# loading training data .jsonl\n",
    "TRAINING_DATA = './resources/data/train.jsonl'\n",
    "VAL_DATA = './resources/data/val.jsonl'\n",
    "\n",
    "df_train, df_val = get_jsonl(TRAINING_DATA), get_jsonl(VAL_DATA)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_train.shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1592"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "s = set()\n",
    "for v in df_train['voters']:\n",
    "    s = s.union(v)\n",
    "print(len(s))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2927\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# %%\n",
    "print(df_train.columns)\n",
    "# df_train\n",
    "# %%\n",
    "# Explore the structure of rounds\n",
    "one_round = df_train.loc[0, \"rounds\"] # this is a list of list of dictionary\n",
    "two_sides = one_round[1] # this is a list consists of two sides speaking\n",
    "\n",
    "# import json\n",
    "# json.dumps(one_round, indent=4)\n",
    "\n",
    "# one_round\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['id', 'category', 'title', 'rounds', 'date', 'pro_debater',\n",
      "       'con_debater', 'voters', 'winner'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def get_texts(df):\n",
    "    '''\n",
    "    Return a list of statements in df without differentiating the side of the speaker\n",
    "    '''\n",
    "\n",
    "    texts = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round:\n",
    "                texts.append(speech['text'])\n",
    "\n",
    "    return texts\n",
    "\n",
    "def get_text_by_side(df): \n",
    "    '''\n",
    "    Return a list of documents where each document contains all text on one side in a \n",
    "    single debate\n",
    "    \n",
    "    text = [[Pro statement 1, Pro statement 2, ... Pro statement n],\n",
    "            [Con statement 1, Con statement 2, ... Con statement m]]\n",
    "            where n, m is the total number of statements from Pro and Con side across\n",
    "            all debates\n",
    "\n",
    "    size: [n x 2 x # statements in each debate]\n",
    "    '''\n",
    "\n",
    "    text = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        round_text = collections.defaultdict(list)\n",
    "\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round: \n",
    "                round_text[speech['side']].append(speech['text'])\n",
    "\n",
    "        for speech in round_text.values():\n",
    "            text.append(\"\".join(speech))\n",
    "\n",
    "    return text\n",
    "\n",
    "def get_ngram_feature(df, vectorizer: TfidfVectorizer): \n",
    "    '''\n",
    "    Return the ngram features associated with a single debate\n",
    "\n",
    "    For pro side, each document is defined as a string that contains all the statements \n",
    "    from the pro side in a single debate (across different subrounds). Con side is \n",
    "    similarly defined. \n",
    "\n",
    "    return [[Pro side n gram vector, Con side n gram vector for 1 debate],\n",
    "            [Pro side n gram vector, Con side n gram vector for 2 debate],\n",
    "            ...]\n",
    "\n",
    "            size: [n, 2 x ngram count]\n",
    "    \n",
    "    Pro side and con side n gram vector are concatenated.\n",
    "    '''\n",
    "\n",
    "    pro_text, con_text = [], []\n",
    "\n",
    "    for round in df.loc[:, 'rounds']: \n",
    "        round_text_list = collections.defaultdict(list)\n",
    "        round_feature = []\n",
    "\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round: \n",
    "                round_text_list[speech['side']].append(speech['text'])\n",
    "\n",
    "        round_text = {}\n",
    "        for side, speech in round_text_list.items():\n",
    "            one_side_text = \"\".join(speech)\n",
    "            round_text[side] = one_side_text\n",
    "            \n",
    "        pro_text.append(round_text['Pro'])\n",
    "        con_text.append(round_text['Con'])\n",
    "\n",
    "    pro_feature = vectorizer.transform(pro_text)\n",
    "    con_feature = vectorizer.transform(con_text)\n",
    "    print(\"pro , con shape are\", pro_feature.shape, con_feature.shape)\n",
    "    return sparse.hstack([pro_feature, con_feature])   \n",
    "\n",
    "def get_debate_feature(df):\n",
    "    '''\n",
    "    Return the debate feature such as category, pro_debator user name, etc\n",
    "\n",
    "    feature: [n, # of features] \n",
    "    '''\n",
    "    feature_name = ['category']\n",
    "    feature = []\n",
    "\n",
    "    for name in feature_name: \n",
    "        # TODO: check for data type of the column. If non-numeric, then do this\n",
    "        # otherwise, use the numerical data\n",
    "        encoding, unique_feature_val = pd.factorize(df[name])\n",
    "        feature.append(encoding)\n",
    "\n",
    "    return np.reshape(np.array(feature), [-1, len(feature_name)])\n",
    "\n",
    "def get_winner(df): \n",
    "    '''\n",
    "    Cons gets mapped to 0 and pro gets mapped to 1\n",
    "    '''\n",
    "    return df.loc[:, \"winner\"].replace({\"Con\": 0, \"Pro\": 1})\n",
    "\n",
    "def get_all_feature_label(df, vectorizer):\n",
    "    '''\n",
    "    Return the training input and validation input that contains all features, \n",
    "    which are ngram features and debate features\n",
    "    '''\n",
    "    \n",
    "    # Getting two sets of features - ngram and debate related features\n",
    "    ngram_feature = get_ngram_feature(df, vectorizer)\n",
    "\n",
    "    # debate_feature = get_debate_feature(df)\n",
    "\n",
    "    # Combining two sets of features\n",
    "    # X = sparse.hstack([debate_feature, ngram_feature])\n",
    "    X = sparse.hstack([ngram_feature])\n",
    "\n",
    "    y = np.array(get_winner(df))\n",
    "\n",
    "    return X, y\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 2 - lex feature, debate feature, n-gram feature\n",
    "This model should use\n",
    "1. word ngrams\n",
    "2. lexicon based features: implement lexicon based features for a lexicon of your choice\n",
    "   1. Connotation lexicon\n",
    "   2. NRC-VAD lexicon\n",
    "   3. How you extract features is part of the desgin decision that you need to make. One simple example for lexical features could be counting how many words in each debaters language appear in the corresponding lexicon. \n",
    "\n",
    "TODO: \n",
    "1. Collect the connotation score documents by documents  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# 1. Read connotation - 1 file\n",
    "# 2. NRC features - 2 files \n",
    "CONNOTATION = \"./resources/lexica/connotation_lexicon_a.0.1.csv\"\n",
    "NRC_LEXICON_VAD = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/NRC-VAD-Lexicon.txt\"\n",
    "NRC_LEXICON_SORTED_VALENCE = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/v-scores.txt\"\n",
    "NRC_LEXICON_SORTED_AROUSAL = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/a-scores.txt\"\n",
    "NRC_LEXICON_SORTED_DOMINANCE = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/d-scores.txt\"\n",
    "\n",
    "df_connotation = pd.read_csv(CONNOTATION, sep=\",|_\", header=None)\n",
    "df_connotation.columns = [\"word\", \"pos\", \"connotation\"] # word, part of speech, connotation\n",
    "df_connotation = df_connotation.dropna()\n",
    "df_connotation = df_connotation.set_index(\"word\")\n",
    "df_nrc_vad = pd.read_csv(NRC_LEXICON_VAD, sep=\"\t\", header=None)\n",
    "df_nrc_vad.columns = [\"word\", \"valence\", \"arousal\", \"dominance\"]\n",
    "df_nrc_vad = df_nrc_vad.set_index(\"word\")\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/xhe/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/ipykernel_launcher.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Extracting texts from training and testing data\n",
    "label_train = get_winner(df_train)\n",
    "label_val = get_winner(df_val)\n",
    "\n",
    "# Generate the corpus \n",
    "document_train = get_text_by_side(df_train)\n",
    "document_test = get_text_by_side(df_val)\n",
    "\n",
    "# Get the feature scores\n",
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_train = unigram_vectorizer.fit_transform(document_train)\n",
    "print(unigram_train.shape)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3185, 57063)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Construct the connotation matrix where each column list the valence / a / d for each word\n",
    "connotation_matrix = np.zeros(shape=[unigram_train.shape[1], 2])\n",
    "# print(df_connotation.iloc[, :])\n",
    "connotation_words = df_connotation.index\n",
    "unigram_vectorizer.transform(connotation_words)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<93869x57063 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 41660 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 1 - Here is the model that only uses debate features and ngram features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# Extracting texts from training and testing data\n",
    "label_train = get_winner(df_train)\n",
    "label_val = get_winner(df_val)\n",
    "\n",
    "# Generate the corpus \n",
    "document_train = get_text_by_side(df_train)\n",
    "document_test = get_text_by_side(df_val)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.9, min_df=0.1, stop_words='english', ngram_range=(1,3))\n",
    "vectorizer.fit(document_train)\n",
    "\n",
    "# Getting two sets of features - ngram and debate related features\n",
    "ngram_feature_train = get_ngram_feature(df_train, vectorizer)\n",
    "ngram_feature_val = get_ngram_feature(df_val, vectorizer)\n",
    "\n",
    "debate_feature_train = get_debate_feature(df_train)\n",
    "debate_feture_val = get_debate_feature(df_val)\n",
    "\n",
    "# Combining two sets of features\n",
    "X_train = sparse.hstack([debate_feature_train, ngram_feature_train])\n",
    "X_val = sparse.hstack([debate_feture_val, ngram_feature_val])\n",
    "\n",
    "y_train = np.array(label_train)\n",
    "y_val = np.array(label_val)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pro , con shape are (1592, 606) (1592, 606)\n",
      "pro , con shape are (399, 606) (399, 606)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "print('Sanity check')\n",
    "print(df_train.shape[0], 'number of observations in the training set')\n",
    "print(X_train.shape, 'number of observation x the size of ngram vectors in the training set')\n",
    "print(y_train.shape, 'number of labels in the training set')\n",
    "print(df_val.shape[0], 'number of observations in the validation set')\n",
    "print(X_val.shape, 'number of observation x the size of ngram vectors in the validation set')\n",
    "print(y_val.shape, 'number of labels in the validation set')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sanity check\n",
      "1592 number of observations in the training set\n",
      "(1592, 1213) number of observation x the size of ngram vectors in the training set\n",
      "(1592,) number of labels in the training set\n",
      "399 number of observations in the validation set\n",
      "(399, 1213) number of observation x the size of ngram vectors in the validation set\n",
      "(399,) number of labels in the validation set\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# Building and training the model\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(ngram_feature_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression training set report:\")\n",
    "print(classification_report(y_train, clf.predict(ngram_feature_train), target_names=['Pro', 'Con']))\n",
    "print(classification_report(y_val, clf.predict(ngram_feature_val), target_names=['Pro', 'Con']))\n",
    "\n",
    "# %%"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic Regression training set report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.88      0.94      0.91       916\n",
      "         Con       0.91      0.83      0.87       676\n",
      "\n",
      "    accuracy                           0.89      1592\n",
      "   macro avg       0.90      0.88      0.89      1592\n",
      "weighted avg       0.89      0.89      0.89      1592\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.86      0.78       211\n",
      "         Con       0.80      0.62      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "X_val"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<399x1213 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 96112 stored elements in COOrdinate format>"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# Evaluating the model on the validation set\n",
    "y_predicted = clf.predict(X_val_religion)\n",
    "print(\"Logistic Regression testing set report:\")\n",
    "print(classification_report(y_val_religion, y_predicted, target_names=['Pro', 'Con']))\n",
    "\n",
    "print(\"Accuracy score: \",accuracy_score(y_val_religion, y_predicted))\n",
    "print(\"Balanced accuracy score: \",accuracy_score(y_val_religion, y_predicted))\n",
    "\n",
    "plot_confusion_matrix(clf, X_val, y_predicted)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "X has 1682716 features per sample; expecting 1213",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-aa2b8b9a62ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluating the model on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Logistic Regression testing set report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Con'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 289\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1682716 features per sample; expecting 1213"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# Tuning ngram models over max_df and min_df\n",
    "def search_max_df_min_df(df_train, df_val):\n",
    "    highest_acc, best_min_df, best_max_df = 0, -1, -1\n",
    "    report = {}\n",
    "    for min_df in np.arange(0, 1, 0.1):\n",
    "        for diff in np.arange(0.1, 1 - min_df, 0.1):\n",
    "            max_df = min_df + diff\n",
    "\n",
    "            vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=max_df, min_df=min_df, stop_words='english', ngram_range=(1,3))\n",
    "            document_train = get_text_by_side(df_train)\n",
    "            vectorizer.fit(document_train)\n",
    "            X_train, y_train = get_all_feature_label(df_train, vectorizer)\n",
    "            X_val, y_val = get_all_feature_label(df_val, vectorizer)\n",
    "\n",
    "            clf = sklearn.linear_model.LogisticRegression()\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"====================================\")\n",
    "\n",
    "            y_predicted = clf.predict(X_val)\n",
    "            print(\"Logistic Regression testing set report:\")\n",
    "            report[(min_df, max_df)] = classification_report(y_val, y_predicted, target_names=['Pro', 'Con'], output_dict=True)\n",
    "            acc = accuracy_score(y_val, y_predicted)\n",
    "\n",
    "            print(\"max_df: {}, min_df: {}, accuracy: {}\".format(max_df, min_df, acc))\n",
    "\n",
    "            if acc > highest_acc:\n",
    "                highest_acc, best_min_df, best_max_df = acc, min_df, max_df\n",
    "\n",
    "    print(\"************ best min_df, best max_df, acc\", best_min_df, best_max_df, highest_acc)\n",
    "    return report\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "max_acc, best_min_df, best_max_df = 0, -1, -1\n",
    "gram3_report = report\n",
    "\n",
    "for key, val in report.items():\n",
    "    print(\"====================\")\n",
    "    print(key)\n",
    "    print(val)\n",
    "\n",
    "# The best min df and the best max df are (0.2, 0.8) with validation accuracy of 0.76\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====================\n",
      "(0.0, 0.1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.54      1.00      0.70       211\n",
      "         Con       1.00      0.06      0.11       188\n",
      "\n",
      "    accuracy                           0.56       399\n",
      "   macro avg       0.77      0.53      0.41       399\n",
      "weighted avg       0.76      0.56      0.42       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.57      1.00      0.72       211\n",
      "         Con       1.00      0.14      0.25       188\n",
      "\n",
      "    accuracy                           0.60       399\n",
      "   macro avg       0.78      0.57      0.49       399\n",
      "weighted avg       0.77      0.60      0.50       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.30000000000000004)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.57      1.00      0.73       211\n",
      "         Con       1.00      0.15      0.26       188\n",
      "\n",
      "    accuracy                           0.60       399\n",
      "   macro avg       0.78      0.57      0.49       399\n",
      "weighted avg       0.77      0.60      0.51       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.57      1.00      0.73       211\n",
      "         Con       1.00      0.17      0.29       188\n",
      "\n",
      "    accuracy                           0.61       399\n",
      "   macro avg       0.79      0.59      0.51       399\n",
      "weighted avg       0.78      0.61      0.52       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.58      1.00      0.73       211\n",
      "         Con       1.00      0.18      0.31       188\n",
      "\n",
      "    accuracy                           0.61       399\n",
      "   macro avg       0.79      0.59      0.52       399\n",
      "weighted avg       0.78      0.61      0.53       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.58      1.00      0.74       211\n",
      "         Con       1.00      0.20      0.34       188\n",
      "\n",
      "    accuracy                           0.62       399\n",
      "   macro avg       0.79      0.60      0.54       399\n",
      "weighted avg       0.78      0.62      0.55       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.7000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.59      1.00      0.74       211\n",
      "         Con       1.00      0.21      0.34       188\n",
      "\n",
      "    accuracy                           0.63       399\n",
      "   macro avg       0.79      0.60      0.54       399\n",
      "weighted avg       0.78      0.63      0.55       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.59      1.00      0.74       211\n",
      "         Con       1.00      0.21      0.35       188\n",
      "\n",
      "    accuracy                           0.63       399\n",
      "   macro avg       0.79      0.61      0.55       399\n",
      "weighted avg       0.78      0.63      0.56       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.59      1.00      0.74       211\n",
      "         Con       1.00      0.21      0.35       188\n",
      "\n",
      "    accuracy                           0.63       399\n",
      "   macro avg       0.79      0.61      0.55       399\n",
      "weighted avg       0.78      0.63      0.56       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.88      0.78       211\n",
      "         Con       0.82      0.59      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.74      0.73       399\n",
      "weighted avg       0.76      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.30000000000000004)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.83      0.58      0.68       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.70      0.90      0.79       211\n",
      "         Con       0.84      0.57      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.77      0.73      0.73       399\n",
      "weighted avg       0.76      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.69      0.90      0.78       211\n",
      "         Con       0.83      0.56      0.67       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.73      0.72       399\n",
      "weighted avg       0.76      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.83      0.58      0.68       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.7)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.84      0.59      0.69       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.77      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.89      0.79       211\n",
      "         Con       0.82      0.59      0.69       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.83      0.59      0.69       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.77      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.30000000000000004)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.86      0.78       211\n",
      "         Con       0.80      0.61      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.75      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.70      0.87      0.78       211\n",
      "         Con       0.80      0.59      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.70      0.88      0.78       211\n",
      "         Con       0.81      0.57      0.67       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.6000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.88      0.79       211\n",
      "         Con       0.82      0.61      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.75      0.75       399\n",
      "weighted avg       0.77      0.75      0.75       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.7)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.89      0.79       211\n",
      "         Con       0.82      0.59      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.74      0.73       399\n",
      "weighted avg       0.76      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.90      0.80       211\n",
      "         Con       0.84      0.60      0.70       188\n",
      "\n",
      "    accuracy                           0.76       399\n",
      "   macro avg       0.78      0.75      0.75       399\n",
      "weighted avg       0.77      0.76      0.75       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.9000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.84      0.60      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.75      0.74       399\n",
      "weighted avg       0.77      0.75      0.75       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.68      0.84      0.75       211\n",
      "         Con       0.76      0.56      0.65       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.72      0.70      0.70       399\n",
      "weighted avg       0.72      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.69      0.85      0.76       211\n",
      "         Con       0.77      0.58      0.66       188\n",
      "\n",
      "    accuracy                           0.72       399\n",
      "   macro avg       0.73      0.71      0.71       399\n",
      "weighted avg       0.73      0.72      0.72       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.6000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.88      0.79       211\n",
      "         Con       0.82      0.60      0.69       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.7000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.87      0.78       211\n",
      "         Con       0.81      0.60      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.76      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.85      0.77       211\n",
      "         Con       0.78      0.61      0.68       188\n",
      "\n",
      "    accuracy                           0.73       399\n",
      "   macro avg       0.74      0.73      0.73       399\n",
      "weighted avg       0.74      0.73      0.73       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.87      0.79       211\n",
      "         Con       0.81      0.62      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.75       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.69      0.82      0.75       211\n",
      "         Con       0.74      0.59      0.65       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.72      0.70      0.70       399\n",
      "weighted avg       0.71      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.6000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.86      0.78       211\n",
      "         Con       0.80      0.62      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.7000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.85      0.77       211\n",
      "         Con       0.78      0.61      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.74      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.85      0.77       211\n",
      "         Con       0.79      0.61      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.86      0.78       211\n",
      "         Con       0.80      0.60      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.5, 0.6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.84      0.77       211\n",
      "         Con       0.78      0.62      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.74      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.5, 0.7)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.70      0.86      0.77       211\n",
      "         Con       0.79      0.60      0.68       188\n",
      "\n",
      "    accuracy                           0.73       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.74      0.73      0.73       399\n",
      "\n",
      "====================\n",
      "(0.5, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.85      0.77       211\n",
      "         Con       0.78      0.60      0.68       188\n",
      "\n",
      "    accuracy                           0.73       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.74      0.73      0.73       399\n",
      "\n",
      "====================\n",
      "(0.5, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.86      0.78       211\n",
      "         Con       0.79      0.61      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.6000000000000001, 0.7000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.67      0.85      0.75       211\n",
      "         Con       0.76      0.53      0.62       188\n",
      "\n",
      "    accuracy                           0.70       399\n",
      "   macro avg       0.72      0.69      0.69       399\n",
      "weighted avg       0.71      0.70      0.69       399\n",
      "\n",
      "====================\n",
      "(0.6000000000000001, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.67      0.88      0.76       211\n",
      "         Con       0.79      0.52      0.62       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.73      0.70      0.69       399\n",
      "weighted avg       0.73      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.6000000000000001, 0.9000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.67      0.88      0.76       211\n",
      "         Con       0.79      0.51      0.62       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.73      0.70      0.69       399\n",
      "weighted avg       0.73      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.7000000000000001, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.67      0.92      0.77       211\n",
      "         Con       0.84      0.48      0.61       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.75      0.70      0.69       399\n",
      "weighted avg       0.75      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.7000000000000001, 0.9000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.66      0.91      0.77       211\n",
      "         Con       0.83      0.48      0.61       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.75      0.70      0.69       399\n",
      "weighted avg       0.74      0.71      0.69       399\n",
      "\n",
      "====================\n",
      "(0.8, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.61      0.91      0.73       211\n",
      "         Con       0.77      0.34      0.47       188\n",
      "\n",
      "    accuracy                           0.64       399\n",
      "   macro avg       0.69      0.62      0.60       399\n",
      "weighted avg       0.68      0.64      0.60       399\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One way of achieving this is to create two n-gram models. One n-gram model outputs features\n",
    "for religious topics and another n-gram model outputs features for non-religious topics.\n",
    "By limiting the corpus within their topics, the Tf_idf scores may better reflect the \n",
    "proper weighting. For example, certain words that might only appear in winning relgious debates\n",
    "but also appear in all other losing debates may now have a significantly different score from \n",
    "words that appear in only losing religous debates but appear in all other winning debates. \n",
    "Previously, these two sets of words would have similar tf_idf score but are not helpful \n",
    "towards predicting winning debates because their prediciton power within relgious topic is\n",
    "diluted by the non-religous topics. By limiting the corpus scope, we can see that these \n",
    "words become helpful in both religous and non-relgious debates.\n",
    "\n",
    "TODO:\n",
    "1. Define a Tfidfvectorizer for both religous and non-religious topics\n",
    "2. Train the vectorizer using their respective subsets\n",
    "3. Depending the topic of the new data, we should use the two models conditionally"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# Partition the data sets\n",
    "df_train_religion = df_train.loc[df_train.category == \"Religion\" ,:]\n",
    "df_train_other = df_train.loc[df_train.category != \"Religion\" ,:]\n",
    "df_val_religion = df_val.loc[df_val.category == \"Religion\" ,:]\n",
    "df_val_other = df_val.loc[df_val.category != \"Religion\" ,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "print(\"Sanity check\")\n",
    "print(df_train_religious.shape)\n",
    "print(df_train_other.shape)\n",
    "print(df_train.shape)\n",
    "print(\"validation set\")\n",
    "print(df_val_religious.shape)\n",
    "print(df_val_other.shape)\n",
    "print(df_val.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sanity check\n",
      "(370, 9)\n",
      "(1222, 9)\n",
      "(1592, 9)\n",
      "validation set\n",
      "(93, 9)\n",
      "(306, 9)\n",
      "(399, 9)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "print(X_train_religion.shape)\n",
    "print(X_val_religion.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(370, 607)\n",
      "(93, 607)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "search_max_df_min_df(df_train_religion, df_val_religion)\n",
    "search_max_df_min_df(df_train_other, df_val_other)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pro , con shape are (370, 840554) (370, 840554)\n",
      "pro , con shape are (93, 840554) (93, 840554)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.1, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841057) (370, 841057)\n",
      "pro , con shape are (93, 841057) (93, 841057)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841222) (370, 841222)\n",
      "pro , con shape are (93, 841222) (93, 841222)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841289) (370, 841289)\n",
      "pro , con shape are (93, 841289) (93, 841289)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841325) (370, 841325)\n",
      "pro , con shape are (93, 841325) (93, 841325)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841343) (370, 841343)\n",
      "pro , con shape are (93, 841343) (93, 841343)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841354) (370, 841354)\n",
      "pro , con shape are (93, 841354) (93, 841354)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841358) (370, 841358)\n",
      "pro , con shape are (93, 841358) (93, 841358)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841359) (370, 841359)\n",
      "pro , con shape are (93, 841359) (93, 841359)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 518) (370, 518)\n",
      "pro , con shape are (93, 518) (93, 518)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.1, accuracy: 0.5698924731182796\n",
      "pro , con shape are (370, 683) (370, 683)\n",
      "pro , con shape are (93, 683) (93, 683)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.1, accuracy: 0.5806451612903226\n",
      "pro , con shape are (370, 750) (370, 750)\n",
      "pro , con shape are (93, 750) (93, 750)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.1, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 786) (370, 786)\n",
      "pro , con shape are (93, 786) (93, 786)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.1, accuracy: 0.6236559139784946\n",
      "pro , con shape are (370, 804) (370, 804)\n",
      "pro , con shape are (93, 804) (93, 804)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.1, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 815) (370, 815)\n",
      "pro , con shape are (93, 815) (93, 815)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.1, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 819) (370, 819)\n",
      "pro , con shape are (93, 819) (93, 819)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.1, accuracy: 0.6344086021505376\n",
      "pro , con shape are (370, 820) (370, 820)\n",
      "pro , con shape are (93, 820) (93, 820)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.1, accuracy: 0.6451612903225806\n",
      "pro , con shape are (370, 167) (370, 167)\n",
      "pro , con shape are (93, 167) (93, 167)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.2, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 234) (370, 234)\n",
      "pro , con shape are (93, 234) (93, 234)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.2, accuracy: 0.6559139784946236\n",
      "pro , con shape are (370, 270) (370, 270)\n",
      "pro , con shape are (93, 270) (93, 270)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.2, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 288) (370, 288)\n",
      "pro , con shape are (93, 288) (93, 288)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.2, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 299) (370, 299)\n",
      "pro , con shape are (93, 299) (93, 299)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.2, accuracy: 0.6774193548387096\n",
      "pro , con shape are (370, 303) (370, 303)\n",
      "pro , con shape are (93, 303) (93, 303)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.2, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 304) (370, 304)\n",
      "pro , con shape are (93, 304) (93, 304)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.2, accuracy: 0.6559139784946236\n",
      "pro , con shape are (370, 67) (370, 67)\n",
      "pro , con shape are (93, 67) (93, 67)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.30000000000000004, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 103) (370, 103)\n",
      "pro , con shape are (93, 103) (93, 103)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.30000000000000004, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 121) (370, 121)\n",
      "pro , con shape are (93, 121) (93, 121)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.30000000000000004, accuracy: 0.5806451612903226\n",
      "pro , con shape are (370, 132) (370, 132)\n",
      "pro , con shape are (93, 132) (93, 132)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.30000000000000004, accuracy: 0.6236559139784946\n",
      "pro , con shape are (370, 136) (370, 136)\n",
      "pro , con shape are (93, 136) (93, 136)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.30000000000000004, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 137) (370, 137)\n",
      "pro , con shape are (93, 137) (93, 137)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.30000000000000004, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 36) (370, 36)\n",
      "pro , con shape are (93, 36) (93, 36)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.4, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 54) (370, 54)\n",
      "pro , con shape are (93, 54) (93, 54)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.4, accuracy: 0.6451612903225806\n",
      "pro , con shape are (370, 65) (370, 65)\n",
      "pro , con shape are (93, 65) (93, 65)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.4, accuracy: 0.6559139784946236\n",
      "pro , con shape are (370, 69) (370, 69)\n",
      "pro , con shape are (93, 69) (93, 69)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.4, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 70) (370, 70)\n",
      "pro , con shape are (93, 70) (93, 70)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.4, accuracy: 0.6559139784946236\n",
      "pro , con shape are (370, 18) (370, 18)\n",
      "pro , con shape are (93, 18) (93, 18)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.5, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 29) (370, 29)\n",
      "pro , con shape are (93, 29) (93, 29)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.5, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 33) (370, 33)\n",
      "pro , con shape are (93, 33) (93, 33)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.5, accuracy: 0.6989247311827957\n",
      "pro , con shape are (370, 34) (370, 34)\n",
      "pro , con shape are (93, 34) (93, 34)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.5, accuracy: 0.6881720430107527\n",
      "pro , con shape are (370, 11) (370, 11)\n",
      "pro , con shape are (93, 11) (93, 11)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.6000000000000001, accuracy: 0.5913978494623656\n",
      "pro , con shape are (370, 15) (370, 15)\n",
      "pro , con shape are (93, 15) (93, 15)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.6000000000000001, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 16) (370, 16)\n",
      "pro , con shape are (93, 16) (93, 16)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.6000000000000001, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 4) (370, 4)\n",
      "pro , con shape are (93, 4) (93, 4)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.7000000000000001, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 5) (370, 5)\n",
      "pro , con shape are (93, 5) (93, 5)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.7000000000000001, accuracy: 0.5806451612903226\n",
      "pro , con shape are (370, 1) (370, 1)\n",
      "pro , con shape are (93, 1) (93, 1)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.8, accuracy: 0.5053763440860215\n",
      "************ best min_df, best max_df, acc 0.5 0.8 0.6989247311827957\n",
      "pro , con shape are (1222, 2228111) (1222, 2228111)\n",
      "pro , con shape are (306, 2228111) (306, 2228111)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.1, min_df: 0.0, accuracy: 0.5882352941176471\n",
      "pro , con shape are (1222, 2228508) (1222, 2228508)\n",
      "pro , con shape are (306, 2228508) (306, 2228508)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.0, accuracy: 0.6111111111111112\n",
      "pro , con shape are (1222, 2228606) (1222, 2228606)\n",
      "pro , con shape are (306, 2228606) (306, 2228606)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.0, accuracy: 0.6274509803921569\n",
      "pro , con shape are (1222, 2228645) (1222, 2228645)\n",
      "pro , con shape are (306, 2228645) (306, 2228645)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.0, accuracy: 0.6339869281045751\n",
      "pro , con shape are (1222, 2228662) (1222, 2228662)\n",
      "pro , con shape are (306, 2228662) (306, 2228662)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.0, accuracy: 0.6535947712418301\n",
      "pro , con shape are (1222, 2228672) (1222, 2228672)\n",
      "pro , con shape are (306, 2228672) (306, 2228672)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.0, accuracy: 0.6633986928104575\n",
      "pro , con shape are (1222, 2228676) (1222, 2228676)\n",
      "pro , con shape are (306, 2228676) (306, 2228676)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.0, accuracy: 0.6633986928104575\n",
      "pro , con shape are (1222, 2228677) (1222, 2228677)\n",
      "pro , con shape are (306, 2228677) (306, 2228677)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.0, accuracy: 0.6633986928104575\n",
      "pro , con shape are (1222, 2228677) (1222, 2228677)\n",
      "pro , con shape are (306, 2228677) (306, 2228677)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.0, accuracy: 0.6633986928104575\n",
      "pro , con shape are (1222, 397) (1222, 397)\n",
      "pro , con shape are (306, 397) (306, 397)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.1, accuracy: 0.7156862745098039\n",
      "pro , con shape are (1222, 495) (1222, 495)\n",
      "pro , con shape are (306, 495) (306, 495)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.1, accuracy: 0.7320261437908496\n",
      "pro , con shape are (1222, 534) (1222, 534)\n",
      "pro , con shape are (306, 534) (306, 534)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.1, accuracy: 0.7189542483660131\n",
      "pro , con shape are (1222, 551) (1222, 551)\n",
      "pro , con shape are (306, 551) (306, 551)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.1, accuracy: 0.7189542483660131\n",
      "pro , con shape are (1222, 561) (1222, 561)\n",
      "pro , con shape are (306, 561) (306, 561)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.1, accuracy: 0.7549019607843137\n",
      "pro , con shape are (1222, 565) (1222, 565)\n",
      "pro , con shape are (306, 565) (306, 565)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.1, accuracy: 0.7418300653594772\n",
      "pro , con shape are (1222, 566) (1222, 566)\n",
      "pro , con shape are (306, 566) (306, 566)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.1, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 566) (1222, 566)\n",
      "pro , con shape are (306, 566) (306, 566)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.1, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 99) (1222, 99)\n",
      "pro , con shape are (306, 99) (306, 99)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.2, accuracy: 0.7320261437908496\n",
      "pro , con shape are (1222, 138) (1222, 138)\n",
      "pro , con shape are (306, 138) (306, 138)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.2, accuracy: 0.738562091503268\n",
      "pro , con shape are (1222, 155) (1222, 155)\n",
      "pro , con shape are (306, 155) (306, 155)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.2, accuracy: 0.7418300653594772\n",
      "pro , con shape are (1222, 165) (1222, 165)\n",
      "pro , con shape are (306, 165) (306, 165)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.2, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 169) (1222, 169)\n",
      "pro , con shape are (306, 169) (306, 169)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.2, accuracy: 0.7418300653594772\n",
      "pro , con shape are (1222, 170) (1222, 170)\n",
      "pro , con shape are (306, 170) (306, 170)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.2, accuracy: 0.7516339869281046\n",
      "pro , con shape are (1222, 170) (1222, 170)\n",
      "pro , con shape are (306, 170) (306, 170)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.2, accuracy: 0.7516339869281046\n",
      "pro , con shape are (1222, 39) (1222, 39)\n",
      "pro , con shape are (306, 39) (306, 39)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.30000000000000004, accuracy: 0.7222222222222222\n",
      "pro , con shape are (1222, 56) (1222, 56)\n",
      "pro , con shape are (306, 56) (306, 56)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.30000000000000004, accuracy: 0.738562091503268\n",
      "pro , con shape are (1222, 66) (1222, 66)\n",
      "pro , con shape are (306, 66) (306, 66)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.30000000000000004, accuracy: 0.7647058823529411\n",
      "pro , con shape are (1222, 70) (1222, 70)\n",
      "pro , con shape are (306, 70) (306, 70)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.30000000000000004, accuracy: 0.7549019607843137\n",
      "pro , con shape are (1222, 71) (1222, 71)\n",
      "pro , con shape are (306, 71) (306, 71)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.30000000000000004, accuracy: 0.761437908496732\n",
      "pro , con shape are (1222, 71) (1222, 71)\n",
      "pro , con shape are (306, 71) (306, 71)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.30000000000000004, accuracy: 0.761437908496732\n",
      "pro , con shape are (1222, 17) (1222, 17)\n",
      "pro , con shape are (306, 17) (306, 17)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.4, accuracy: 0.6830065359477124\n",
      "pro , con shape are (1222, 27) (1222, 27)\n",
      "pro , con shape are (306, 27) (306, 27)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.4, accuracy: 0.7418300653594772\n",
      "pro , con shape are (1222, 31) (1222, 31)\n",
      "pro , con shape are (306, 31) (306, 31)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.4, accuracy: 0.7352941176470589\n",
      "pro , con shape are (1222, 32) (1222, 32)\n",
      "pro , con shape are (306, 32) (306, 32)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.4, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 32) (1222, 32)\n",
      "pro , con shape are (306, 32) (306, 32)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.4, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 10) (1222, 10)\n",
      "pro , con shape are (306, 10) (306, 10)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.5, accuracy: 0.7352941176470589\n",
      "pro , con shape are (1222, 14) (1222, 14)\n",
      "pro , con shape are (306, 14) (306, 14)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.5, accuracy: 0.7320261437908496\n",
      "pro , con shape are (1222, 15) (1222, 15)\n",
      "pro , con shape are (306, 15) (306, 15)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.5, accuracy: 0.7222222222222222\n",
      "pro , con shape are (1222, 15) (1222, 15)\n",
      "pro , con shape are (306, 15) (306, 15)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.5, accuracy: 0.7222222222222222\n",
      "pro , con shape are (1222, 4) (1222, 4)\n",
      "pro , con shape are (306, 4) (306, 4)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.6000000000000001, accuracy: 0.6339869281045751\n",
      "pro , con shape are (1222, 5) (1222, 5)\n",
      "pro , con shape are (306, 5) (306, 5)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.6000000000000001, accuracy: 0.6764705882352942\n",
      "pro , con shape are (1222, 5) (1222, 5)\n",
      "pro , con shape are (306, 5) (306, 5)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.6000000000000001, accuracy: 0.6764705882352942\n",
      "pro , con shape are (1222, 1) (1222, 1)\n",
      "pro , con shape are (306, 1) (306, 1)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.7000000000000001, accuracy: 0.6535947712418301\n",
      "pro , con shape are (1222, 1) (1222, 1)\n",
      "pro , con shape are (306, 1) (306, 1)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.7000000000000001, accuracy: 0.6535947712418301\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-e5171e942c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msearch_max_df_min_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msearch_max_df_min_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_other\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val_other\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-bbafb6186b24>\u001b[0m in \u001b[0;36msearch_max_df_min_df\u001b[0;34m(df_train, df_val)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mdocument_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_by_side\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_feature_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_feature_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m   1225\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[1;32m   1093\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "# Set up the vectorizer\n",
    "vectorizer_religion = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0, stop_words='english', ngram_range=(1,3))\n",
    "document_train_religion = get_text_by_side(df_train_religion)\n",
    "vectorizer_religion.fit(document_train_religion)\n",
    "X_train_religion, y_train_religion = get_all_feature_label(df_train_religion, vectorizer_religion)\n",
    "X_val_religion, y_val_religion = get_all_feature_label(df_val_religion, vectorizer_religion)\n",
    "report_religion = search_max_df_min_df(X_train_religion, y_train_religion, X_val_religion, y_val_religion)\n",
    "\n",
    "vectorizer_other = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0, stop_words='english', ngram_range=(1,3))\n",
    "document_train_other = get_text_by_side(df_train_other)\n",
    "vectorizer_other.fit(document_train_other)\n",
    "X_train_other, y_train_other = get_all_feature_label(df_train_other, vectorizer_other)\n",
    "X_val_other, y_val_other = get_all_feature_label(df_val_other, vectorizer_other)\n",
    "report_other = search_max_df_min_df(X_train_other, y_train_other, X_val_other, y_val_other)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pro , con shape are (370, 841358) (370, 841358)\n",
      "pro , con shape are (93, 841358) (93, 841358)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.1, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.5, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.5, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.5, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.5, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.6000000000000001, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.6000000000000001, accuracy: 0.4946236559139785\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-c06ef8e9c814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_religion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_feature_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_val_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_religion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_feature_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mreport_religion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_max_df_min_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvectorizer_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-84f2027f84e5>\u001b[0m in \u001b[0;36msearch_max_df_min_df\u001b[0;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1414\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1416\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             )\n\u001b[1;32m    763\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 618\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mupdate_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFD_METHODS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('env_nlp': conda)"
  },
  "interpreter": {
   "hash": "f78e94ca1a29e9011c2866c841de859bf08fcc5b57f07b9ffb161018ea406f8e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}