{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from numpy.lib.function_base import vectorize\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import sparse\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from better_profanity import profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading user  data \n",
    "USER_DATA = './resources/data/users.json'\n",
    "df_user = pd.read_json(USER_DATA, orient=\"index\")\n",
    "\n",
    "# loading training data .jsonl\n",
    "TRAINING_DATA = './resources/data/train.jsonl'\n",
    "VAL_DATA = './resources/data/val.jsonl'\n",
    "\n",
    "df_train, df_val = pd.read_json(TRAINING_DATA, lines=True), pd.read_json(VAL_DATA, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(document_side, vectorizer): \n",
    "    # Count the number if unigrams in a feature\n",
    "    document_pro = document_side[:, 0]\n",
    "    length_pro = np.sum(vectorizer(document_pro))\n",
    "    \n",
    "    document_con = document_side[:, 1]\n",
    "    length_con = np.sum(vectorizer(document_con))\n",
    "    \n",
    "    return length_pro, length_con\n",
    "\n",
    "def get_reference_to_opponent(df, document_side, vectorizer): \n",
    "    # Count the number of times the opponent's username is mentioned \n",
    "    pro_count = []\n",
    "    con_count = []\n",
    "    document_pro = document_side[:, 0]\n",
    "    document_con = document_side[:, 1]\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        opponent_name = df.loc[i, \"con_debator\"]\n",
    "        pro_count.append(document_pro.count(opponent_name))\n",
    "        \n",
    "        opponent_name = df.loc[i, \"pro_debator\"]\n",
    "        con_count.append(document_con.count(opponent_name))\n",
    "        \n",
    "    return pro_count, con_count\n",
    "\n",
    "def get_politeness_words(document_side, vectorizer):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_swear_words(document_side, vectorizer):\n",
    "    document_pro = document_side[:, 0]\n",
    "    document_con = document_side[:, 1]\n",
    "    \n",
    "    return sum(map(profanity.contains_profanity, document_pro)),\n",
    "            sum(map(profanity.contains_profanity, document_con))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jsonl(path):\n",
    "\n",
    "    with open(path) as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    data_list = []\n",
    "    for json_str in json_list:\n",
    "        data_list.append(json.loads(json_str))\n",
    "\n",
    "    return pd.DataFrame(data_list)\n",
    "def get_texts(df):\n",
    "    '''\n",
    "    Return a list of statements in df without differentiating the side of the speaker\n",
    "    '''\n",
    "\n",
    "    texts = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round:\n",
    "                texts.append(speech['text'])\n",
    "\n",
    "    return texts\n",
    "\n",
    "def get_text_by_side(df): \n",
    "    '''\n",
    "    Return a list of documents where each document contains all text on one side in a \n",
    "    single debate\n",
    "    \n",
    "    text = [[Pro statement 1, Pro statement 2, ... Pro statement n],\n",
    "            [Con statement 1, Con statement 2, ... Con statement m]]\n",
    "            where n, m is the total number of statements from Pro and Con side across\n",
    "            all debates\n",
    "\n",
    "    size: [n x 2 x # statements in each debate]\n",
    "    '''\n",
    "\n",
    "    text = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        round_text = collections.defaultdict(list)\n",
    "\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round: \n",
    "                round_text[speech['side']].append(speech['text'])\n",
    "\n",
    "        \n",
    "        text.append([\"\".join(round_text['Pro']), \"\".join(round_text['Con'])])\n",
    "\n",
    "    return np.array(text)\n",
    "\n",
    "def get_ngram_feature(document_side, vectorizer): \n",
    "    '''\n",
    "    Return the ngram features associated with a single debate\n",
    "\n",
    "    For pro side, each document is defined as a string that contains all the statements \n",
    "    from the pro side in a single debate (across different subrounds). Con side is \n",
    "    similarly defined. \n",
    "\n",
    "    return [[Pro side n gram vector, Con side n gram vector for 1 debate],\n",
    "            [Pro side n gram vector, Con side n gram vector for 2 debate],\n",
    "            ...]\n",
    "\n",
    "            size: [n, 2 x ngram count]\n",
    "    \n",
    "    Pro side and con side n gram vector are concatenated.\n",
    "    '''\n",
    "\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "\n",
    "    pro_feature = vectorizer.transform(pro_document)\n",
    "    con_feature = vectorizer.transform(con_document)\n",
    "    return sparse.hstack([pro_feature, con_feature])   \n",
    "\n",
    "def get_debate_feature(df):\n",
    "    '''\n",
    "    Return the debate feature such as category, pro_debator user name, etc\n",
    "\n",
    "    feature: [n, # of features] \n",
    "    '''\n",
    "    feature_name = ['category']\n",
    "    feature = []\n",
    "\n",
    "    for name in feature_name: \n",
    "        # TODO: check for data type of the column. If non-numeric, then do this\n",
    "        # otherwise, use the numerical data\n",
    "        encoding, unique_feature_val = pd.factorize(df[name])\n",
    "        feature.append(encoding)\n",
    "\n",
    "    return np.reshape(np.array(feature), [-1, len(feature_name)])\n",
    "\n",
    "def get_connotation_feature(document_side, matrix_connotation, vectorizer):\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "    \n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    \n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    \n",
    "    return np.hstack([feature_pro, feature_con])\n",
    "\n",
    "def get_connotation_percentage_feature(document_side, matrix_connotation, vectorizer):\n",
    "    # create features where count of features are percentage points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    total_feature_count = np.reshape(np.sum(feature_pro, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_pro = np.divide(feature_pro, total_feature_count)\n",
    "    feature_pct_pro[np.isneginf(feature_pct_pro)]=0\n",
    "    feature_pct_pro[np.isnan(feature_pct_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 1]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    total_feature_count = np.reshape(np.sum(feature_con, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_con = np.divide(feature_con, total_feature_count)\n",
    "    feature_pct_con[np.isneginf(feature_pct_con)]=0\n",
    "    feature_pct_con[np.isnan(feature_pct_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_pct_pro, feature_pct_con])\n",
    "\n",
    "def get_connotation_ln_feature(document_side, matrix_connotation, vectorizer):\n",
    "    # create features where count of features are ln points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    feature_ln_pro = np.log(feature_pro)\n",
    "    feature_ln_pro[np.isneginf(feature_ln_pro)]=0\n",
    "    feature_ln_pro[np.isnan(feature_ln_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 0]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    feature_ln_con = np.log(feature_con)\n",
    "    feature_ln_con[np.isneginf(feature_ln_con)]=0\n",
    "    feature_ln_con[np.isnan(feature_ln_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_ln_pro, feature_ln_con])\n",
    "\n",
    "\n",
    "def get_vad_feature(document_side, matrix_vad, vectorizer):\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "    \n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    \n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    \n",
    "    return np.hstack([feature_pro, feature_con])\n",
    "\n",
    "def get_vad_percentage_feature(document_side, matrix_vad, vectorizer):\n",
    "    # create features where count of features are percentage points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    total_feature_count = np.reshape(np.sum(feature_pro, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_pro = np.divide(feature_pro, total_feature_count)\n",
    "    feature_pct_pro[np.isneginf(feature_pct_pro)]=0\n",
    "    feature_pct_pro[np.isnan(feature_pct_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 1]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    total_feature_count = np.reshape(np.sum(feature_con, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_con = np.divide(feature_con, total_feature_count)\n",
    "    feature_pct_con[np.isneginf(feature_pct_con)]=0\n",
    "    feature_pct_con[np.isnan(feature_pct_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_pct_pro, feature_pct_con])\n",
    "\n",
    "def get_vad_ln_feature(document_side, matrix_vad, vectorizer):\n",
    "    # create features where count of features are ln points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    feature_ln_pro = np.log(feature_pro)\n",
    "    feature_ln_pro[np.isneginf(feature_ln_pro)]=0\n",
    "    feature_ln_pro[np.isnan(feature_ln_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 0]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    feature_ln_con = np.log(feature_con)\n",
    "    feature_ln_con[np.isneginf(feature_ln_con)]=0\n",
    "    feature_ln_con[np.isnan(feature_ln_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_ln_pro, feature_ln_con])\n",
    "\n",
    "def get_winner(df): \n",
    "    '''\n",
    "    Cons gets mapped to 0 and pro gets mapped to 1\n",
    "    '''\n",
    "    return df.loc[:, \"winner\"].replace({\"Con\": 0, \"Pro\": 1})\n",
    "\n",
    "def get_all_feature_label(df, vectorizer):\n",
    "    '''\n",
    "    Return the training input and validation input that contains all features, \n",
    "    which are ngram features and debate features\n",
    "    '''\n",
    "    \n",
    "    # Getting two sets of features - ngram and debate related features\n",
    "    ngram_feature = get_ngram_feature(df, vectorizer)\n",
    "\n",
    "    # debate_feature = get_debate_feature(df)\n",
    "\n",
    "    # Combining two sets of features\n",
    "    # X = sparse.hstack([debate_feature, ngram_feature])\n",
    "    X = sparse.hstack([ngram_feature])\n",
    "\n",
    "    y = np.array(get_winner(df))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   [\n",
      "      {\n",
      "         \"side\": \"Pro\",\n",
      "         \"text\": \"\\n  \\n  Thank you, Muted, for accepting this debate.  \\n  Resolved:   Atheism is more probable than Theism.  \\n  For purposes of this debate, the term \\\"God\\\" will be defined as to include the general attributes of the Judeo-Christian God (i.e.: omnipotence, omniscience, omnibenevolence etc.) That is to say, we are not referring to any   specific   deity. Therefore, terms such as the incarnation, Biblical errors, etc. are irrelevant for this debate.  \\\"More probable\\\" is to be defined as more likely than not (in other words, atheism is more likely than Theism).   Rules:     (1) Debater must have typing experience and internet access.  (2) Sources may be linked to inside the debate; however, no arguments can be placed in that page.  (3) Structure the debate in a readable, coherent fashion.  (4) No semantics, trolling, or lawyering.  (5) Forfeiting any round will result in a 7 point loss.   Rounds  :   (1) Acceptance  (2) Opening Statement  (3) Rebuttal  (4) Rebuttal  (5) Closing Statements - 1,000 character limit  Other notes:  (1) 72 hours to argue;  (2) If special circumstances arise, one side may ask the other to wait out his or her remaining time.   (3) If one side explicitly concedes or violates any terms, then all seven points will be awarded to the other;  (4) By accepting this challenge, you agree to these terms.  \\n  \\n\"\n",
      "      },\n",
      "      {\n",
      "         \"side\": \"Con\",\n",
      "         \"text\": \"\\n  \\r\\nI accept.\"\n",
      "      }\n",
      "   ],\n",
      "   [\n",
      "      {\n",
      "         \"side\": \"Pro\",\n",
      "         \"text\": \"\\n  \\n  \\n  A challenge often presented to Atheists from fundamentalist Christians or various Theists is that atheists have no proof there is no God; therefore it is another faith. Although we do not have the Burden of Proof, we can still put forth different types of reasoning to give a philosophical justification for an Atheological worldview. There are two main categories of evidence that can be used. I will divide my arguments up into different sections for these categories. The first is called   evidential   arguments. These are arguments that some facts about the world are cited as evidence against God's existence; for example, the large amount of suffering in the world or the argument from Biblical defects. These arguments carry the   probabilistic   conclusion that God does not exist; in other words, on balance of probability, it is more likely than not that God does not exist. Therefore, these arguments do not carry conclusive evidence that there is absolutely no God. The second is called   logical   evidence against God's existence. These are  philosophical   evidence which cites that either a) The proposition that God exists is logically incoherent in some way; or b) the concept of God is incoherent in some way. These type of evidence purports to conclusively demonstrate the fact of atheism based on logical incompatibility with the cited contingent facts about the world and the proposition that God exists.  \\n  \\n  Part 1: The Evidential Evidence Against God\\u2019s Existence  Contention 1: Argument from Evil and Suffering  \\n     \\n  The Problem of Evil cites the large number of suffering as evidence against his existence. In syllogism form, we have:  \\n  \\n  If God exists, unjustified evil does not exist  \\n  Unjustified evil does exist  \\n  Therefore, God does not exist.  \\n  \\n  The world is indeed full of unnecessary suffering and evil. When I say the word   evil,   I do not limit myself to just   moral   evil such as sin. Rather, I am referring to all types of calamity that can befall on humans (i.e., earthquakes, storms, floods) and the existence of mass suffering (i.e., famines, poverty, oppression, etc). I do not believe that Theists have a good answer for the Problem of Suffering and Evil. As Charles Brandlaugh argues [1]:  \\n  \\n  \\n  \\n     \\n  \\n  \\n  \\n  \\u201cThe existence of evil is a terrible stumbling block for the theist. Pain, misery, crime, poverty confront the advocate of eternal goodness, and challenge with unanswerable potency his declaration of Deity all-good, all-wise and all-powerful. Evil is either caused by God or it exist independently; but it cannot be caused by God, as in that case he would not be all-good; nor can it exists hostilely, as in that case he would not be all-powerful. If all-good he would desire to annihilate evil, and continued evil contradicts either God's desire, or God's ability, to prevent it. Evil must either have had a beginning or it must have been eternal, but according to the theist, it cannot be eternal, because God alone is eternal. Nor can it have had a beginning, for if it had it must either have originated in God, or outside God; but according to the theist, it cannot have originated in God, for he is all-good, and out of all goodness evil cannot originate; nor can evil have originated outside God, for, according to the theist, God is infinite, and it is impossible to go outside of or beyond infinity.\\u201d  \\n  For examples of disasters may include Hurricane Sandy, which left billions of dollars in damage and hundreds dead, or the Haitian earthquake that has left hundreds of people dead. Thousands of more examples can be noted.  \\n  William Rowe points out [2]:  \\n  Lightning strikes a tree in a forest, causing a forest fire. A fawn is caught in this fire, and suffers intense agony for an extended period of time before finally dying.     (This has undoubtedly happened many times in the Earth's history.)  A five year old girl is, by her mother's boyfriend, severely beaten, raped and strangled to death.   [3]  \\n  In conclusion,  \\n  \\u201cEither God wants to abolish evil and cannot, or he can but does not want to, or he cannot and does not want to, or lastly he can and wants to. If he wants to remove evil, and cannot, he is not omnipotent; If he can, but does not want to, he is not benevolent; If he neither can nor wants to, he is neither omnipotent nor benevolent; But if God can abolish evil and wants to, how does evil exists?\\u201d   [4]  \\n  One final note: This does not disprove the existence of   all   God\\u2019s; however, it is strong evidence against a God that is supposedly all loving , all-powerful, and all-knowing.  \\n  Contention 2: The Argument from Demographics  \\n     \\n  \\n  If the demographics of Theism are better explained by Atheism than Theism, then the demographics of Theism make Atheism more plausible than Theism.  \\n  The demographics of Theism are better explained by Atheism than Theism.  \\n  Therefore, Atheism is more plausible than Theism.  \\n  \\n  We can begin by making some simple observations:  \\n     \\n  \\n  There are many more Muslims than Christians in Saudi Arabia;[5]  \\n  There are many more Hindus in India than in the rest of the world[6]; and  \\n  In the ancient world, every culture had its own mythology. In fact, these mythologies often contradicted each other and varied wildly.[7]  \\n  \\n  This pattern is very surprising on the part of Theism. Why would God let such an important matter depend strongly upon the time and place of one\\u2019s birth? In fact, atheism explains these demographics better. If God does not exist, then religions are but elaborate social constructions. Therefore, we would predict that the demographics would obey the contours of history and geographic similar to other beliefs and ideologies. This is, in fact, what we observe.  \\n  \\n  Part II: Logical Arguments  Contention 3: Incoherence of God  \\n     \\n  The standard definition of \\u201cGod\\u201d is largely incoherent. According to the National Catholic Almanac, there are 22 attributes of \\u201cGod\\u201d[8]:     \\n  \\u201c[A]lmighty, eternal, holy, immortal, immense, immutable, incomprehensible, ineffable, infinite, invisible, just, loving, merciful, most high, most wise, omnipotent, omniscient, omnipresent, patient, perfect, provident, supreme, true.  \\n     \\n  At least two of the above attributes (incomprehensible and ineffable) contradict the others. How can the other attributes of God be known if he can be neither understood nor described? If God has free-will, as some Christians believe that he does, then how can he know everything? These are some of the attributes of God that are logically incompatible; thus making the Theist God impossible. So \\u201c[t]hus the characteristics of God as supplied by Christian theologians (and other theologians) are nothing more than meaningless and contradictory concepts wrapped in theological garb.\\u201d[9]  \\n  Conclusions  \\n     \\n  \\n  The mainstream concept of God is logically impossible;  \\n  The problem of evil is proof positive for the non-existence of an omnipotent, omniscient, omnibenevolent God;  \\n  The demographics of Theism are better explained by Atheism; and  \\n  Theism does not have a good explanation for the problems of suffering and the arguments for Atheism.  \\n  \\n     \\n  \\n  \\n  [1] Bradlaugh, Humanity's Gain From Unbelief: p28-29. Quoted in Tobin, P. (2000) \\u201c  The Rejection of Pascal\\u2019s Wager: The Skeptic\\u2019s Guide to Christianity  .\\u201d  \\n  \\n  \\n  [2] As Presented in a debate between WriterDave and SuburbiaSurvivor   http://debate.org...  ...  \\n  \\n  \\n  [3] This is taken from an instance in Flint, Michigan in 1986  \\n  \\n  \\n  [4] This is the famous Epicurus Dilemma from Aphorisms of Epicurus (c300BC).  \\n  \\n  \\n  [5] 99% of Saudi Arabia are Muslims.   http://www.state.gov...  ...  \\n  \\n  \\n  [6] 80% of India are Hindus.   http://censusindia.gov.in...  ...  \\n  \\n  \\n  [7] See   http://www.mythweb.com...   some of the world\\u2019s myths.  \\n  \\n  \\n  [8] Quoted in Smith, G.   Atheism: The Case Against God  \\n  \\n  \\n  [9] Tobin, P.   The Rejection of Pascal\\u2019s Wager  \\n  \\n  \\n  \\n\"\n",
      "      },\n",
      "      {\n",
      "         \"side\": \"Con\",\n",
      "         \"text\": \"\\n  \\r\\nFirstly I would like to thank Microsuck for beginning this debate. However, all his arguments only work if it is against the Christian God. As we are not arguing for any specific deity, however, I could chose to advocate the human-blood-thirsting Inca god, or aphrodites, or any of them. However, I would not. Instead I will respond to the arguments.  \\n  \\r\\nPart 1:  \\r\\nContention 1: Evil and suffering  \\r\\nThis argument centers around pity for the anecdotes. The problem of evil is actually easily addressed. Plantinga has pointed out that we have a morally significant free will. This accounts for all the unnecessary human suffering caused by other humans. This, however, does not clearly explain natural calamities. But wait, it does. Under the Judeo-Christian theology, man has dominion over all the rest of Creation, this means that when Adam and Eve sinned, the whole of creation would suffer for it (See Romans 8:19ff).  \\r\\nContention 2: Demographics  \\r\\nI will copy from the blog post which I assume you know of.  \\r\\n\\\"I would point out that the syllogism presented has no logical basis because its premises are false and it is badly structured.  \\r\\nSo why is it\\\"s premises false? This is because theism is prevalent, which is not what is expected if there was no deity. (I view Islam as a perversion of Judaism) Furthermore, archeology supports the notion that monotheism came before theism. This cannot be explained if atheism is true, because why one god before more? The more gods the merrier eh?  \\r\\n\\\"According to Stephen Langdon of Oxford, \\\"the history of the oldest civilization of man is a rapid decline from monotheism to extreme polytheism and widespread belief in evil spirits.\\\"  \\r\\nArthur C. Custance makes explanation as follows:  \\r\\n\\\"When the cuneiform literature first began to reveal its message, scholars of cuneiform and Egyptian hieroglyphics soon found themselves dealing with a tremendous number of gods and goddesses, and demons and other spiritual powers of a lesser sort, which seemed to be always at war with one another and much of the time highly destructive. As earlier and earlier tablets, however, began to be excavated and brought to light, and skill in deciphering them increased, the first picture of gross polytheism began to be replaced by something more nearly approaching a hierarchy of spiritual beings organized into a kind of court with one Supreme Being over all.\\\"  \\r\\nLangton: \\\"The history of Sumerian religion, which was the most powerful cultural influence in the ancient world, could be traced by means of pictographic inscriptions almost to the earliest religious concepts of man. The evidence points unmistakably to an original monotheism, the inscriptions and literary remains of the oldest Semitic peoples also indicate a primitive monotheism, and the totemistic origin of Hebrew and other Semitic religions is now entirely discredited.\\\"  \\r\\nAccording to historical evidence, the same pattern is found in Egypt, India, China and Greece. Henry C. Thiessen writes: \\\"The first departure from monotheism seems to have been in the direction of nature worship. Sun, moon, and stars, the great representatives of nature, and fire, air, and water, the great representatives of earth, became objects of popular worship. At the first they were merely personified; then men came to believe that personal beings presided over them. Polytheism has a strong affinity for fallen human nature.\\\"  \\r\\nCustance: \\\"it may safely be said without the slightest hesitation that monotheism never evolved out of polytheism in any part of the world\\\"s earliest history for which we have documentary evidence.\\\" [1]\\\"  \\n  \\r\\nPart II:  \\r\\nContention 3: Incoherence  \\r\\nThe basic theology behind this is that God cannot be fully defined by one word. God is a concept beyond the descriptive ability of words. Even the list given is not complete, simply because each word is too limiting. It is thus no incoherence at all, but difficult to comprehend theology.  \\n  \\r\\n1.   http://creation.com...\"\n",
      "      }\n",
      "   ],\n",
      "   [],\n",
      "   [\n",
      "      {\n",
      "         \"side\": \"Pro\",\n",
      "         \"text\": \"\\n  \\n  Thank you for accepting this debate and I am looking forward to the rest of the debate. I should point out that this past round was for opening statements only and rebuttals should begin in this round. Moreover, the burden of proof is shared, so in the next reply, please present your arguments in favour of God's existence.  Part 1: Evidential Arguments  Contention 1: Evil and Suffering  My opponent's sole response is the argument from free will. However, the argument is lacking and unconvincing. Paul Tobin argues [1]:  \\n  But the free will explanation cannot even satisfactorily explain moral evil. If God is all powerful, he could have created all man with free will and with a predisposition towards doing good. But according to the same theologians, man is sinful by nature, with a predisposition for doing bad. God's action in giving man free-will and at the same time giving him a predisposition towards doing bad is no different morally from a man who drinks, on purpose, in front of a recently reformed alcoholic! If we describe such a man as irresponsible and immoral, why do we persist in calling such a God good?   \\n  The abstraction \\u201cman\\u201d used above is also misleading. All of mankind have free-will; some, a small minority, some men-and women-, chose evil and rob, kill, cheat and maim. Are the more numerous victims to be consoled by saying that this is a consequence of their (the victims) having free will? In other words, are the innocent victims somehow responsible for the crimes on themselves because they have free will? The right to be protected from crimes is basic for all citizens in the world; any government that fails to deliver a reasonable amount of protection from these would be condemned and duly removed from power. Yet somehow it is okay for the all powerful God to give men free will and allow them to suffer the consequences from the minority who misuse it. To say that all will be rectified in the afterlife where the good will be rewarded in heaven and the bad will be punished in hell does not resolve the issue. As George H. Smith observes:  \\n  \\n  \\n  \\n     \\n  [N]o appeal to an afterlife can actually eradicate the problem of evil. An injustice always remains an injustice, regardless of any subsequent effort to comfort the victim. If a father, after beating his child unmercifully, later gives him a lollipop as compensation, this does not eradicate the original act or its evil nature. Nor would we praise the father as just and loving.   \\n     \\n  \\n  \\n  \\n  Yet, this is exactly what the Judeo-Christians claims their God to do. He allows the faithful to suffer (remember Job!) and later rewards them. This God cannot, by any moral yardstick, be called good.  \\n  My opponent argues because the fall of man affected   all   of creation, it can therefore explain natural evil. However, that too is unconvincing.  Why should we suffer for the sins of Adam? My opponent brings up a Biblical verse to prove that point; namely, Adam's sin affected all of Creation. However, Ezekiel 18:20 states this:  The soul that sins, it shall die; a son shall not bear the iniquity of the father, and a father shall not bear the iniquity of the son; the righteousness of the righteous shall be upon himself, and the wickedness of the wicked shall be upon himself.  If this were to be true, why are so many pepole suffering for Adam's sin?   Contention 2: Demographics  Please do forgive me, but I cannot make out what you are trying to argue. I do not see what your argument is. Please expand on it in the next rebuttal round.  Part II: Logical Arguments  Contention 3: Argument from Incoherence  My opponent's reply is a non-answer. I never stated God must be defined by one word. By incoherence, I don't mean that the definition of God is incoherent, rather I mean it is impossible: like a square circle. I gave two attributes of God that are contradictory: Free will and Omnipotent; and Incomprehendible versus Indescribable.  I await your reply.  References  1. Tobin, P. (2000) \\\"  The Rejection of Pascal's Wager: The Skeptic's Guide to Christianity.\\\"   \"\n",
      "      },\n",
      "      {\n",
      "         \"side\": \"Con\",\n",
      "         \"text\": \"\\n  \\r\\nMy apologies, Microsuck, I did not realize I had a BoP or that I was not supposed to refute your arguments in the first round. That being said, I will reply to your arguments first, and then add my arguments.  \\n  \\r\\nContention 1  \\r\\nI will not reply to your objection to the free will argument until you phrase it in your own words. (Our two quotations differ in intent. Mine was to give evidence, yours is to make an argument)  \\n  \\r\\nAs to your opposition to the fall of man affecting all of creation, I said that it is the result of an ongoing punishment. (Paraphrase) I meant that it is then the CONSEQUENCE visited upon the children of Adam, rather than the punishment itself being dealt out to Adam\\\"s descendents. This is because the punishment upon Adam was so great that the consequence were far-reaching. I acknowledge that my phrasing and wording in the previous round led directly to this seeming contradiction. That was my fault. (See [1]) (Consequences and punishments are different)  \\n  \\r\\nContention 2:  \\r\\nMy apologies for the vagueness. I will expand on them. I gave historical evidence in the above round, but I failed to explain it. I will do so here.  \\r\\nFrom the evidence given, we know that monotheism led to polytheism. This brings us to the question (and this is an argument for theism), How did man get such a concept? Is it the result of a \\\"god spot\\\"? Well, despite years of searching for such, none has been found. Therefore it is reasonable to conclude that there is no god spot.  \\r\\nFrom this it is easy to see that there is only one other possibility. This other possibility is that there really was a (singular) theo who revealed himself to man. This is actually quite easy to understand. However, what about all the different gods? (This being all the different monotheistic gods) It is clear that there is actually not much difference between Allah and Yahweh. So the question that must be asked is \\\"which is the perversion of which?\\\" (I\\\"m not wanting to offend anyone here) Not, \\\"Can we discard theo because there seems to be a contradiction?\\\"  \\r\\nI hope this explains it.  \\n  \\r\\nContention 3  \\r\\nI do not understand how incomprehensible and indescribable are contradictory to each other. Neither do I see how omnipotence and free will can contradict. I absolutely do not understand you here. I\\\"m sorry (I searched up the definitions, I don\\\"t find any contradictions). Please revise and give explanations that does not contradict my previous argument, since you don\\\"t dispute that.  \\n  \\r\\nSo now I will go to arguments for God. Besides the one above. I will only use one other argument because you\\\"ll only have one other round to refute me. (My bad.) Therefore I\\\"ll have two arguments.  \\r\\nThe presence of evil [2]  \\r\\nIf there is evil, then there must be some sort of moral code by which Theo is being compared to. Now we know that moral codes are not material, and if they were just the result of chemical reactions, you would have no basis on which to raise the argument of the problem of evil. How do we know what is evil and what is not? There is an innate moral rule in each of us. That is an observation. Do we feel guilt when we violate this code? Yes we do. This brings us to the only logical conclusion of a higher morality. The only higher morality that can logically exist is the Judeo-Christian God.  \\n  \\r\\nNow that I\\\"m running out of time, I\\\"ll pass back to you.  \\n  \\r\\n1.   http://www.apologeticspress.org...  \\r\\n2.   http://www.str.org...\"\n",
      "      }\n",
      "   ],\n",
      "   [],\n",
      "   [\n",
      "      {\n",
      "         \"side\": \"Pro\",\n",
      "         \"text\": \"\\n  \\n  Thank you for your swift response. I have been super busy this weekend with work and school. As such, I may not be able to get all of my arguments in. Therefore, I will focus most on your argument for God's existence.  Part I: Response to Opponent's Arguments for God's Existence  Rebuttal A: Moral Argument for God's Existence  My opponent's sole opening argument for God's existence is the moral argument; namely, if there is evil, then there must be some moral code to live by. In logical syllogism form, we have this:  Premise 1: If objective moral facts exists, then God exists.  Premise 2: Objective moral facts exist.  Conclusion: Therefore, God exists.  To refute this, I wish to bring something that has been presented long ago:  \\\"  Is the holy loved by gods because it is holy? Or is it holy because it is loved by the gods?  \\\"  This is called the Euthyphro's Dilemma. We can put the Euthyphro's Dilemma in logical syllogism format:  \\n  Either:  \\n  The Good is willed by God because it is the Good.  \\n  \\n  \\n  \\n  The Good is the Good because it is willed by God.  \\n  \\n  \\n  If (1a) is true, then the Good is independent of God\\u2019s will.  \\n  If (2) is true, then God did not create the Good, and is not Creator.  \\n  If (1b) is true, then the Good is contingent and subjective (to God\\u2019s will).  \\n  If (4) is true, then there is no objective standard of morality, and the absolute of value-selection is false.  \\n  The standard response (at least the response I have seen) is that it is a false dichotomy: the third option would be that it is subjected to God's   nature  . However, this too is subject to the same dilemma, as Michael Martin notes:  [A]ppealing to God's character only postpones the problem since the dilemma can be reformulated in terms of His character. Is God's character the way it is because it is good or is God's character good simply because it is God's character?  [2]   Secondly, this does not automatically follow that God exists. In order for my opponent's argument to be sound, my opponent MUST show: 1) That there are objective moral facts; and 2) These facts must have come from God. It is logically possible for there to be no morality. In this case, it appears that this is an undesirable case; however, we see the wishful thinking in the logical format:  \\n  If god does not exist, condition A follows.  \\n  Condition A is undesirable.  \\n  One should not believe in undesirable conditions.  \\n  Third, what role does God play in morality? As Grant Petersen notes [4]:  \\n  Problem of subjectivity  : Who is to say that god's perception of right and wrong is superior to anyone else's? With no guarantee that objective morality even exists (philosophers are still arguing about that one) could one be sure that god's opinion is not any less subjective than yours or mine?  \\n  \\n  Problem of displaced subjectivity  : The god theory does not effectively refute any of the arguments against objective morality, it simply passes the buck. Humans disagree on moral questions, so why not invoke gods? What if the gods disagree among themselves, would they, in turn, appeal to super-gods? And what about the super-gods? It seems a bit like an infinite pile of turtles.  \\n  \\n  Problem of circular reasoning  : Define god as the only possible source of objective morality. Then assume that objective morality exists. Use this as \\\"proof\\\" that god exists.  \\n  \\n  Problem of interpretation  : Assume for a moment that god's morals are, in fact, superior to human morals: how is one to determine what those morals or values consist of? Some ancient writings and the somewhat dubious interpretations of priests, etc., are all that we have to go on. Even if god knows what is morally right or wrong, the fact that we do not know what he knows makes the point moot.  \\n  \\n  Problem of numerous gods  : Through the ages there have been many different religions with many different gods, all of which seemed to have somewhat differing opinions about morality, ranging from human sacrifice to cannibalism. Which one was right? Sounds pretty subjective to me.  \\n  Finally, altruism, compassion, empathy, love, conscience, the sense of justice-all of those things that hold society together - can now be confidently be said to have a firm genetic basis.   Morality evolved \\u2026 as a form of social control, conflict resolution and group cohesion. [4] Without such, society as a whole cannot exist.  I hope I have managed to, at the very least, cast doubt on the moral argument for God's existence and to convince the reader that God is not necessary for morality. The fact of the matter is that we can explain morality from a natural standpoint (we can debate this next, if you would like); moreover, I feel that with the   Euthyphro's Dilemma, the argument is immediately refuted with the fact that the argument is logically  fallacious.  Once again, I apologize for these short statements and I apologize for not responding sooner. I will allow you in the next round to defend only your opening statements; please do not add anything to it or rebut my opening arguments further. If you would like, we may amend the 5th round to include VERY BRIEF defenses and polishes on our statements.  I bounch it back to you.  _______________________________________________________________________________________________  References  1.   http://www.strongatheism.net...  ;  2.   http://www.infidels.org...  ;  3. Tobin, P. (2000). \\\"  The Rejection of Pascal's Wager  .\\\"      \\n\"\n",
      "      },\n",
      "      {\n",
      "         \"side\": \"Con\",\n",
      "         \"text\": \"\\n  \\r\\nAs my opponent has to drop all of his arguments, I too will focus only on my own arguments. In this, I will point out that my opponent has an incomplete reference 4.  \\n  \\r\\nSo I will defend my arguments here. Firstly, I will put to rest the idea of \\\"genetic basis-hence evolved. Hence no God.\\\"  \\r\\n1. We have no evidence that it evolved. A common ancestor is only just as plausible as a common designer, with none of the intelligence.  \\r\\n2. It goes against evolutionary philosophy. This is because survival of the fittest prohibits that which is weak from reproducing more than that of the strong. There is thus no need for, and no selective pressure.  \\r\\n3. Even if morality evolved, the possibility that a God placed it there is actually very great.  \\r\\n4. Finally, all the qualities you have listed are NOT qualities of morality. It is aspects of emotion.  \\n  \\r\\nEuthyphro's Dilemma:  \\r\\nThis indeed is a false dichotomy. And because you did not phrase it in such a way as to protect against the \\\"delaying,\\\" I still can use it. Since you have already yourself answered the first portion, I will move on to the second portion. The question of God and good.  \\r\\n[1] (Since you quoted from Martin, I will quote from Koukl) \\\"Socrates' challenge to Euthyphro has not been met. What is \\\"good\\\"? It doesn't help to say that God is good unless we know what the term refers to.  \\r\\nIf the word \\\"good\\\" means \\\"in accord with the nature and character of God,\\\" we have a problem. When the Bible says \\\"God is good,\\\" it simply means \\\"God has the nature and character that God has.\\\" If God and goodness are the very same thing, then the statement \\\"God is good\\\" means nothing more than \\\"God is God,\\\" a useless tautology.  \\r\\nThe answer to this problem hinges on the philosophical notion of identity, expressed symbolically as A = A. When one thing is identical to another..., there are not two things, but one...  \\r\\nAccording to Christian teaching, God is not good in the same way that a bachelor is an unmarried male. When we say God is good, we are giving additional information, namely that God has a certain quality. God is not the very same thing as goodness (identical to it). It's an essential characteristic of God, so there is no tautology.\\\"  \\r\\nSo the question arises (and I\\\"m taking ideas from 1\\\"s next section), how do we know what is good? Well, there is a simple answer to this, moral intuition. As I mentioned earlier, this is a good argument for the existence of a God, and it cannot be explained naturalistically. Without the Christian God, moral terms are incoherent and our intuition is a nothing.  \\n  \\r\\nSo I have addressed the issue of whether God exist or not. The syllogism regarding conditions and god have nothing to do with my arguments. I will thus not refute it. (My arguments are not based on emotion)  \\n  \\r\\nI will address each of the points made by Peterson in detail.  \\r\\nPoints 1, 2, and 5 are only useful against a religion with numerous gods. They fail thoroughly against the Christian God, and I don\\\"t think I need to explain why.  \\r\\nPoint 3: As I said above, objective morality in some form exist. This is not an assumption. Logical reasoning would make clear that objective morality must have originated from a higher power, even highest. This does not prove the existence of a god. However, it is a strong indicator.  \\r\\nPoint 4: This assumes that the divine is unable to interact with humans. This point is mute in the case of the Judeo-Christian God.  \\r\\nNow that I have answered fully all of Pro\\\"s objections. I would like to agree to the amendment proposed. Say around 3k characters?  \\n  \\r\\nSo in conclusion, my arguments are not logically fallacious, morality is not naturalistically explicable, and some of your counters don\\\"t even fit the God I\\\"m advocating.  \\n  \\r\\n1.   http://www.str.org...\"\n",
      "      }\n",
      "   ],\n",
      "   [\n",
      "      {\n",
      "         \"side\": \"Pro\",\n",
      "         \"text\": \"\\n  \\n  Thank you for this debate. As per the rules, these are my closing statements.  I believe that I have casted doubts on the existence of YHWH God. I do not believe that my opponent adaquetly responded  to my arguments and did not adaquetly refute my argument against the moral argument for God's existence.   I do not have time for a full closing statements, so I'll leave it at this: Happy thanksgiving to everyone and I thank Muted for this fun debate.  Vote pro.  \"\n",
      "      },\n",
      "      {\n",
      "         \"side\": \"Con\",\n",
      "         \"text\": \"\\n  \\r\\nI would like to wish everyone happy thanksgiving and leave it now to the voters.\"\n",
      "      }\n",
      "   ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(df_train.loc[0, \"rounds\"], default=str, indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - lex feature, debate feature, n-gram feature\n",
    "This model should use\n",
    "1. word ngrams\n",
    "2. lexicon based features: implement lexicon based features for a lexicon of your choice\n",
    "   1. Connotation lexicon\n",
    "   2. NRC-VAD lexicon\n",
    "   3. How you extract features is part of the desgin decision that you need to make. One simple example for lexical features could be counting how many words in each debaters language appear in the corresponding lexicon. \n",
    "\n",
    "TODO: \n",
    "1. Read connotation - 1 file\n",
    "2. NRC features - 2 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-9f939a208fd7>:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_connotation = pd.read_csv(CONNOTATION, sep=\",|_\", header=None)\n"
     ]
    }
   ],
   "source": [
    "# 1. Read connotation - 1 file\n",
    "# 2. NRC features - 2 files \n",
    "CONNOTATION = \"./resources/lexica/connotation_lexicon_a.0.1.csv\"\n",
    "NRC_LEXICON_VAD = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/NRC-VAD-Lexicon.txt\"\n",
    "NRC_LEXICON_SORTED_VALENCE = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/v-scores.txt\"\n",
    "NRC_LEXICON_SORTED_AROUSAL = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/a-scores.txt\"\n",
    "NRC_LEXICON_SORTED_DOMINANCE = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/d-scores.txt\"\n",
    "\n",
    "df_connotation = pd.read_csv(CONNOTATION, sep=\",|_\", header=None)\n",
    "df_connotation.columns = [\"word\", \"pos\", \"connotation\"] # word, part of speech, connotation\n",
    "df_connotation = df_connotation.dropna() # There are five words in the connotation that are nan \n",
    "df_connotation = df_connotation.set_index(\"word\")\n",
    "df_connotation[\"pos\"] = df_connotation[\"pos\"].astype('category')\n",
    "df_connotation = df_connotation.drop(columns=[\"pos\"]) # drop the part of speech classification because we can't use it now \n",
    "df_connotation[\"connotation\"] = df_connotation[\"connotation\"].astype('category')\n",
    "df_connotation = pd.get_dummies(df_connotation)\n",
    "\n",
    "df_nrc_vad = pd.read_csv(NRC_LEXICON_VAD, sep=\"\t\", header=None)\n",
    "df_nrc_vad.columns = [\"word\", \"valence\", \"arousal\", \"dominance\"]\n",
    "df_nrc_vad = df_nrc_vad.dropna()\n",
    "df_nrc_vad = df_nrc_vad.set_index(\"word\")\n",
    "df_nrc_vad[\"valence\"] = df_nrc_vad[\"valence\"].astype('category')\n",
    "df_nrc_vad[\"arousal\"] = df_nrc_vad[\"arousal\"].astype('category')\n",
    "df_nrc_vad[\"dominance\"] = df_nrc_vad[\"dominance\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, min_df=0.2, ngram_range=(1, 3),\n",
       "                stop_words='english', sublinear_tf=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get features and labels for traininig and validation \n",
    "unigram_vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate the corpus for vectotrizer to fit on \n",
    "document_train_side = get_text_by_side(df_train)\n",
    "document_val_side = get_text_by_side(df_val)\n",
    "document_train = [side[0] + side[1] for side in document_train_side]\n",
    "document_val = [side[0] + side[1] for side in document_val_side]\n",
    "\n",
    "# The vectorizer trains all all the textual corpus regardless of the side \n",
    "# of the debate \n",
    "unigram_vectorizer.fit(document_train)\n",
    "\n",
    "# Get the feature vector of a sentence using ngram @ matrix_connotation\n",
    "# Creating the matrix \n",
    "word_connotation = df_connotation.index\n",
    "word_vector_connotation = unigram_vectorizer.transform(word_connotation)\n",
    "matrix_connotation = word_vector_connotation.T @ df_connotation\n",
    "matrix_connotation_no_neutral = word_vector_connotation.T @ df_connotation.drop(columns=[\"connotation_neutral\"])\n",
    "\n",
    "word_vad = df_nrc_vad.index\n",
    "word_vector_vad = unigram_vectorizer.transform(word_vad)\n",
    "matrix_vad = word_vector_vad.T @ df_nrc_vad\n",
    "# For words with mulitple part of speech, we are counting the total\n",
    "# sum across all part of speech of that word for each feature \n",
    "\n",
    "# Get label \n",
    "label_train = get_winner(df_train)\n",
    "label_val = get_winner(df_val)\n",
    "\n",
    "y_train = np.array(label_train)\n",
    "y_val = np.array(label_val)\n",
    "\n",
    "# Get more grams \n",
    "trigram_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0.2, stop_words='english', ngram_range=(1,3))\n",
    "trigram_vectorizer.fit(document_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================== you can run experiments here ======================\n",
    "# Get all TRAINING features:\n",
    "# Get the documents on pro and con side so that we can forming feature \n",
    "# vector on both sides for training \n",
    "\n",
    "trigram_train = get_ngram_feature(document_side=document_train_side, vectorizer=trigram_vectorizer)\n",
    "# ============= using raw number counts of the feature ==========================\n",
    "# feature_connotation_train = get_connotation_feature(document_side=document_train_side,\n",
    "#                                                         matrix_connotation=matrix_connotation,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_vad_train = get_vad_feature(document_side=document_train_side,\n",
    "#                                                         matrix_vad=matrix_vad,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_train, \n",
    "#                     feature_vad_train])\n",
    "\n",
    "# ============= using percentage counts of the feature ==========================\n",
    "# feature_connotation_pct_train = get_connotation_percentage_feature(document_train_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_pct_train = get_vad_percentage_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "#                     feature_vad_pct_train])\n",
    "\n",
    "# ============= using log counts of the feature ==========================\n",
    "# feature_connotation_ln_train = get_connotation_ln_feature(document_train_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_ln_train = get_vad_ln_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_ln_train, \n",
    "#                     feature_vad_ln_train])\n",
    "\n",
    "# ============= using percentage counts of the feature without neutral connotation ==========================\n",
    "feature_connotation_pct_train = get_connotation_percentage_feature(document_train_side, matrix_connotation_no_neutral, unigram_vectorizer)\n",
    "feature_vad_pct_train = get_vad_percentage_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "                    feature_vad_pct_train])\n",
    "\n",
    "# Get all VALIDATION features:\n",
    "trigram_val = get_ngram_feature(document_side=document_val_side, vectorizer=trigram_vectorizer)\n",
    "# ============= using raw counts of of the feature ==========================\n",
    "# feature_connotation_val = get_connotation_feature(document_side=document_val_side,\n",
    "#                                                         matrix_connotation=matrix_connotation,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_vad_val = get_vad_feature(document_side=document_val_side,\n",
    "#                                                         matrix_vad=matrix_vad,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_val, \n",
    "#                     feature_vad_val])\n",
    "\n",
    "# ============= using percentage count of of the feature ==========================\n",
    "# feature_connotation_pct_val = get_connotation_percentage_feature(document_val_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_pct_val = get_vad_percentage_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "#                     feature_vad_pct_train])\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_pct_val, \n",
    "#                     feature_vad_pct_val])\n",
    "\n",
    "# ============= using log counts of the feature ==========================\n",
    "# feature_connotation_ln_val = get_connotation_ln_feature(document_val_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_ln_val = get_vad_ln_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_ln_val, \n",
    "#                     feature_vad_ln_val])\n",
    "\n",
    "# ============= using percentage counts of the feature without neutral connotation ==========================\n",
    "feature_connotation_pct_val = get_connotation_percentage_feature(document_val_side, matrix_connotation_no_neutral, unigram_vectorizer)\n",
    "feature_vad_pct_val = get_vad_percentage_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "\n",
    "feature_val = sparse.hstack([trigram_val, feature_connotation_pct_val, \n",
    "                    feature_vad_pct_val])\n",
    "\n",
    "# Create model\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(feature_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       916\n",
      "           1       0.91      0.82      0.86       676\n",
      "\n",
      "    accuracy                           0.89      1592\n",
      "   macro avg       0.89      0.88      0.88      1592\n",
      "weighted avg       0.89      0.89      0.89      1592\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77       211\n",
      "           1       0.77      0.60      0.68       188\n",
      "\n",
      "    accuracy                           0.73       399\n",
      "   macro avg       0.74      0.72      0.72       399\n",
      "weighted avg       0.74      0.73      0.72       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, clf.predict(feature_train)))\n",
    "print(classification_report(y_val, clf.predict(feature_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Here is the model that only uses debate features and ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro , con shape are (1592, 606) (1592, 606)\n",
      "pro , con shape are (399, 606) (399, 606)\n"
     ]
    }
   ],
   "source": [
    "# Extracting texts from training and testing data\n",
    "label_train = get_winner(df_train)\n",
    "label_val = get_winner(df_val)\n",
    "\n",
    "# Generate the corpus \n",
    "document_train = get_text_by_side(df_train)\n",
    "document_val = get_text_by_side(df_val)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.9, min_df=0.1, stop_words='english', ngram_range=(1,3))\n",
    "vectorizer.fit(document_train)\n",
    "\n",
    "# Getting two sets of features - ngram and debate related features\n",
    "ngram_feature_train = get_ngram_feature(df_train, vectorizer)\n",
    "ngram_feature_val = get_ngram_feature(df_val, vectorizer)\n",
    "\n",
    "debate_feature_train = get_debate_feature(df_train)\n",
    "debate_feture_val = get_debate_feature(df_val)\n",
    "\n",
    "# Combining two sets of features\n",
    "X_train = sparse.hstack([debate_feature_train, ngram_feature_train])\n",
    "X_val = sparse.hstack([debate_feture_val, ngram_feature_val])\n",
    "\n",
    "y_train = np.array(label_train)\n",
    "y_val = np.array(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check\n",
      "1592 number of observations in the training set\n",
      "(1592, 1213) number of observation x the size of ngram vectors in the training set\n",
      "(1592,) number of labels in the training set\n",
      "399 number of observations in the validation set\n",
      "(399, 1213) number of observation x the size of ngram vectors in the validation set\n",
      "(399,) number of labels in the validation set\n"
     ]
    }
   ],
   "source": [
    "print('Sanity check')\n",
    "print(df_train.shape[0], 'number of observations in the training set')\n",
    "print(X_train.shape, 'number of observation x the size of ngram vectors in the training set')\n",
    "print(y_train.shape, 'number of labels in the training set')\n",
    "print(df_val.shape[0], 'number of observations in the validation set')\n",
    "print(X_val.shape, 'number of observation x the size of ngram vectors in the validation set')\n",
    "print(y_val.shape, 'number of labels in the validation set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression training set report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.88      0.94      0.91       916\n",
      "         Con       0.91      0.83      0.87       676\n",
      "\n",
      "    accuracy                           0.89      1592\n",
      "   macro avg       0.90      0.88      0.89      1592\n",
      "weighted avg       0.89      0.89      0.89      1592\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.86      0.78       211\n",
      "         Con       0.80      0.62      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building and training the model\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(ngram_feature_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression training set report:\")\n",
    "print(classification_report(y_train, clf.predict(ngram_feature_train), target_names=['Pro', 'Con']))\n",
    "print(classification_report(y_val, clf.predict(ngram_feature_val), target_names=['Pro', 'Con']))\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<399x1213 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 96112 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1682716 features per sample; expecting 1213",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-aa2b8b9a62ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluating the model on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Logistic Regression testing set report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Con'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 289\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1682716 features per sample; expecting 1213"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the validation set\n",
    "y_predicted = clf.predict(X_val_religion)\n",
    "print(\"Logistic Regression testing set report:\")\n",
    "print(classification_report(y_val_religion, y_predicted, target_names=['Pro', 'Con']))\n",
    "\n",
    "print(\"Accuracy score: \",accuracy_score(y_val_religion, y_predicted))\n",
    "print(\"Balanced accuracy score: \",accuracy_score(y_val_religion, y_predicted))\n",
    "\n",
    "plot_confusion_matrix(clf, X_val, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning ngram models over max_df and min_df\n",
    "def search_max_df_min_df(df_train, df_val):\n",
    "    highest_acc, best_min_df, best_max_df = 0, -1, -1\n",
    "    report = {}\n",
    "    for min_df in np.arange(0, 1, 0.1):\n",
    "        for diff in np.arange(0.1, 1 - min_df, 0.1):\n",
    "            max_df = min_df + diff\n",
    "\n",
    "            vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=max_df, min_df=min_df, stop_words='english', ngram_range=(1,3))\n",
    "            document_train = get_text_by_side(df_train)\n",
    "            vectorizer.fit(document_train)\n",
    "            X_train, y_train = get_all_feature_label(df_train, vectorizer)\n",
    "            X_val, y_val = get_all_feature_label(df_val, vectorizer)\n",
    "\n",
    "            clf = sklearn.linear_model.LogisticRegression()\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"====================================\")\n",
    "\n",
    "            y_predicted = clf.predict(X_val)\n",
    "            print(\"Logistic Regression testing set report:\")\n",
    "            report[(min_df, max_df)] = classification_report(y_val, y_predicted, target_names=['Pro', 'Con'], output_dict=True)\n",
    "            acc = accuracy_score(y_val, y_predicted)\n",
    "\n",
    "            print(\"max_df: {}, min_df: {}, accuracy: {}\".format(max_df, min_df, acc))\n",
    "\n",
    "            if acc > highest_acc:\n",
    "                highest_acc, best_min_df, best_max_df = acc, min_df, max_df\n",
    "\n",
    "    print(\"************ best min_df, best max_df, acc\", best_min_df, best_max_df, highest_acc)\n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "(0.0, 0.1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.54      1.00      0.70       211\n",
      "         Con       1.00      0.06      0.11       188\n",
      "\n",
      "    accuracy                           0.56       399\n",
      "   macro avg       0.77      0.53      0.41       399\n",
      "weighted avg       0.76      0.56      0.42       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.57      1.00      0.72       211\n",
      "         Con       1.00      0.14      0.25       188\n",
      "\n",
      "    accuracy                           0.60       399\n",
      "   macro avg       0.78      0.57      0.49       399\n",
      "weighted avg       0.77      0.60      0.50       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.30000000000000004)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.57      1.00      0.73       211\n",
      "         Con       1.00      0.15      0.26       188\n",
      "\n",
      "    accuracy                           0.60       399\n",
      "   macro avg       0.78      0.57      0.49       399\n",
      "weighted avg       0.77      0.60      0.51       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.57      1.00      0.73       211\n",
      "         Con       1.00      0.17      0.29       188\n",
      "\n",
      "    accuracy                           0.61       399\n",
      "   macro avg       0.79      0.59      0.51       399\n",
      "weighted avg       0.78      0.61      0.52       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.58      1.00      0.73       211\n",
      "         Con       1.00      0.18      0.31       188\n",
      "\n",
      "    accuracy                           0.61       399\n",
      "   macro avg       0.79      0.59      0.52       399\n",
      "weighted avg       0.78      0.61      0.53       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.58      1.00      0.74       211\n",
      "         Con       1.00      0.20      0.34       188\n",
      "\n",
      "    accuracy                           0.62       399\n",
      "   macro avg       0.79      0.60      0.54       399\n",
      "weighted avg       0.78      0.62      0.55       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.7000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.59      1.00      0.74       211\n",
      "         Con       1.00      0.21      0.34       188\n",
      "\n",
      "    accuracy                           0.63       399\n",
      "   macro avg       0.79      0.60      0.54       399\n",
      "weighted avg       0.78      0.63      0.55       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.59      1.00      0.74       211\n",
      "         Con       1.00      0.21      0.35       188\n",
      "\n",
      "    accuracy                           0.63       399\n",
      "   macro avg       0.79      0.61      0.55       399\n",
      "weighted avg       0.78      0.63      0.56       399\n",
      "\n",
      "====================\n",
      "(0.0, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.59      1.00      0.74       211\n",
      "         Con       1.00      0.21      0.35       188\n",
      "\n",
      "    accuracy                           0.63       399\n",
      "   macro avg       0.79      0.61      0.55       399\n",
      "weighted avg       0.78      0.63      0.56       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.88      0.78       211\n",
      "         Con       0.82      0.59      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.74      0.73       399\n",
      "weighted avg       0.76      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.30000000000000004)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.83      0.58      0.68       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.70      0.90      0.79       211\n",
      "         Con       0.84      0.57      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.77      0.73      0.73       399\n",
      "weighted avg       0.76      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.69      0.90      0.78       211\n",
      "         Con       0.83      0.56      0.67       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.73      0.72       399\n",
      "weighted avg       0.76      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.83      0.58      0.68       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.7)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.84      0.59      0.69       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.77      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.89      0.79       211\n",
      "         Con       0.82      0.59      0.69       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.1, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.83      0.59      0.69       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.77      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.30000000000000004)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.86      0.78       211\n",
      "         Con       0.80      0.61      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.75      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.70      0.87      0.78       211\n",
      "         Con       0.80      0.59      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.70      0.88      0.78       211\n",
      "         Con       0.81      0.57      0.67       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.6000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.88      0.79       211\n",
      "         Con       0.82      0.61      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.75      0.75       399\n",
      "weighted avg       0.77      0.75      0.75       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.7)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.89      0.79       211\n",
      "         Con       0.82      0.59      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.74      0.73       399\n",
      "weighted avg       0.76      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.90      0.80       211\n",
      "         Con       0.84      0.60      0.70       188\n",
      "\n",
      "    accuracy                           0.76       399\n",
      "   macro avg       0.78      0.75      0.75       399\n",
      "weighted avg       0.77      0.76      0.75       399\n",
      "\n",
      "====================\n",
      "(0.2, 0.9000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.90      0.79       211\n",
      "         Con       0.84      0.60      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.75      0.74       399\n",
      "weighted avg       0.77      0.75      0.75       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.4)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.68      0.84      0.75       211\n",
      "         Con       0.76      0.56      0.65       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.72      0.70      0.70       399\n",
      "weighted avg       0.72      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.69      0.85      0.76       211\n",
      "         Con       0.77      0.58      0.66       188\n",
      "\n",
      "    accuracy                           0.72       399\n",
      "   macro avg       0.73      0.71      0.71       399\n",
      "weighted avg       0.73      0.72      0.72       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.6000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.88      0.79       211\n",
      "         Con       0.82      0.60      0.69       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.77      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.7000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.87      0.78       211\n",
      "         Con       0.81      0.60      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.76      0.74      0.74       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.85      0.77       211\n",
      "         Con       0.78      0.61      0.68       188\n",
      "\n",
      "    accuracy                           0.73       399\n",
      "   macro avg       0.74      0.73      0.73       399\n",
      "weighted avg       0.74      0.73      0.73       399\n",
      "\n",
      "====================\n",
      "(0.30000000000000004, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.87      0.79       211\n",
      "         Con       0.81      0.62      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.75       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.69      0.82      0.75       211\n",
      "         Con       0.74      0.59      0.65       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.72      0.70      0.70       399\n",
      "weighted avg       0.71      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.6000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.72      0.86      0.78       211\n",
      "         Con       0.80      0.62      0.70       188\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.76      0.74      0.74       399\n",
      "weighted avg       0.76      0.75      0.74       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.7000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.85      0.77       211\n",
      "         Con       0.78      0.61      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.74      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.85      0.77       211\n",
      "         Con       0.79      0.61      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.4, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.86      0.78       211\n",
      "         Con       0.80      0.60      0.68       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.5, 0.6)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.84      0.77       211\n",
      "         Con       0.78      0.62      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.74      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.5, 0.7)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.70      0.86      0.77       211\n",
      "         Con       0.79      0.60      0.68       188\n",
      "\n",
      "    accuracy                           0.73       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.74      0.73      0.73       399\n",
      "\n",
      "====================\n",
      "(0.5, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.85      0.77       211\n",
      "         Con       0.78      0.60      0.68       188\n",
      "\n",
      "    accuracy                           0.73       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.74      0.73      0.73       399\n",
      "\n",
      "====================\n",
      "(0.5, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.71      0.86      0.78       211\n",
      "         Con       0.79      0.61      0.69       188\n",
      "\n",
      "    accuracy                           0.74       399\n",
      "   macro avg       0.75      0.73      0.73       399\n",
      "weighted avg       0.75      0.74      0.73       399\n",
      "\n",
      "====================\n",
      "(0.6000000000000001, 0.7000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.67      0.85      0.75       211\n",
      "         Con       0.76      0.53      0.62       188\n",
      "\n",
      "    accuracy                           0.70       399\n",
      "   macro avg       0.72      0.69      0.69       399\n",
      "weighted avg       0.71      0.70      0.69       399\n",
      "\n",
      "====================\n",
      "(0.6000000000000001, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.67      0.88      0.76       211\n",
      "         Con       0.79      0.52      0.62       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.73      0.70      0.69       399\n",
      "weighted avg       0.73      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.6000000000000001, 0.9000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.67      0.88      0.76       211\n",
      "         Con       0.79      0.51      0.62       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.73      0.70      0.69       399\n",
      "weighted avg       0.73      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.7000000000000001, 0.8)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.67      0.92      0.77       211\n",
      "         Con       0.84      0.48      0.61       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.75      0.70      0.69       399\n",
      "weighted avg       0.75      0.71      0.70       399\n",
      "\n",
      "====================\n",
      "(0.7000000000000001, 0.9000000000000001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.66      0.91      0.77       211\n",
      "         Con       0.83      0.48      0.61       188\n",
      "\n",
      "    accuracy                           0.71       399\n",
      "   macro avg       0.75      0.70      0.69       399\n",
      "weighted avg       0.74      0.71      0.69       399\n",
      "\n",
      "====================\n",
      "(0.8, 0.9)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Pro       0.61      0.91      0.73       211\n",
      "         Con       0.77      0.34      0.47       188\n",
      "\n",
      "    accuracy                           0.64       399\n",
      "   macro avg       0.69      0.62      0.60       399\n",
      "weighted avg       0.68      0.64      0.60       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "max_acc, best_min_df, best_max_df = 0, -1, -1\n",
    "gram3_report = report\n",
    "\n",
    "for key, val in report.items():\n",
    "    print(\"====================\")\n",
    "    print(key)\n",
    "    print(val)\n",
    "\n",
    "# The best min df and the best max df are (0.2, 0.8) with validation accuracy of 0.76\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of achieving this is to create two n-gram models. One n-gram model outputs features\n",
    "for religious topics and another n-gram model outputs features for non-religious topics.\n",
    "By limiting the corpus within their topics, the Tf_idf scores may better reflect the \n",
    "proper weighting. For example, certain words that might only appear in winning relgious debates\n",
    "but also appear in all other losing debates may now have a significantly different score from \n",
    "words that appear in only losing religous debates but appear in all other winning debates. \n",
    "Previously, these two sets of words would have similar tf_idf score but are not helpful \n",
    "towards predicting winning debates because their prediciton power within relgious topic is\n",
    "diluted by the non-religous topics. By limiting the corpus scope, we can see that these \n",
    "words become helpful in both religous and non-relgious debates.\n",
    "\n",
    "TODO:\n",
    "1. Define a Tfidfvectorizer for both religous and non-religious topics\n",
    "2. Train the vectorizer using their respective subsets\n",
    "3. Depending the topic of the new data, we should use the two models conditionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data sets\n",
    "df_train_religion = df_train.loc[df_train.category == \"Religion\" ,:]\n",
    "df_train_other = df_train.loc[df_train.category != \"Religion\" ,:]\n",
    "df_val_religion = df_val.loc[df_val.category == \"Religion\" ,:]\n",
    "df_val_other = df_val.loc[df_val.category != \"Religion\" ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check\n",
      "(370, 9)\n",
      "(1222, 9)\n",
      "(1592, 9)\n",
      "validation set\n",
      "(93, 9)\n",
      "(306, 9)\n",
      "(399, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sanity check\")\n",
    "print(df_train_religious.shape)\n",
    "print(df_train_other.shape)\n",
    "print(df_train.shape)\n",
    "print(\"validation set\")\n",
    "print(df_val_religious.shape)\n",
    "print(df_val_other.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 607)\n",
      "(93, 607)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_religion.shape)\n",
    "print(X_val_religion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro , con shape are (370, 840554) (370, 840554)\n",
      "pro , con shape are (93, 840554) (93, 840554)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.1, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841057) (370, 841057)\n",
      "pro , con shape are (93, 841057) (93, 841057)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841222) (370, 841222)\n",
      "pro , con shape are (93, 841222) (93, 841222)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841289) (370, 841289)\n",
      "pro , con shape are (93, 841289) (93, 841289)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841325) (370, 841325)\n",
      "pro , con shape are (93, 841325) (93, 841325)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841343) (370, 841343)\n",
      "pro , con shape are (93, 841343) (93, 841343)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841354) (370, 841354)\n",
      "pro , con shape are (93, 841354) (93, 841354)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841358) (370, 841358)\n",
      "pro , con shape are (93, 841358) (93, 841358)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 841359) (370, 841359)\n",
      "pro , con shape are (93, 841359) (93, 841359)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "pro , con shape are (370, 518) (370, 518)\n",
      "pro , con shape are (93, 518) (93, 518)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.1, accuracy: 0.5698924731182796\n",
      "pro , con shape are (370, 683) (370, 683)\n",
      "pro , con shape are (93, 683) (93, 683)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.1, accuracy: 0.5806451612903226\n",
      "pro , con shape are (370, 750) (370, 750)\n",
      "pro , con shape are (93, 750) (93, 750)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.1, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 786) (370, 786)\n",
      "pro , con shape are (93, 786) (93, 786)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.1, accuracy: 0.6236559139784946\n",
      "pro , con shape are (370, 804) (370, 804)\n",
      "pro , con shape are (93, 804) (93, 804)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.1, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 815) (370, 815)\n",
      "pro , con shape are (93, 815) (93, 815)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.1, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 819) (370, 819)\n",
      "pro , con shape are (93, 819) (93, 819)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.1, accuracy: 0.6344086021505376\n",
      "pro , con shape are (370, 820) (370, 820)\n",
      "pro , con shape are (93, 820) (93, 820)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.1, accuracy: 0.6451612903225806\n",
      "pro , con shape are (370, 167) (370, 167)\n",
      "pro , con shape are (93, 167) (93, 167)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.2, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 234) (370, 234)\n",
      "pro , con shape are (93, 234) (93, 234)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.2, accuracy: 0.6559139784946236\n",
      "pro , con shape are (370, 270) (370, 270)\n",
      "pro , con shape are (93, 270) (93, 270)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.2, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 288) (370, 288)\n",
      "pro , con shape are (93, 288) (93, 288)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.2, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 299) (370, 299)\n",
      "pro , con shape are (93, 299) (93, 299)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.2, accuracy: 0.6774193548387096\n",
      "pro , con shape are (370, 303) (370, 303)\n",
      "pro , con shape are (93, 303) (93, 303)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.2, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 304) (370, 304)\n",
      "pro , con shape are (93, 304) (93, 304)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.2, accuracy: 0.6559139784946236\n",
      "pro , con shape are (370, 67) (370, 67)\n",
      "pro , con shape are (93, 67) (93, 67)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.30000000000000004, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 103) (370, 103)\n",
      "pro , con shape are (93, 103) (93, 103)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.30000000000000004, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 121) (370, 121)\n",
      "pro , con shape are (93, 121) (93, 121)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.30000000000000004, accuracy: 0.5806451612903226\n",
      "pro , con shape are (370, 132) (370, 132)\n",
      "pro , con shape are (93, 132) (93, 132)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.30000000000000004, accuracy: 0.6236559139784946\n",
      "pro , con shape are (370, 136) (370, 136)\n",
      "pro , con shape are (93, 136) (93, 136)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.30000000000000004, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 137) (370, 137)\n",
      "pro , con shape are (93, 137) (93, 137)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.30000000000000004, accuracy: 0.6129032258064516\n",
      "pro , con shape are (370, 36) (370, 36)\n",
      "pro , con shape are (93, 36) (93, 36)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.4, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 54) (370, 54)\n",
      "pro , con shape are (93, 54) (93, 54)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.4, accuracy: 0.6451612903225806\n",
      "pro , con shape are (370, 65) (370, 65)\n",
      "pro , con shape are (93, 65) (93, 65)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.4, accuracy: 0.6559139784946236\n",
      "pro , con shape are (370, 69) (370, 69)\n",
      "pro , con shape are (93, 69) (93, 69)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.4, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 70) (370, 70)\n",
      "pro , con shape are (93, 70) (93, 70)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.4, accuracy: 0.6559139784946236\n",
      "pro , con shape are (370, 18) (370, 18)\n",
      "pro , con shape are (93, 18) (93, 18)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.5, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 29) (370, 29)\n",
      "pro , con shape are (93, 29) (93, 29)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.5, accuracy: 0.6666666666666666\n",
      "pro , con shape are (370, 33) (370, 33)\n",
      "pro , con shape are (93, 33) (93, 33)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.5, accuracy: 0.6989247311827957\n",
      "pro , con shape are (370, 34) (370, 34)\n",
      "pro , con shape are (93, 34) (93, 34)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.5, accuracy: 0.6881720430107527\n",
      "pro , con shape are (370, 11) (370, 11)\n",
      "pro , con shape are (93, 11) (93, 11)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.6000000000000001, accuracy: 0.5913978494623656\n",
      "pro , con shape are (370, 15) (370, 15)\n",
      "pro , con shape are (93, 15) (93, 15)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.6000000000000001, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 16) (370, 16)\n",
      "pro , con shape are (93, 16) (93, 16)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.6000000000000001, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 4) (370, 4)\n",
      "pro , con shape are (93, 4) (93, 4)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.7000000000000001, accuracy: 0.6021505376344086\n",
      "pro , con shape are (370, 5) (370, 5)\n",
      "pro , con shape are (93, 5) (93, 5)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.7000000000000001, accuracy: 0.5806451612903226\n",
      "pro , con shape are (370, 1) (370, 1)\n",
      "pro , con shape are (93, 1) (93, 1)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.8, accuracy: 0.5053763440860215\n",
      "************ best min_df, best max_df, acc 0.5 0.8 0.6989247311827957\n",
      "pro , con shape are (1222, 2228111) (1222, 2228111)\n",
      "pro , con shape are (306, 2228111) (306, 2228111)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.1, min_df: 0.0, accuracy: 0.5882352941176471\n",
      "pro , con shape are (1222, 2228508) (1222, 2228508)\n",
      "pro , con shape are (306, 2228508) (306, 2228508)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.0, accuracy: 0.6111111111111112\n",
      "pro , con shape are (1222, 2228606) (1222, 2228606)\n",
      "pro , con shape are (306, 2228606) (306, 2228606)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.0, accuracy: 0.6274509803921569\n",
      "pro , con shape are (1222, 2228645) (1222, 2228645)\n",
      "pro , con shape are (306, 2228645) (306, 2228645)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.0, accuracy: 0.6339869281045751\n",
      "pro , con shape are (1222, 2228662) (1222, 2228662)\n",
      "pro , con shape are (306, 2228662) (306, 2228662)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.0, accuracy: 0.6535947712418301\n",
      "pro , con shape are (1222, 2228672) (1222, 2228672)\n",
      "pro , con shape are (306, 2228672) (306, 2228672)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.0, accuracy: 0.6633986928104575\n",
      "pro , con shape are (1222, 2228676) (1222, 2228676)\n",
      "pro , con shape are (306, 2228676) (306, 2228676)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.0, accuracy: 0.6633986928104575\n",
      "pro , con shape are (1222, 2228677) (1222, 2228677)\n",
      "pro , con shape are (306, 2228677) (306, 2228677)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.0, accuracy: 0.6633986928104575\n",
      "pro , con shape are (1222, 2228677) (1222, 2228677)\n",
      "pro , con shape are (306, 2228677) (306, 2228677)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.0, accuracy: 0.6633986928104575\n",
      "pro , con shape are (1222, 397) (1222, 397)\n",
      "pro , con shape are (306, 397) (306, 397)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.1, accuracy: 0.7156862745098039\n",
      "pro , con shape are (1222, 495) (1222, 495)\n",
      "pro , con shape are (306, 495) (306, 495)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.1, accuracy: 0.7320261437908496\n",
      "pro , con shape are (1222, 534) (1222, 534)\n",
      "pro , con shape are (306, 534) (306, 534)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.1, accuracy: 0.7189542483660131\n",
      "pro , con shape are (1222, 551) (1222, 551)\n",
      "pro , con shape are (306, 551) (306, 551)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.1, accuracy: 0.7189542483660131\n",
      "pro , con shape are (1222, 561) (1222, 561)\n",
      "pro , con shape are (306, 561) (306, 561)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.1, accuracy: 0.7549019607843137\n",
      "pro , con shape are (1222, 565) (1222, 565)\n",
      "pro , con shape are (306, 565) (306, 565)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.1, accuracy: 0.7418300653594772\n",
      "pro , con shape are (1222, 566) (1222, 566)\n",
      "pro , con shape are (306, 566) (306, 566)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.1, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 566) (1222, 566)\n",
      "pro , con shape are (306, 566) (306, 566)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.1, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 99) (1222, 99)\n",
      "pro , con shape are (306, 99) (306, 99)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.2, accuracy: 0.7320261437908496\n",
      "pro , con shape are (1222, 138) (1222, 138)\n",
      "pro , con shape are (306, 138) (306, 138)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.2, accuracy: 0.738562091503268\n",
      "pro , con shape are (1222, 155) (1222, 155)\n",
      "pro , con shape are (306, 155) (306, 155)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.2, accuracy: 0.7418300653594772\n",
      "pro , con shape are (1222, 165) (1222, 165)\n",
      "pro , con shape are (306, 165) (306, 165)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.2, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 169) (1222, 169)\n",
      "pro , con shape are (306, 169) (306, 169)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.2, accuracy: 0.7418300653594772\n",
      "pro , con shape are (1222, 170) (1222, 170)\n",
      "pro , con shape are (306, 170) (306, 170)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.2, accuracy: 0.7516339869281046\n",
      "pro , con shape are (1222, 170) (1222, 170)\n",
      "pro , con shape are (306, 170) (306, 170)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.2, accuracy: 0.7516339869281046\n",
      "pro , con shape are (1222, 39) (1222, 39)\n",
      "pro , con shape are (306, 39) (306, 39)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.30000000000000004, accuracy: 0.7222222222222222\n",
      "pro , con shape are (1222, 56) (1222, 56)\n",
      "pro , con shape are (306, 56) (306, 56)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.30000000000000004, accuracy: 0.738562091503268\n",
      "pro , con shape are (1222, 66) (1222, 66)\n",
      "pro , con shape are (306, 66) (306, 66)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.30000000000000004, accuracy: 0.7647058823529411\n",
      "pro , con shape are (1222, 70) (1222, 70)\n",
      "pro , con shape are (306, 70) (306, 70)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.30000000000000004, accuracy: 0.7549019607843137\n",
      "pro , con shape are (1222, 71) (1222, 71)\n",
      "pro , con shape are (306, 71) (306, 71)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.30000000000000004, accuracy: 0.761437908496732\n",
      "pro , con shape are (1222, 71) (1222, 71)\n",
      "pro , con shape are (306, 71) (306, 71)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.30000000000000004, accuracy: 0.761437908496732\n",
      "pro , con shape are (1222, 17) (1222, 17)\n",
      "pro , con shape are (306, 17) (306, 17)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.4, accuracy: 0.6830065359477124\n",
      "pro , con shape are (1222, 27) (1222, 27)\n",
      "pro , con shape are (306, 27) (306, 27)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.4, accuracy: 0.7418300653594772\n",
      "pro , con shape are (1222, 31) (1222, 31)\n",
      "pro , con shape are (306, 31) (306, 31)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.4, accuracy: 0.7352941176470589\n",
      "pro , con shape are (1222, 32) (1222, 32)\n",
      "pro , con shape are (306, 32) (306, 32)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.4, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 32) (1222, 32)\n",
      "pro , con shape are (306, 32) (306, 32)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.4, accuracy: 0.7450980392156863\n",
      "pro , con shape are (1222, 10) (1222, 10)\n",
      "pro , con shape are (306, 10) (306, 10)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.5, accuracy: 0.7352941176470589\n",
      "pro , con shape are (1222, 14) (1222, 14)\n",
      "pro , con shape are (306, 14) (306, 14)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.5, accuracy: 0.7320261437908496\n",
      "pro , con shape are (1222, 15) (1222, 15)\n",
      "pro , con shape are (306, 15) (306, 15)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.5, accuracy: 0.7222222222222222\n",
      "pro , con shape are (1222, 15) (1222, 15)\n",
      "pro , con shape are (306, 15) (306, 15)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.5, accuracy: 0.7222222222222222\n",
      "pro , con shape are (1222, 4) (1222, 4)\n",
      "pro , con shape are (306, 4) (306, 4)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.6000000000000001, accuracy: 0.6339869281045751\n",
      "pro , con shape are (1222, 5) (1222, 5)\n",
      "pro , con shape are (306, 5) (306, 5)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.6000000000000001, accuracy: 0.6764705882352942\n",
      "pro , con shape are (1222, 5) (1222, 5)\n",
      "pro , con shape are (306, 5) (306, 5)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.6000000000000001, accuracy: 0.6764705882352942\n",
      "pro , con shape are (1222, 1) (1222, 1)\n",
      "pro , con shape are (306, 1) (306, 1)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.7000000000000001, accuracy: 0.6535947712418301\n",
      "pro , con shape are (1222, 1) (1222, 1)\n",
      "pro , con shape are (306, 1) (306, 1)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.7000000000000001, accuracy: 0.6535947712418301\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-e5171e942c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msearch_max_df_min_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msearch_max_df_min_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_other\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val_other\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-bbafb6186b24>\u001b[0m in \u001b[0;36msearch_max_df_min_df\u001b[0;34m(df_train, df_val)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mdocument_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_by_side\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_feature_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_feature_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m   1225\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[1;32m   1093\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "search_max_df_min_df(df_train_religion, df_val_religion)\n",
    "search_max_df_min_df(df_train_other, df_val_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro , con shape are (370, 841358) (370, 841358)\n",
      "pro , con shape are (93, 841358) (93, 841358)\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.1, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.0, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.2, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.1, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.30000000000000004, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9000000000000001, min_df: 0.2, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.4, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.30000000000000004, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.5, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6000000000000001, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.4, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.6, min_df: 0.5, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7, min_df: 0.5, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.5, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.9, min_df: 0.5, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.7000000000000001, min_df: 0.6000000000000001, accuracy: 0.4946236559139785\n",
      "====================================\n",
      "Logistic Regression testing set report:\n",
      "max_df: 0.8, min_df: 0.6000000000000001, accuracy: 0.4946236559139785\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-c06ef8e9c814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_religion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_feature_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_val_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_religion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_feature_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mreport_religion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_max_df_min_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_religion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_religion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvectorizer_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-84f2027f84e5>\u001b[0m in \u001b[0;36msearch_max_df_min_df\u001b[0;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1414\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1416\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             )\n\u001b[1;32m    763\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 618\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mupdate_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFD_METHODS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up the vectorizer\n",
    "vectorizer_religion = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0, stop_words='english', ngram_range=(1,3))\n",
    "document_train_religion = get_text_by_side(df_train_religion)\n",
    "vectorizer_religion.fit(document_train_religion)\n",
    "X_train_religion, y_train_religion = get_all_feature_label(df_train_religion, vectorizer_religion)\n",
    "X_val_religion, y_val_religion = get_all_feature_label(df_val_religion, vectorizer_religion)\n",
    "report_religion = search_max_df_min_df(X_train_religion, y_train_religion, X_val_religion, y_val_religion)\n",
    "\n",
    "vectorizer_other = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0, stop_words='english', ngram_range=(1,3))\n",
    "document_train_other = get_text_by_side(df_train_other)\n",
    "vectorizer_other.fit(document_train_other)\n",
    "X_train_other, y_train_other = get_all_feature_label(df_train_other, vectorizer_other)\n",
    "X_val_other, y_val_other = get_all_feature_label(df_val_other, vectorizer_other)\n",
    "report_other = search_max_df_min_df(X_train_other, y_train_other, X_val_other, y_val_other)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f78e94ca1a29e9011c2866c841de859bf08fcc5b57f07b9ffb161018ea406f8e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('env_nlp': conda)",
   "language": "python",
   "name": "python3613jvsc74a57bd0f78e94ca1a29e9011c2866c841de859bf08fcc5b57f07b9ffb161018ea406f8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
