{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from numpy.lib.function_base import vectorize\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import sparse\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from better_profanity import profanity\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading user  data \n",
    "USER_DATA = './resources/data/users.json'\n",
    "df_user = pd.read_json(USER_DATA, orient=\"index\")\n",
    "\n",
    "# loading training data .jsonl\n",
    "TRAINING_DATA = './resources/data/train.jsonl'\n",
    "VAL_DATA = './resources/data/val.jsonl'\n",
    "\n",
    "df_train, df_val = pd.read_json(TRAINING_DATA, lines=True), pd.read_json(VAL_DATA, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Length\n",
    "# (b) Reference to the opponent\n",
    "# (c) Politeness words\n",
    "# (d) Swear words\n",
    "# (e) Personal pronouns\n",
    "# (f) Modal verbs\n",
    "# (g) Misspellings\n",
    "# (h) Links to outside websites\n",
    "# (i) Numbers\n",
    "# (j) Exclamation points\n",
    "# (k) Questions\n",
    "\n",
    "def get_length(document_side, vectorizer): \n",
    "    # Count the number if unigrams in a feature\n",
    "    document_pro = document_side[:, 0]\n",
    "    length_pro = np.sum(vectorizer(document_pro), axis=1)\n",
    "    \n",
    "    document_con = document_side[:, 1]\n",
    "    length_con = np.sum(vectorizer(document_con), axis=1)\n",
    "    \n",
    "    return length_pro, length_con\n",
    "\n",
    "def get_reference_to_opponent(df, document_side, vectorizer): \n",
    "    # Count the number of times the opponent's username is mentioned \n",
    "    pro_count = []\n",
    "    con_count = []\n",
    "    document_pro = document_side[:, 0]\n",
    "    document_con = document_side[:, 1]\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        opponent_name = df.loc[i, \"con_debator\"]\n",
    "        pro_count.append(document_pro.lower().count(opponent_name))\n",
    "        \n",
    "        opponent_name = df.loc[i, \"pro_debator\"]\n",
    "        con_count.append(document_con.lower().count(opponent_name))\n",
    "        \n",
    "    return np.array(pro_count), np.array(con_count) \n",
    "\n",
    "def get_politeness_words(document_side, vectorizer):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_swear_words(document_side, vectorizer):\n",
    "#     perhaps get rid some of the swear words because they look like they are necessary words \n",
    "#     for discussion such as arian, sodom \n",
    "    unigram = vectorizer.get_feature_names() \n",
    "    vector_swear = list(map(lambda x: int(profanity.contains_profanity(x)), unigram))\n",
    "    matrix_swear = np.reshape(vector_swear, newshape=[-1, 1])\n",
    "\n",
    "    document_pro = document_side[:, 0]\n",
    "    unigram_pro = vectorizer.transform(document_pro)\n",
    "    swear_pro = unigram_pro @ matrix_swear\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    unigram_con = vectorizer.transform(document_con)\n",
    "    swear_con = unigram_con @ matrix_swear\n",
    "\n",
    "def get_personal_pronouns(document_side, vectorizer):\n",
    "#     ================== faster but less accurate ========================\n",
    "    personal_pronouns = pd.Series([\"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\"])\n",
    "\n",
    "    document_pro = document_side[:, 0]\n",
    "    document_con = document_side[:, 1]\n",
    "\n",
    "    all_counts_pro = []\n",
    "    all_counts_con = []\n",
    "\n",
    "    for name in personal_pronouns:\n",
    "        count_pro = np.array(list(map(lambda x: x.count(\" {} \".format(name)), document_pro)))\n",
    "        count_pro = np.reshape(count_pro, newshape=[-1, 1])\n",
    "        all_counts_pro.append(count_pro)\n",
    "\n",
    "        count_con = np.array(list(map(lambda x: x.count(\" {} \".format(name)), document_con)))\n",
    "        count_con = np.reshape(count_con, newshape=[-1, 1])\n",
    "        all_counts_con.append(count_con)\n",
    "\n",
    "    personal_pronouns_feature_pro = np.hstack(all_counts_pro)\n",
    "    personal_connouns_feature_con = np.hstack(all_counts_con)\n",
    "\n",
    "#     ================== more accurate but slower ========================\n",
    "    # personal_pronouns_vector = unigram_vectorizer.transform(personal_pronouns)\n",
    "    # matrix_person_pronouns = personal_pronouns_vector.T \n",
    "\n",
    "    # document_pro = document_side[:, 0]\n",
    "    # unigram_pro = vectorizer.transform(document_pro)\n",
    "    # personal_pronouns_feature_pro = unigram_pro @ matrix_person_pronouns\n",
    "    # I_count_pro = np.array(list(map(lambda x: x.count(\" I \"), document_pro)))\n",
    "    # I_count_pro = np.reshape(I_count_pro, newshape=[-1, 1])\n",
    "    # personal_pronouns_feature_pro = sparse.hstack([personal_pronouns_feature_pro, I_count_pro])\n",
    "\n",
    "    # document_con = document_side[:, 1]\n",
    "    # unigram_con = vectorizer.transform(document_con)\n",
    "    # personal_pronouns_feature_con = unigram_con @ matrix_person_pronouns\n",
    "    # I_count_con = np.array(list(map(lambda x: x.count(\" I \"), document_con)))\n",
    "    # I_count_con = np.reshape(I_count_con, newshape=[-1, 1])\n",
    "    # personal_pronouns_feature_con = sparse.hstack([personal_pronouns_feature_con, I_count_con])\n",
    "\n",
    "    return personal_pronouns_feature_pro, personal_pronouns_feature_con\n",
    "    \n",
    "        \n",
    "def get_questions(document_side, vectorizer):\n",
    "    \n",
    "    document_pro = document_side[:, 0]\n",
    "    question_count_pro = np.array(list(map(lambda x: x.count(\"?\"), document_pro)))\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    question_count_con = np.array(list(map(lambda x: x.count(\"?\"), document_con)))\n",
    "    \n",
    "    return question_count_pro, question_count_con\n",
    "    \n",
    "    \n",
    "def get_reference_website(document_side, vectorizer):\n",
    "    \n",
    "    document_pro = document_side[:, 0]\n",
    "    website_count_pro = np.array(list(map(lambda x: x.count(\"http\"), document_pro)))\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    website_count_con = np.array(list(map(lambda x: x.count(\"http\"), document_con)))\n",
    "    \n",
    "    return website_count_pro, website_count_con\n",
    "\n",
    "def get_exclamation(document_side, vectorizer):\n",
    "    \n",
    "    document_pro = document_side[:, 0]\n",
    "    exclamation_count_pro = np.array(list(map(lambda x: x.count(\"!\"), document_pro)))\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    exclamation_count_con = np.array(list(map(lambda x: x.count(\"!\"), document_con)))\n",
    "    \n",
    "    return exclamation_count_pro, exclamation_count_con\n",
    "\n",
    "def get_number(document_side, vectorizer):\n",
    "    \n",
    "    unigram = unigram_vectorizer.get_feature_names()\n",
    "    vector_number = list(map(lambda x: int(x[0].isnumeric()), unigram))\n",
    "    matrix_number = np.reshape(vector_number, newshape=[-1, 1])\n",
    "\n",
    "    document_pro = document_side[:, 0]\n",
    "    unigram_pro = vectorizer.transform(document_pro)\n",
    "    number_pro = unigram_pro @ matrix_number\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    unigram_con = vectorizer.transform(document_con)\n",
    "    number_con = unigram_con @ matrix_number\n",
    "    \n",
    "    return number_pro, number_con\n",
    "\n",
    "def get_modal_verb(document_side, vectorizer):\n",
    "    modal_verbs = set([\"can\", \"could\", \"may\", \"might\", \"shall\", \"should\", \"will\", \"would\", \"must\"])\n",
    "    \n",
    "    unigram = unigram_vectorizer.get_feature_names()\n",
    "    vector_modal_verb = list(map(lambda x: int(x in modal_verbs), unigram))\n",
    "    matrix_modal_verb = np.reshape(vector_modal_verb, newshape=[-1, 1])\n",
    "\n",
    "    document_pro = document_side[:, 0]\n",
    "    unigram_pro = vectorizer.transform(document_pro)\n",
    "    modal_verb_pro = unigram_pro @ matrix_modal_verb\n",
    "\n",
    "    document_con = document_side[:, 1]\n",
    "    unigram_con = vectorizer.transform(document_con)\n",
    "    modal_verb_con = unigram_con @ matrix_modal_verb\n",
    "    \n",
    "    return modal_verb_pro, modal_verb_con\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "spell.existing(\"I'm not sleapy and tehre is no place I'm giong to.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_modal_verb(document_side, unigram_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jsonl(path):\n",
    "\n",
    "    with open(path) as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    data_list = []\n",
    "    for json_str in json_list:\n",
    "        data_list.append(json.loads(json_str))\n",
    "\n",
    "    return pd.DataFrame(data_list)\n",
    "def get_texts(df):\n",
    "    '''\n",
    "    Return a list of statements in df without differentiating the side of the speaker\n",
    "    '''\n",
    "\n",
    "    texts = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round:\n",
    "                texts.append(speech['text'])\n",
    "\n",
    "    return texts\n",
    "\n",
    "def get_text_by_side(df): \n",
    "    '''\n",
    "    Return a list of documents where each document contains all text on one side in a \n",
    "    single debate\n",
    "    \n",
    "    text = [[Pro statement 1, Pro statement 2, ... Pro statement n],\n",
    "            [Con statement 1, Con statement 2, ... Con statement m]]\n",
    "            where n, m is the total number of statements from Pro and Con side across\n",
    "            all debates\n",
    "\n",
    "    size: [n x 2 x # statements in each debate]\n",
    "    '''\n",
    "\n",
    "    text = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        round_text = collections.defaultdict(list)\n",
    "\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round: \n",
    "                round_text[speech['side']].append(speech['text'])\n",
    "\n",
    "        \n",
    "        text.append([\"\".join(round_text['Pro']), \"\".join(round_text['Con'])])\n",
    "\n",
    "    return np.array(text)\n",
    "\n",
    "def get_ngram_feature(document_side, vectorizer): \n",
    "    '''\n",
    "    Return the ngram features associated with a single debate\n",
    "\n",
    "    For pro side, each document is defined as a string that contains all the statements \n",
    "    from the pro side in a single debate (across different subrounds). Con side is \n",
    "    similarly defined. \n",
    "\n",
    "    return [[Pro side n gram vector, Con side n gram vector for 1 debate],\n",
    "            [Pro side n gram vector, Con side n gram vector for 2 debate],\n",
    "            ...]\n",
    "\n",
    "            size: [n, 2 x ngram count]\n",
    "    \n",
    "    Pro side and con side n gram vector are concatenated.\n",
    "    '''\n",
    "\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "\n",
    "    pro_feature = vectorizer.transform(pro_document)\n",
    "    con_feature = vectorizer.transform(con_document)\n",
    "    return sparse.hstack([pro_feature, con_feature])   \n",
    "\n",
    "def get_debate_feature(df):\n",
    "    '''\n",
    "    Return the debate feature such as category, pro_debator user name, etc\n",
    "\n",
    "    feature: [n, # of features] \n",
    "    '''\n",
    "    feature_name = ['category']\n",
    "    feature = []\n",
    "\n",
    "    for name in feature_name: \n",
    "        # TODO: check for data type of the column. If non-numeric, then do this\n",
    "        # otherwise, use the numerical data\n",
    "        encoding, unique_feature_val = pd.factorize(df[name])\n",
    "        feature.append(encoding)\n",
    "\n",
    "    return np.reshape(np.array(feature), [-1, len(feature_name)])\n",
    "\n",
    "def get_connotation_feature(document_side, matrix_connotation, vectorizer):\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "    \n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    \n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    \n",
    "    return np.hstack([feature_pro, feature_con])\n",
    "\n",
    "def get_connotation_percentage_feature(document_side, matrix_connotation, vectorizer):\n",
    "    # create features where count of features are percentage points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    total_feature_count = np.reshape(np.sum(feature_pro, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_pro = np.divide(feature_pro, total_feature_count)\n",
    "    feature_pct_pro[np.isneginf(feature_pct_pro)]=0\n",
    "    feature_pct_pro[np.isnan(feature_pct_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 1]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    total_feature_count = np.reshape(np.sum(feature_con, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_con = np.divide(feature_con, total_feature_count)\n",
    "    feature_pct_con[np.isneginf(feature_pct_con)]=0\n",
    "    feature_pct_con[np.isnan(feature_pct_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_pct_pro, feature_pct_con])\n",
    "\n",
    "def get_connotation_ln_feature(document_side, matrix_connotation, vectorizer):\n",
    "    # create features where count of features are ln points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_connotation\n",
    "    feature_ln_pro = np.log(feature_pro)\n",
    "    feature_ln_pro[np.isneginf(feature_ln_pro)]=0\n",
    "    feature_ln_pro[np.isnan(feature_ln_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 0]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_connotation\n",
    "    feature_ln_con = np.log(feature_con)\n",
    "    feature_ln_con[np.isneginf(feature_ln_con)]=0\n",
    "    feature_ln_con[np.isnan(feature_ln_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_ln_pro, feature_ln_con])\n",
    "\n",
    "\n",
    "def get_vad_feature(document_side, matrix_vad, vectorizer):\n",
    "    pro_document = document_side[:, 0]\n",
    "    con_document = document_side[:, 1]\n",
    "    \n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    \n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    \n",
    "    return np.hstack([feature_pro, feature_con])\n",
    "\n",
    "def get_vad_percentage_feature(document_side, matrix_vad, vectorizer):\n",
    "    # create features where count of features are percentage points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    total_feature_count = np.reshape(np.sum(feature_pro, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_pro = np.divide(feature_pro, total_feature_count)\n",
    "    feature_pct_pro[np.isneginf(feature_pct_pro)]=0\n",
    "    feature_pct_pro[np.isnan(feature_pct_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 1]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    total_feature_count = np.reshape(np.sum(feature_con, axis=1), newshape=(-1, 1))\n",
    "    feature_pct_con = np.divide(feature_con, total_feature_count)\n",
    "    feature_pct_con[np.isneginf(feature_pct_con)]=0\n",
    "    feature_pct_con[np.isnan(feature_pct_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_pct_pro, feature_pct_con])\n",
    "\n",
    "def get_vad_ln_feature(document_side, matrix_vad, vectorizer):\n",
    "    # create features where count of features are ln points \n",
    "    pro_document = document_side[:, 0]\n",
    "    gram_pro = vectorizer.transform(pro_document)\n",
    "    feature_pro = gram_pro @ matrix_vad\n",
    "    feature_ln_pro = np.log(feature_pro)\n",
    "    feature_ln_pro[np.isneginf(feature_ln_pro)]=0\n",
    "    feature_ln_pro[np.isnan(feature_ln_pro)]=0\n",
    "    \n",
    "    con_document = document_side[:, 0]\n",
    "    gram_con = vectorizer.transform(con_document)\n",
    "    feature_con = gram_con @ matrix_vad\n",
    "    feature_ln_con = np.log(feature_con)\n",
    "    feature_ln_con[np.isneginf(feature_ln_con)]=0\n",
    "    feature_ln_con[np.isnan(feature_ln_con)]=0\n",
    "    \n",
    "    return np.hstack([feature_ln_pro, feature_ln_con])\n",
    "\n",
    "def get_winner(df): \n",
    "    '''\n",
    "    Cons gets mapped to 0 and pro gets mapped to 1\n",
    "    '''\n",
    "    return df.loc[:, \"winner\"].replace({\"Con\": 0, \"Pro\": 1})\n",
    "\n",
    "def get_all_feature_label(df, vectorizer):\n",
    "    '''\n",
    "    Return the training input and validation input that contains all features, \n",
    "    which are ngram features and debate features\n",
    "    '''\n",
    "    \n",
    "    # Getting two sets of features - ngram and debate related features\n",
    "    ngram_feature = get_ngram_feature(df, vectorizer)\n",
    "\n",
    "    # debate_feature = get_debate_feature(df)\n",
    "\n",
    "    # Combining two sets of features\n",
    "    # X = sparse.hstack([debate_feature, ngram_feature])\n",
    "    X = sparse.hstack([ngram_feature])\n",
    "\n",
    "    y = np.array(get_winner(df))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - lex feature, debate feature, n-gram feature\n",
    "This model should use\n",
    "1. word ngrams\n",
    "2. lexicon based features: implement lexicon based features for a lexicon of your choice\n",
    "   1. Connotation lexicon\n",
    "   2. NRC-VAD lexicon\n",
    "   3. How you extract features is part of the desgin decision that you need to make. One simple example for lexical features could be counting how many words in each debaters language appear in the corresponding lexicon. \n",
    "\n",
    "TODO: \n",
    "1. Read connotation - 1 file\n",
    "2. NRC features - 2 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read connotation - 1 file\n",
    "# 2. NRC features - 2 files \n",
    "CONNOTATION = \"./resources/lexica/connotation_lexicon_a.0.1.csv\"\n",
    "NRC_LEXICON_VAD = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/NRC-VAD-Lexicon.txt\"\n",
    "NRC_LEXICON_SORTED_VALENCE = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/v-scores.txt\"\n",
    "NRC_LEXICON_SORTED_AROUSAL = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/a-scores.txt\"\n",
    "NRC_LEXICON_SORTED_DOMINANCE = \"./resources/lexica/NRC-VAD-Lexicon-Aug2018Release/OneFilePerDimension/d-scores.txt\"\n",
    "\n",
    "df_connotation = pd.read_csv(CONNOTATION, sep=\",|_\", header=None)\n",
    "df_connotation.columns = [\"word\", \"pos\", \"connotation\"] # word, part of speech, connotation\n",
    "df_connotation = df_connotation.dropna() # There are five words in the connotation that are nan \n",
    "df_connotation = df_connotation.set_index(\"word\")\n",
    "df_connotation[\"pos\"] = df_connotation[\"pos\"].astype('category')\n",
    "df_connotation = df_connotation.drop(columns=[\"pos\"]) # drop the part of speech classification because we can't use it now \n",
    "df_connotation[\"connotation\"] = df_connotation[\"connotation\"].astype('category')\n",
    "df_connotation = pd.get_dummies(df_connotation)\n",
    "\n",
    "df_nrc_vad = pd.read_csv(NRC_LEXICON_VAD, sep=\"\t\", header=None)\n",
    "df_nrc_vad.columns = [\"word\", \"valence\", \"arousal\", \"dominance\"]\n",
    "df_nrc_vad = df_nrc_vad.dropna()\n",
    "df_nrc_vad = df_nrc_vad.set_index(\"word\")\n",
    "df_nrc_vad[\"valence\"] = df_nrc_vad[\"valence\"].astype('category')\n",
    "df_nrc_vad[\"arousal\"] = df_nrc_vad[\"arousal\"].astype('category')\n",
    "df_nrc_vad[\"dominance\"] = df_nrc_vad[\"dominance\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, min_df=0.2, ngram_range=(1, 3),\n",
       "                stop_words='english', sublinear_tf=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get features and labels for traininig and validation \n",
    "unigram_vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate the corpus for vectotrizer to fit on \n",
    "document_train_side = get_text_by_side(df_train)\n",
    "document_val_side = get_text_by_side(df_val)\n",
    "document_train = [side[0] + side[1] for side in document_train_side]\n",
    "document_val = [side[0] + side[1] for side in document_val_side]\n",
    "\n",
    "# The vectorizer trains all all the textual corpus regardless of the side \n",
    "# of the debate \n",
    "unigram_vectorizer.fit(document_train)\n",
    "\n",
    "# Get the feature vector of a sentence using ngram @ matrix_connotation\n",
    "# Creating the matrix \n",
    "word_connotation = df_connotation.index\n",
    "word_vector_connotation = unigram_vectorizer.transform(word_connotation)\n",
    "matrix_connotation = word_vector_connotation.T @ df_connotation\n",
    "matrix_connotation_no_neutral = word_vector_connotation.T @ df_connotation.drop(columns=[\"connotation_neutral\"])\n",
    "\n",
    "word_vad = df_nrc_vad.index\n",
    "word_vector_vad = unigram_vectorizer.transform(word_vad)\n",
    "matrix_vad = word_vector_vad.T @ df_nrc_vad\n",
    "# For words with mulitple part of speech, we are counting the total\n",
    "# sum across all part of speech of that word for each feature \n",
    "\n",
    "# Get label \n",
    "label_train = get_winner(df_train)\n",
    "label_val = get_winner(df_val)\n",
    "\n",
    "y_train = np.array(label_train)\n",
    "y_val = np.array(label_val)\n",
    "\n",
    "# Get more grams \n",
    "trigram_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0.2, stop_words='english', ngram_range=(1,3))\n",
    "trigram_vectorizer.fit(document_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== you can run experiments here ======================\n",
    "# Get all TRAINING features:\n",
    "# Get the documents on pro and con side so that we can forming feature \n",
    "# vector on both sides for training \n",
    "\n",
    "trigram_train = get_ngram_feature(document_side=document_train_side, vectorizer=trigram_vectorizer)\n",
    "# ============= using raw number counts of the feature ==========================\n",
    "# feature_connotation_train = get_connotation_feature(document_side=document_train_side,\n",
    "#                                                         matrix_connotation=matrix_connotation,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_vad_train = get_vad_feature(document_side=document_train_side,\n",
    "#                                                         matrix_vad=matrix_vad,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_train, \n",
    "#                     feature_vad_train])\n",
    "\n",
    "# ============= using percentage counts of the feature ==========================\n",
    "# feature_connotation_pct_train = get_connotation_percentage_feature(document_train_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_pct_train = get_vad_percentage_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "#                     feature_vad_pct_train])\n",
    "\n",
    "# ============= using log counts of the feature ==========================\n",
    "# feature_connotation_ln_train = get_connotation_ln_feature(document_train_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_ln_train = get_vad_ln_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_ln_train, \n",
    "#                     feature_vad_ln_train])\n",
    "\n",
    "# ============= using percentage counts of the feature without neutral connotation ==========================\n",
    "feature_connotation_pct_train = get_connotation_percentage_feature(document_train_side, matrix_connotation_no_neutral, unigram_vectorizer)\n",
    "feature_vad_pct_train = get_vad_percentage_feature(document_train_side, matrix_vad, unigram_vectorizer)\n",
    "feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "                    feature_vad_pct_train])\n",
    "\n",
    "# Get all VALIDATION features:\n",
    "trigram_val = get_ngram_feature(document_side=document_val_side, vectorizer=trigram_vectorizer)\n",
    "# ============= using raw counts of of the feature ==========================\n",
    "# feature_connotation_val = get_connotation_feature(document_side=document_val_side,\n",
    "#                                                         matrix_connotation=matrix_connotation,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_vad_val = get_vad_feature(document_side=document_val_side,\n",
    "#                                                         matrix_vad=matrix_vad,\n",
    "#                                                         vectorizer=unigram_vectorizer)\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_val, \n",
    "#                     feature_vad_val])\n",
    "\n",
    "# ============= using percentage count of of the feature ==========================\n",
    "# feature_connotation_pct_val = get_connotation_percentage_feature(document_val_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_pct_val = get_vad_percentage_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "# feature_train = sparse.hstack([trigram_train, feature_connotation_pct_train, \n",
    "#                     feature_vad_pct_train])\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_pct_val, \n",
    "#                     feature_vad_pct_val])\n",
    "\n",
    "# ============= using log counts of the feature ==========================\n",
    "# feature_connotation_ln_val = get_connotation_ln_feature(document_val_side, matrix_connotation, unigram_vectorizer)\n",
    "# feature_vad_ln_val = get_vad_ln_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "\n",
    "# feature_val = sparse.hstack([trigram_val, feature_connotation_ln_val, \n",
    "#                     feature_vad_ln_val])\n",
    "\n",
    "# ============= using percentage counts of the feature without neutral connotation ==========================\n",
    "feature_connotation_pct_val = get_connotation_percentage_feature(document_val_side, matrix_connotation_no_neutral, unigram_vectorizer)\n",
    "feature_vad_pct_val = get_vad_percentage_feature(document_val_side, matrix_vad, unigram_vectorizer)\n",
    "\n",
    "feature_val = sparse.hstack([trigram_val, feature_connotation_pct_val, \n",
    "                    feature_vad_pct_val])\n",
    "\n",
    "# Create model\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(feature_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train, clf.predict(feature_train)))\n",
    "print(classification_report(y_val, clf.predict(feature_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Here is the model that only uses debate features and ngram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting texts from training and testing data\n",
    "label_train = get_winner(df_train)\n",
    "label_val = get_winner(df_val)\n",
    "\n",
    "# Generate the corpus \n",
    "document_train = get_text_by_side(df_train)\n",
    "document_val = get_text_by_side(df_val)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.9, min_df=0.1, stop_words='english', ngram_range=(1,3))\n",
    "vectorizer.fit(document_train)\n",
    "\n",
    "# Getting two sets of features - ngram and debate related features\n",
    "ngram_feature_train = get_ngram_feature(df_train, vectorizer)\n",
    "ngram_feature_val = get_ngram_feature(df_val, vectorizer)\n",
    "\n",
    "debate_feature_train = get_debate_feature(df_train)\n",
    "debate_feture_val = get_debate_feature(df_val)\n",
    "\n",
    "# Combining two sets of features\n",
    "X_train = sparse.hstack([debate_feature_train, ngram_feature_train])\n",
    "X_val = sparse.hstack([debate_feture_val, ngram_feature_val])\n",
    "\n",
    "y_train = np.array(label_train)\n",
    "y_val = np.array(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sanity check')\n",
    "print(df_train.shape[0], 'number of observations in the training set')\n",
    "print(X_train.shape, 'number of observation x the size of ngram vectors in the training set')\n",
    "print(y_train.shape, 'number of labels in the training set')\n",
    "print(df_val.shape[0], 'number of observations in the validation set')\n",
    "print(X_val.shape, 'number of observation x the size of ngram vectors in the validation set')\n",
    "print(y_val.shape, 'number of labels in the validation set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training the model\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "clf.fit(ngram_feature_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression training set report:\")\n",
    "print(classification_report(y_train, clf.predict(ngram_feature_train), target_names=['Pro', 'Con']))\n",
    "print(classification_report(y_val, clf.predict(ngram_feature_val), target_names=['Pro', 'Con']))\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the validation set\n",
    "y_predicted = clf.predict(X_val_religion)\n",
    "print(\"Logistic Regression testing set report:\")\n",
    "print(classification_report(y_val_religion, y_predicted, target_names=['Pro', 'Con']))\n",
    "\n",
    "print(\"Accuracy score: \",accuracy_score(y_val_religion, y_predicted))\n",
    "print(\"Balanced accuracy score: \",accuracy_score(y_val_religion, y_predicted))\n",
    "\n",
    "plot_confusion_matrix(clf, X_val, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning ngram models over max_df and min_df\n",
    "def search_max_df_min_df(df_train, df_val):\n",
    "    highest_acc, best_min_df, best_max_df = 0, -1, -1\n",
    "    report = {}\n",
    "    for min_df in np.arange(0, 1, 0.1):\n",
    "        for diff in np.arange(0.1, 1 - min_df, 0.1):\n",
    "            max_df = min_df + diff\n",
    "\n",
    "            vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=max_df, min_df=min_df, stop_words='english', ngram_range=(1,3))\n",
    "            document_train = get_text_by_side(df_train)\n",
    "            vectorizer.fit(document_train)\n",
    "            X_train, y_train = get_all_feature_label(df_train, vectorizer)\n",
    "            X_val, y_val = get_all_feature_label(df_val, vectorizer)\n",
    "\n",
    "            clf = sklearn.linear_model.LogisticRegression()\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"====================================\")\n",
    "\n",
    "            y_predicted = clf.predict(X_val)\n",
    "            print(\"Logistic Regression testing set report:\")\n",
    "            report[(min_df, max_df)] = classification_report(y_val, y_predicted, target_names=['Pro', 'Con'], output_dict=True)\n",
    "            acc = accuracy_score(y_val, y_predicted)\n",
    "\n",
    "            print(\"max_df: {}, min_df: {}, accuracy: {}\".format(max_df, min_df, acc))\n",
    "\n",
    "            if acc > highest_acc:\n",
    "                highest_acc, best_min_df, best_max_df = acc, min_df, max_df\n",
    "\n",
    "    print(\"************ best min_df, best max_df, acc\", best_min_df, best_max_df, highest_acc)\n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "max_acc, best_min_df, best_max_df = 0, -1, -1\n",
    "gram3_report = report\n",
    "\n",
    "for key, val in report.items():\n",
    "    print(\"====================\")\n",
    "    print(key)\n",
    "    print(val)\n",
    "\n",
    "# The best min df and the best max df are (0.2, 0.8) with validation accuracy of 0.76\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of achieving this is to create two n-gram models. One n-gram model outputs features\n",
    "for religious topics and another n-gram model outputs features for non-religious topics.\n",
    "By limiting the corpus within their topics, the Tf_idf scores may better reflect the \n",
    "proper weighting. For example, certain words that might only appear in winning relgious debates\n",
    "but also appear in all other losing debates may now have a significantly different score from \n",
    "words that appear in only losing religous debates but appear in all other winning debates. \n",
    "Previously, these two sets of words would have similar tf_idf score but are not helpful \n",
    "towards predicting winning debates because their prediciton power within relgious topic is\n",
    "diluted by the non-religous topics. By limiting the corpus scope, we can see that these \n",
    "words become helpful in both religous and non-relgious debates.\n",
    "\n",
    "TODO:\n",
    "1. Define a Tfidfvectorizer for both religous and non-religious topics\n",
    "2. Train the vectorizer using their respective subsets\n",
    "3. Depending the topic of the new data, we should use the two models conditionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data sets\n",
    "df_train_religion = df_train.loc[df_train.category == \"Religion\" ,:]\n",
    "df_train_other = df_train.loc[df_train.category != \"Religion\" ,:]\n",
    "df_val_religion = df_val.loc[df_val.category == \"Religion\" ,:]\n",
    "df_val_other = df_val.loc[df_val.category != \"Religion\" ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sanity check\")\n",
    "print(df_train_religious.shape)\n",
    "print(df_train_other.shape)\n",
    "print(df_train.shape)\n",
    "print(\"validation set\")\n",
    "print(df_val_religious.shape)\n",
    "print(df_val_other.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_religion.shape)\n",
    "print(X_val_religion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_max_df_min_df(df_train_religion, df_val_religion)\n",
    "search_max_df_min_df(df_train_other, df_val_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the vectorizer\n",
    "vectorizer_religion = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0, stop_words='english', ngram_range=(1,3))\n",
    "document_train_religion = get_text_by_side(df_train_religion)\n",
    "vectorizer_religion.fit(document_train_religion)\n",
    "X_train_religion, y_train_religion = get_all_feature_label(df_train_religion, vectorizer_religion)\n",
    "X_val_religion, y_val_religion = get_all_feature_label(df_val_religion, vectorizer_religion)\n",
    "report_religion = search_max_df_min_df(X_train_religion, y_train_religion, X_val_religion, y_val_religion)\n",
    "\n",
    "vectorizer_other = TfidfVectorizer(sublinear_tf=True, max_df=0.8, min_df=0, stop_words='english', ngram_range=(1,3))\n",
    "document_train_other = get_text_by_side(df_train_other)\n",
    "vectorizer_other.fit(document_train_other)\n",
    "X_train_other, y_train_other = get_all_feature_label(df_train_other, vectorizer_other)\n",
    "X_val_other, y_val_other = get_all_feature_label(df_val_other, vectorizer_other)\n",
    "report_other = search_max_df_min_df(X_train_other, y_train_other, X_val_other, y_val_other)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f78e94ca1a29e9011c2866c841de859bf08fcc5b57f07b9ffb161018ea406f8e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}