{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff39984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from numpy.lib.function_base import vectorize\n",
    "import pandas as pd \n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy import sparse\n",
    "from scipy.spatial import distance\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from better_profanity import profanity\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d1c1dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading user  data \n",
    "\n",
    "# loading training data .jsonl\n",
    "TRAINING_DATA = './resources/data/train.jsonl'\n",
    "VAL_DATA = './resources/data/val.jsonl'\n",
    "\n",
    "df_train, df_val = pd.read_json(TRAINING_DATA, lines=True), pd.read_json(VAL_DATA, lines=True)\n",
    "USER_DATA = './resources/data/users.json'\n",
    "df_user = pd.read_json(USER_DATA, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "81302e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "306\n",
      "(399, 9)\n"
     ]
    }
   ],
   "source": [
    "print(sum(df_val.category == 'Religion'))\n",
    "print(sum(df_val.category != 'Religion'))\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea0960fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_side(df): \n",
    "    '''\n",
    "    Return a list of documents where each document contains all text on one side in a \n",
    "    single debate\n",
    "    \n",
    "    text = [[Pro statement 1, Pro statement 2, ... Pro statement n],\n",
    "            [Con statement 1, Con statement 2, ... Con statement m]]\n",
    "            where n, m is the total number of statements from Pro and Con side across\n",
    "            all debates\n",
    "\n",
    "    size: [n x 2 x # statements in each debate]\n",
    "    '''\n",
    "\n",
    "    text = []\n",
    "    for round in df.loc[:, 'rounds']:\n",
    "        round_text = collections.defaultdict(list)\n",
    "\n",
    "        for sub_round in round:\n",
    "            for speech in sub_round: \n",
    "                round_text[speech['side']].append(speech['text'])\n",
    "\n",
    "        \n",
    "        text.append([\"\".join(round_text['Pro']), \"\".join(round_text['Con'])])\n",
    "\n",
    "    return np.array(text)\n",
    "    \n",
    "countrape = []\n",
    "for doc in get_text_by_side(df_train):\n",
    "    countrape.append([doc[0].count('stupid'), doc[1].count('stupid')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19692f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>rounds</th>\n",
       "      <th>date</th>\n",
       "      <th>pro_debater</th>\n",
       "      <th>con_debater</th>\n",
       "      <th>voters</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>The-debate.org-site-rules-should-be-more-stric...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>The debate.org site rules should be more stric...</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \n",
       "  The debate.or...</td>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>RoyLatham</td>\n",
       "      <td>imabench</td>\n",
       "      <td>[Juris_Naturalis, PeriodicPatriot, bsh1, Garre...</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Legend-of-the-Seeker-stays-true-to-The-Sword-o...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Legend of the Seeker stays true to The Sword o...</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "The Legend of ...</td>\n",
       "      <td>2009-10-29</td>\n",
       "      <td>Seekeroftruth469</td>\n",
       "      <td>Ragnar_Rahl</td>\n",
       "      <td>[aoibhinn, Marauder, Xer, wonderwoman, Seekero...</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>The-10-commandments-are-a-JOKE/1/</td>\n",
       "      <td>Religion</td>\n",
       "      <td>The 10 commandments are a JOKE!</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \n",
       "  Thankfully th...</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>backwardseden</td>\n",
       "      <td>BrianCBiggs</td>\n",
       "      <td>[Khons, DNehlsen]</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>god-is-not-one-therefore-god-is-a-fraud/1/</td>\n",
       "      <td>Religion</td>\n",
       "      <td>god is not \"one\" therefore god is a fraud</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \n",
       "  Genesis 1:26 ...</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>backwardseden</td>\n",
       "      <td>wmickas</td>\n",
       "      <td>[DNehlsen, dsjpk5]</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Tell-me-your-thoughts-on-Abortion./1/</td>\n",
       "      <td>Society</td>\n",
       "      <td>Tell me your thoughts on Abortion.</td>\n",
       "      <td>[[{'side': 'Con', 'text': '\n",
       "  \r\n",
       "I feel that ab...</td>\n",
       "      <td>2007-12-18</td>\n",
       "      <td>Kasrahalteth</td>\n",
       "      <td>tjzimmer</td>\n",
       "      <td>[Mharman, indianajones644, adamh, griffinisrig...</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Abortion/53/</td>\n",
       "      <td>Society</td>\n",
       "      <td>Abortion</td>\n",
       "      <td>[[{'side': 'Con', 'text': '\n",
       "  \r\n",
       "I, con, will a...</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>tkubok</td>\n",
       "      <td>TysonMarshall</td>\n",
       "      <td>[wiseovvl, simplymara, Rasliel, cmahdavi, Deaf...</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Term-Lengths-and-Limitations/1/</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Term Lengths and Limitations</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "I thank my opp...</td>\n",
       "      <td>2009-01-18</td>\n",
       "      <td>crackofdawn_Jr</td>\n",
       "      <td>JBlake</td>\n",
       "      <td>[crackofdawn_Jr, JBlake, RoyLatham]</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>macroevolution-of-humans-has-stopped-for-the-f...</td>\n",
       "      <td>Science</td>\n",
       "      <td>macroevolution of humans has stopped for the f...</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "macroevolution...</td>\n",
       "      <td>2014-07-29</td>\n",
       "      <td>linate</td>\n",
       "      <td>FMAlchemist</td>\n",
       "      <td>[gt4o2007, SamStevens, Sagey, birdlandmemories]</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Racists-are-ignorant-and-are-purely-stupid./1/</td>\n",
       "      <td>Society</td>\n",
       "      <td>Racist's are ignorant and are purely stupid.</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "Racists have n...</td>\n",
       "      <td>2010-03-27</td>\n",
       "      <td>wells5674</td>\n",
       "      <td>Koopin</td>\n",
       "      <td>[wonderwoman, twin, Marauder, belle, Koopin]</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Is-Google-Making-Us-Stupid/1/</td>\n",
       "      <td>Education</td>\n",
       "      <td>Is Google Making Us Stupid?</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "Hi this was an...</td>\n",
       "      <td>2009-05-24</td>\n",
       "      <td>luxx</td>\n",
       "      <td>alto2osu</td>\n",
       "      <td>[thisoneguy, alto2osu, philosphical, Maikuru, ...</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1                                                 id  \\\n",
       "603   19  24  The-debate.org-site-rules-should-be-more-stric...   \n",
       "980    5   4  Legend-of-the-Seeker-stays-true-to-The-Sword-o...   \n",
       "331    4   1                  The-10-commandments-are-a-JOKE/1/   \n",
       "340    4   1         god-is-not-one-therefore-god-is-a-fraud/1/   \n",
       "1076   4   0              Tell-me-your-thoughts-on-Abortion./1/   \n",
       "1118   4   0                                       Abortion/53/   \n",
       "982    3   1                    Term-Lengths-and-Limitations/1/   \n",
       "1207   3   1  macroevolution-of-humans-has-stopped-for-the-f...   \n",
       "1223   3   1     Racists-are-ignorant-and-are-purely-stupid./1/   \n",
       "984    2   6                      Is-Google-Making-Us-Stupid/1/   \n",
       "\n",
       "           category                                              title  \\\n",
       "603   Miscellaneous  The debate.org site rules should be more stric...   \n",
       "980   Entertainment  Legend of the Seeker stays true to The Sword o...   \n",
       "331        Religion                    The 10 commandments are a JOKE!   \n",
       "340        Religion          god is not \"one\" therefore god is a fraud   \n",
       "1076        Society                 Tell me your thoughts on Abortion.   \n",
       "1118        Society                                           Abortion   \n",
       "982        Politics                       Term Lengths and Limitations   \n",
       "1207        Science  macroevolution of humans has stopped for the f...   \n",
       "1223        Society       Racist's are ignorant and are purely stupid.   \n",
       "984       Education                        Is Google Making Us Stupid?   \n",
       "\n",
       "                                                 rounds       date  \\\n",
       "603   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "  The debate.or... 2014-01-20   \n",
       "980   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "The Legend of ... 2009-10-29   \n",
       "331   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "  Thankfully th... 2017-08-20   \n",
       "340   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "  Genesis 1:26 ... 2017-09-30   \n",
       "1076  [[{'side': 'Con', 'text': '\n",
       "  \n",
       "I feel that ab... 2007-12-18   \n",
       "1118  [[{'side': 'Con', 'text': '\n",
       "  \n",
       "I, con, will a... 2010-01-29   \n",
       "982   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "I thank my opp... 2009-01-18   \n",
       "1207  [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "macroevolution... 2014-07-29   \n",
       "1223  [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "Racists have n... 2010-03-27   \n",
       "984   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "Hi this was an... 2009-05-24   \n",
       "\n",
       "           pro_debater    con_debater  \\\n",
       "603          RoyLatham       imabench   \n",
       "980   Seekeroftruth469    Ragnar_Rahl   \n",
       "331      backwardseden    BrianCBiggs   \n",
       "340      backwardseden        wmickas   \n",
       "1076      Kasrahalteth       tjzimmer   \n",
       "1118            tkubok  TysonMarshall   \n",
       "982     crackofdawn_Jr         JBlake   \n",
       "1207            linate    FMAlchemist   \n",
       "1223         wells5674         Koopin   \n",
       "984               luxx       alto2osu   \n",
       "\n",
       "                                                 voters winner  \n",
       "603   [Juris_Naturalis, PeriodicPatriot, bsh1, Garre...    Pro  \n",
       "980   [aoibhinn, Marauder, Xer, wonderwoman, Seekero...    Con  \n",
       "331                                   [Khons, DNehlsen]    Con  \n",
       "340                                  [DNehlsen, dsjpk5]    Con  \n",
       "1076  [Mharman, indianajones644, adamh, griffinisrig...    Con  \n",
       "1118  [wiseovvl, simplymara, Rasliel, cmahdavi, Deaf...    Pro  \n",
       "982                 [crackofdawn_Jr, JBlake, RoyLatham]    Con  \n",
       "1207    [gt4o2007, SamStevens, Sagey, birdlandmemories]    Con  \n",
       "1223       [wonderwoman, twin, Marauder, belle, Koopin]    Con  \n",
       "984   [thisoneguy, alto2osu, philosphical, Maikuru, ...    Con  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.DataFrame(countrape), df_train], axis=1).sort_values(by=[0, 1], ascending=False).head(10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3236ad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrll}\n",
      "\\toprule\n",
      "{} &   0 &   1 &                                              title & winner \\\\\n",
      "\\midrule\n",
      "603  &  19 &  24 &  The debate.org site rules should be more stric... &    Pro \\\\\n",
      "980  &   5 &   4 &  Legend of the Seeker stays true to The Sword o... &    Con \\\\\n",
      "331  &   4 &   1 &                    The 10 commandments are a JOKE! &    Con \\\\\n",
      "340  &   4 &   1 &          god is not \"one\" therefore god is a fraud &    Con \\\\\n",
      "1076 &   4 &   0 &                 Tell me your thoughts on Abortion. &    Con \\\\\n",
      "1118 &   4 &   0 &                                           Abortion &    Pro \\\\\n",
      "982  &   3 &   1 &                       Term Lengths and Limitations &    Con \\\\\n",
      "1207 &   3 &   1 &  macroevolution of humans has stopped for the f... &    Con \\\\\n",
      "1223 &   3 &   1 &       Racist's are ignorant and are purely stupid. &    Con \\\\\n",
      "984  &   2 &   6 &                        Is Google Making Us Stupid? &    Con \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.drop(columns=['voters', 'rounds', 'id', 'date', 'pro_debater', 'con_debater', 'category']).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7ab7a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.75       0.         0.25      ]\n",
      " [0.85714286 0.14285714 0.         0.71428571 0.14285714 0.14285714]\n",
      " [0.75       0.0625     0.1875     0.75       0.0625     0.1875    ]\n",
      " ...\n",
      " [1.         0.         0.         0.66666667 0.         0.33333333]\n",
      " [0.66666667 0.22222222 0.11111111 0.44444444 0.22222222 0.33333333]\n",
      " [1.         0.         0.         0.33333333 0.         0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "class Transformer_get_political_align(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.category = list(set(df_user.political_ideology))\n",
    "        self.religous_type = CategoricalDtype(self.category, ordered=True)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        df = df\n",
    "        voters_political = df.loc[:, 'voters'].apply(self.get_political_voters)\n",
    "        \n",
    "        pro_political = df.loc[:, 'pro_debater'].apply(self.get_political)\n",
    "        pro_political_align = pd.DataFrame({'user_political': pro_political,\n",
    "                                           'voters_political': voters_political}).apply(self.get_match_political, \n",
    "                                                                                       axis=1)\n",
    "        \n",
    "        con_political = df.loc[:, 'con_debater'].apply(self.get_political)\n",
    "        con_political_align = pd.DataFrame({'user_political': con_political,\n",
    "                                           'voters_political': voters_political}).apply(self.get_match_political,\n",
    "                                                                                       axis=1)\n",
    "        \n",
    "        return np.hstack([np.vstack(pro_political_align.values), np.vstack(con_political_align.values)])\n",
    "        \n",
    "        \n",
    "    def get_political(self, user): \n",
    "        user_political = df_user.loc[user, \"political_ideology\"]\n",
    "        return user_political\n",
    "\n",
    "    def get_political_voters(self, voters): \n",
    "        political_vectors = []\n",
    "        voters = np.array(voters)\n",
    "        eligible_voters = voters[list(map(lambda voter: voter in df_user.index, voters))]\n",
    "        if len(eligible_voters) > 0:\n",
    "            data = np.array(list(map(self.get_political, eligible_voters)))\n",
    "        else:\n",
    "            data = np.nan\n",
    "        return data\n",
    "\n",
    "    def get_match_political(self, row): \n",
    "        user_political, voters_political = row[\"user_political\"], row[\"voters_political\"]\n",
    "\n",
    "        if voters_political is np.nan:\n",
    "            return [0, 0, 0]\n",
    "\n",
    "        if user_political == 'Not Saying':\n",
    "            return np.array([0, 1, 0])\n",
    "\n",
    "        feature = np.array([0, 0, 0])\n",
    "        for v_r in voters_political:\n",
    "            if v_r == 'Not Saying' :\n",
    "                feature += np.array([0, 1, 0])\n",
    "            elif v_r == user_political:\n",
    "                feature += np.array([0, 0, 1])\n",
    "            else:\n",
    "                feature += np.array([1, 0, 0])\n",
    "\n",
    "        return feature / np.sum(feature)\n",
    "\n",
    "trans = Transformer_get_political_align()\n",
    "feat = trans.transform(df_train)\n",
    "print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef432983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "big_issues_dict       {'Abortion': 'Con', 'Affirmative Action': 'N/S...\n",
       "birthday                                                    - Private -\n",
       "education                                                    Not Saying\n",
       "ethnicity                                                         White\n",
       "gender                                                             Male\n",
       "friends               [Chrysippus, Deathgodxiii, Ruperttheg, grayron...\n",
       "income                                                       Not Saying\n",
       "joined                                                      9 Years Ago\n",
       "opinion_arguments                                                    []\n",
       "opinion_questions                                                    []\n",
       "party                                                             Other\n",
       "political_ideology                                                Other\n",
       "poll_topics                                                          []\n",
       "poll_votes                                                           []\n",
       "relationship                                                 Not Saying\n",
       "religious_ideology                                            Christian\n",
       "Name: Zealotical, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.loc['Zealotical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08f781a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>rounds</th>\n",
       "      <th>date</th>\n",
       "      <th>pro_debater</th>\n",
       "      <th>con_debater</th>\n",
       "      <th>voters</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>The-existence-of-free-will-as-proposed-by-the-...</td>\n",
       "      <td>Religion</td>\n",
       "      <td>The existence of free will as proposed by the ...</td>\n",
       "      <td>[[{'side': 'Con', 'text': '\n",
       "  \r\n",
       "I challenge an...</td>\n",
       "      <td>2011-06-14</td>\n",
       "      <td>KeytarHero</td>\n",
       "      <td>GOD-vs-ITSELF</td>\n",
       "      <td>[ReformedArsenal, medic0506, Cliff.Stamp]</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Medical-Marijuana/3/</td>\n",
       "      <td>Health</td>\n",
       "      <td>Medical Marijuana</td>\n",
       "      <td>[[{'side': 'Con', 'text': '\n",
       "  \r\n",
       "========  \r\n",
       "In...</td>\n",
       "      <td>2010-11-21</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>Zealotical</td>\n",
       "      <td>[Atheism, MarcL]</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Lighting-Impromptu-Debate/2/</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Lighting Impromptu Debate</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "This is a ligh...</td>\n",
       "      <td>2010-08-09</td>\n",
       "      <td>Strikeeagle84015</td>\n",
       "      <td>Grape</td>\n",
       "      <td>[I-am-a-panda, Strikeeagle84015]</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Atheism-can-not-account-for-moral-truth/1/</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Atheism can not account for moral truth</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "To start, I wa...</td>\n",
       "      <td>2011-06-23</td>\n",
       "      <td>charles15</td>\n",
       "      <td>LeoL</td>\n",
       "      <td>[Cliff.Stamp, GMDebater, RoyLatham]</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>The-Bible-doesnt-forbid-Tattoos/1/</td>\n",
       "      <td>Religion</td>\n",
       "      <td>The Bible doesn't forbid Tattoos</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "The argument i...</td>\n",
       "      <td>2013-08-02</td>\n",
       "      <td>dwmiller</td>\n",
       "      <td>wolfman4711</td>\n",
       "      <td>[GOP, Chapule]</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Standardized-Exit-Exams-Lincoln-Douglas-Format/1/</td>\n",
       "      <td>Education</td>\n",
       "      <td>Standardized Exit Exams: Lincoln-Douglas Format</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "Though I will ...</td>\n",
       "      <td>2009-10-08</td>\n",
       "      <td>alto2osu</td>\n",
       "      <td>simpleton</td>\n",
       "      <td>[insignia96, LadyHavok13, seeley.linda, Nails,...</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Singing-Challenge/1/</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Singing Challenge</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "Let's begin wi...</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>TurleDoveSammie</td>\n",
       "      <td>TUF</td>\n",
       "      <td>[ResponsiblyIrresponsible, ESocialBookworm, Ro...</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>President-Obama-should-not-have-gotten-the-maj...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>President Obama should not have gotten the maj...</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "Barack Obama s...</td>\n",
       "      <td>2013-01-21</td>\n",
       "      <td>Jester02</td>\n",
       "      <td>Deadlykris</td>\n",
       "      <td>[OhioGary, tmar19652, proglib]</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>THBT-Debate.org-should-pay-fifteen-qualified-j...</td>\n",
       "      <td>People</td>\n",
       "      <td>THBT Debate.org should pay fifteen qualified j...</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "Rounds  \n",
       "  \r\n",
       "-...</td>\n",
       "      <td>2015-05-25</td>\n",
       "      <td>Palmo10</td>\n",
       "      <td>cathaystewie</td>\n",
       "      <td>[TheJuniorVarsityNovice, F-16_Fighting_Falcon]</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>The-soul-is-not-a-real-thing/1/</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>The soul is not a real thing</td>\n",
       "      <td>[[{'side': 'Pro', 'text': '\n",
       "  \r\n",
       "I am on the si...</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>mega-antitheist</td>\n",
       "      <td>jwesbruce</td>\n",
       "      <td>[SuburbiaSurvivor, InVinoVeritas, Ron-Paul, wa...</td>\n",
       "      <td>Con</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1    2         3         4         5  \\\n",
       "287   0.000000  0.000000  1.0  0.000000  1.000000  0.000000   \n",
       "498   0.000000  0.000000  1.0  1.000000  0.000000  0.000000   \n",
       "1288  0.000000  0.000000  1.0  1.000000  0.000000  0.000000   \n",
       "1065  0.000000  0.000000  1.0  1.000000  0.000000  0.000000   \n",
       "265   0.000000  0.000000  1.0  0.000000  0.000000  1.000000   \n",
       "...        ...       ...  ...       ...       ...       ...   \n",
       "651   0.000000  1.000000  0.0  0.666667  0.166667  0.166667   \n",
       "650   0.666667  0.333333  0.0  0.333333  0.333333  0.333333   \n",
       "646   1.000000  0.000000  0.0  1.000000  0.000000  0.000000   \n",
       "644   0.000000  1.000000  0.0  0.500000  0.500000  0.000000   \n",
       "1591  1.000000  0.000000  0.0  0.333333  0.000000  0.666667   \n",
       "\n",
       "                                                     id       category  \\\n",
       "287   The-existence-of-free-will-as-proposed-by-the-...       Religion   \n",
       "498                                Medical-Marijuana/3/         Health   \n",
       "1288                       Lighting-Impromptu-Debate/2/  Miscellaneous   \n",
       "1065         Atheism-can-not-account-for-moral-truth/1/     Philosophy   \n",
       "265                  The-Bible-doesnt-forbid-Tattoos/1/       Religion   \n",
       "...                                                 ...            ...   \n",
       "651   Standardized-Exit-Exams-Lincoln-Douglas-Format/1/      Education   \n",
       "650                                Singing-Challenge/1/           Arts   \n",
       "646   President-Obama-should-not-have-gotten-the-maj...       Politics   \n",
       "644   THBT-Debate.org-should-pay-fifteen-qualified-j...         People   \n",
       "1591                    The-soul-is-not-a-real-thing/1/     Philosophy   \n",
       "\n",
       "                                                  title  \\\n",
       "287   The existence of free will as proposed by the ...   \n",
       "498                                   Medical Marijuana   \n",
       "1288                          Lighting Impromptu Debate   \n",
       "1065            Atheism can not account for moral truth   \n",
       "265                    The Bible doesn't forbid Tattoos   \n",
       "...                                                 ...   \n",
       "651     Standardized Exit Exams: Lincoln-Douglas Format   \n",
       "650                                   Singing Challenge   \n",
       "646   President Obama should not have gotten the maj...   \n",
       "644   THBT Debate.org should pay fifteen qualified j...   \n",
       "1591                       The soul is not a real thing   \n",
       "\n",
       "                                                 rounds       date  \\\n",
       "287   [[{'side': 'Con', 'text': '\n",
       "  \n",
       "I challenge an... 2011-06-14   \n",
       "498   [[{'side': 'Con', 'text': '\n",
       "  \n",
       "========  \n",
       "In... 2010-11-21   \n",
       "1288  [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "This is a ligh... 2010-08-09   \n",
       "1065  [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "To start, I wa... 2011-06-23   \n",
       "265   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "The argument i... 2013-08-02   \n",
       "...                                                 ...        ...   \n",
       "651   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "Though I will ... 2009-10-08   \n",
       "650   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "Let's begin wi... 2016-05-01   \n",
       "646   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "Barack Obama s... 2013-01-21   \n",
       "644   [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "Rounds  \n",
       "  \n",
       "-... 2015-05-25   \n",
       "1591  [[{'side': 'Pro', 'text': '\n",
       "  \n",
       "I am on the si... 2012-06-29   \n",
       "\n",
       "           pro_debater    con_debater  \\\n",
       "287         KeytarHero  GOD-vs-ITSELF   \n",
       "498            Atheism     Zealotical   \n",
       "1288  Strikeeagle84015          Grape   \n",
       "1065         charles15           LeoL   \n",
       "265           dwmiller    wolfman4711   \n",
       "...                ...            ...   \n",
       "651           alto2osu      simpleton   \n",
       "650    TurleDoveSammie            TUF   \n",
       "646           Jester02     Deadlykris   \n",
       "644            Palmo10   cathaystewie   \n",
       "1591   mega-antitheist      jwesbruce   \n",
       "\n",
       "                                                 voters winner  \n",
       "287           [ReformedArsenal, medic0506, Cliff.Stamp]    Pro  \n",
       "498                                    [Atheism, MarcL]    Pro  \n",
       "1288                   [I-am-a-panda, Strikeeagle84015]    Con  \n",
       "1065                [Cliff.Stamp, GMDebater, RoyLatham]    Con  \n",
       "265                                      [GOP, Chapule]    Pro  \n",
       "...                                                 ...    ...  \n",
       "651   [insignia96, LadyHavok13, seeley.linda, Nails,...    Pro  \n",
       "650   [ResponsiblyIrresponsible, ESocialBookworm, Ro...    Pro  \n",
       "646                      [OhioGary, tmar19652, proglib]    Con  \n",
       "644      [TheJuniorVarsityNovice, F-16_Fighting_Falcon]    Pro  \n",
       "1591  [SuburbiaSurvivor, InVinoVeritas, Ron-Paul, wa...    Con  \n",
       "\n",
       "[1592 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.DataFrame(feat), df_train], axis=1)\n",
    "df.sort_values(by=[2], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0543cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What two linguistic features did you incorporate in the Ngram+Lex+Ling model?  Stateyour hypothesis about which linguistic features you think would be useful (and why),and perform some data analysis to show that they would be useful to incorporate intoyour model.  Give two examples where these features would help you identify the winnerof a debate.\n",
    "REPORT_PATH = './resources/report/abs_lexicon_feature/'\n",
    "NGRAM_ONLY = REPORT_PATH + 'ngram_only.csv'\n",
    "NGRAM_LEXICON_ONLY = REPORT_PATH + 'ngram_lexicon_only.csv'\n",
    "NGRAM_LEXICON_LINGUISTIC_ONLY = REPORT_PATH + 'ngram_lexicon_linguistic_only.csv'\n",
    "NGRAM_LINGUISTIC_ONLY = REPORT_PATH + 'ngram_linguistic_only.csv'\n",
    "NGRAM_LEXICON_LINGUISTIC_USERS_ONLY = REPORT_PATH + 'ngram_lexicon_linguistic_users_only.csv'\n",
    "\n",
    "report_df_ngram_only = pd.read_csv(NGRAM_ONLY, index_col=0)\n",
    "report_df_ngram_lexicon_only = pd.read_csv(NGRAM_LEXICON_ONLY, index_col=0)\n",
    "report_df_ngram_linguistic_only = pd.read_csv(NGRAM_LINGUISTIC_ONLY, index_col=0)\n",
    "report_df_ngram_lexicon_linguistic_only = pd.read_csv(NGRAM_LEXICON_LINGUISTIC_ONLY, index_col=0)\n",
    "report_df_ngram_lexicon_linguistic_users_only = pd.read_csv(NGRAM_LEXICON_LINGUISTIC_USERS_ONLY, index_col=0)\n",
    "\n",
    "all_report_df = [report_df_ngram_lexicon_linguistic_only, \n",
    "                 report_df_ngram_lexicon_only, \n",
    "                 report_df_ngram_linguistic_only,\n",
    "                 report_df_ngram_only,\n",
    "                 report_df_ngram_lexicon_linguistic_users_only                \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce4676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_report_to_dict(report_df):\n",
    "    val_report = report_df.loc[:, 'val_report'].apply(lambda row: eval(row))\n",
    "    report_df.loc[:, 'val_report'] = val_report\n",
    "    train_report = report_df.loc[:, 'train_report'].apply(lambda row: eval(row))\n",
    "    report_df.loc[:, 'train_report'] = train_report\n",
    "    \n",
    "def add_accuracy(report_df):\n",
    "    val_acc = report_df.loc[:, 'val_report'].apply(lambda row: row['accuracy'])\n",
    "    report_df['val_accuracy'] = val_acc\n",
    "    train_acc = report_df.loc[:, 'train_report'].apply(lambda row: row['accuracy'])\n",
    "    report_df['train_accuracy'] = train_acc\n",
    "    \n",
    "def max_val_accuracy_by_linguistic_features(report_df):\n",
    "    grouped = report_df.groupby(['linguistic_trans'])\n",
    "    max_val_accuracy_by_linguistic = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        max_idx = group['val_accuracy'].argmax()\n",
    "        max_row = group.iloc[max_idx, :]\n",
    "        max_val_accuracy_by_linguistic.append(max_row)\n",
    "\n",
    "    df_max_val_accuracy_by_linguistic = pd.DataFrame(max_val_accuracy_by_linguistic)\n",
    "    return df_max_val_accuracy_by_linguistic.sort_values(by=['val_accuracy'], ascending=False)\n",
    "\n",
    "def max_val_accuracy_by_lexicon_features(report_df):\n",
    "    grouped = report_df.groupby(['lexicon_trans'])\n",
    "    max_val_accuracy_by_linguistic = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        max_idx = group['val_accuracy'].argmax()\n",
    "        max_row = group.iloc[max_idx, :]\n",
    "        max_val_accuracy_by_linguistic.append(max_row)\n",
    "\n",
    "    df_max_val_accuracy_by_lexicon = pd.DataFrame(max_val_accuracy_by_linguistic)\n",
    "    return df_max_val_accuracy_by_lexicon.sort_values(by=['val_accuracy'], ascending=False)\n",
    "\n",
    "def max_val_accuracy_by_users_features(report_df):\n",
    "    grouped = report_df.groupby(['users_trans'])\n",
    "    max_val_accuracy_by_users = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        max_idx = group['val_accuracy'].argmax()\n",
    "        max_row = group.iloc[max_idx, :]\n",
    "        max_val_accuracy_by_users.append(max_row)\n",
    "\n",
    "    df_max_val_accuracy_by_users = pd.DataFrame(max_val_accuracy_by_users)\n",
    "    return df_max_val_accuracy_by_users.sort_values(by=['val_accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c24ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for report_df in all_report_df:\n",
    "    convert_report_to_dict(report_df)\n",
    "    add_accuracy(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a058bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linguistic_report_df = [report_df_ngram_lexicon_linguistic_only, \n",
    "                        report_df_ngram_linguistic_only,\n",
    "                        report_df_ngram_lexicon_linguistic_users_only                \n",
    "                        ]\n",
    "lexicon_report_df = [report_df_ngram_lexicon_linguistic_only, \n",
    "                        report_df_ngram_linguistic_only,\n",
    "                        report_df_ngram_lexicon_only\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "82fde814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer_get_political_align', 'transformer_get_gender_user_align']\n",
      "['transformer_get_religious_align', 'transformer_get_education_user_align']\n",
      "['transformer_get_religious_align', 'transformer_get_political_align']\n",
      "['transformer_get_political_align', 'transformer_get_party_user_align']\n",
      "['transformer_get_cosine_similarity ', 'transformer_get_ethnicity_user_align']\n",
      "['transformer_get_political_align', 'transformer_get_ethnicity_user_align']\n",
      "['transformer_get_political_align', 'transformer_get_education_user_align']\n",
      "['transformer_get_cosine_similarity ', 'transformer_get_relationship_user_align']\n",
      "['transformer_get_education_user_align', 'transformer_get_ethnicity_user_align']\n",
      "['transformer_get_religious_align', 'transformer_get_relationship_user_align']\n",
      "['transformer_get_education_user_align', 'transformer_get_party_user_align']\n",
      "['transformer_get_religious_align', 'transformer_get_ethnicity_user_align']\n",
      "['transformer_get_cosine_similarity ', 'transformer_get_political_align']\n",
      "['transformer_get_political_align', 'transformer_get_relationship_user_align']\n",
      "['transformer_get_education_user_align', 'transformer_get_relationship_user_align']\n",
      "['transformer_get_religious_align', 'transformer_get_party_user_align']\n",
      "['transformer_get_gender_user_align', 'transformer_get_relationship_user_align']\n",
      "['transformer_get_religious_align', 'transformer_get_gender_user_align']\n",
      "['transformer_get_party_user_align', 'transformer_get_relationship_user_align']\n",
      "['transformer_get_cosine_similarity ', 'transformer_get_religious_align']\n",
      "['transformer_get_cosine_similarity ', 'transformer_get_party_user_align']\n",
      "['transformer_get_education_user_align', 'transformer_get_gender_user_align']\n",
      "['transformer_get_ethnicity_user_align', 'transformer_get_relationship_user_align']\n",
      "['transformer_get_cosine_similarity ', 'transformer_get_education_user_align']\n",
      "['transformer_get_gender_user_align', 'transformer_get_ethnicity_user_align']\n",
      "['transformer_get_cosine_similarity ', 'transformer_get_gender_user_align']\n",
      "['transformer_get_party_user_align', 'transformer_get_ethnicity_user_align']\n",
      "['transformer_get_party_user_align', 'transformer_get_gender_user_align']\n"
     ]
    }
   ],
   "source": [
    "df = max_val_accuracy_by_users_features(report_df_ngram_lexicon_linguistic_users_only).drop(columns=['train_report', \n",
    "                                                                                                'val_report']).users_trans\n",
    "\n",
    "for i in df:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e22aaef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('transformer_get_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e62fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['political_align', 'gender_user_align'], ['religious_align', 'education_user_align'], ['religious_align', 'political_align'], ['political_align', 'party_user_align'], ['cosine_similarity ', 'ethnicity_user_align'], ['political_align', 'ethnicity_user_align'], ['political_align', 'education_user_align'], ['cosine_similarity ', 'relationship_user_align'], ['education_user_align', 'ethnicity_user_align'], ['religious_align', 'relationship_user_align'], ['education_user_align', 'party_user_align'], ['religious_align', 'ethnicity_user_align'], ['cosine_similarity ', 'political_align'], ['political_align', 'relationship_user_align'], ['education_user_align', 'relationship_user_align'], ['religious_align', 'party_user_align'], ['gender_user_align', 'relationship_user_align'], ['religious_align', 'gender_user_align'], ['party_user_align', 'relationship_user_align'], ['cosine_similarity ', 'religious_align'], ['cosine_similarity ', 'party_user_align'], ['education_user_align', 'gender_user_align'], ['ethnicity_user_align', 'relationship_user_align'], ['cosine_similarity ', 'education_user_align'], ['gender_user_align', 'ethnicity_user_align'], ['cosine_similarity ', 'gender_user_align'], ['party_user_align', 'ethnicity_user_align'], ['party_user_align', 'gender_user_align']]\n"
     ]
    }
   ],
   "source": [
    "user_features = max_val_accuracy_by_users_features(report_df_ngram_lexicon_linguistic_users_only).drop(columns=['train_report', \n",
    "                                                                                                'val_report']).users_trans\n",
    "\n",
    "ans = []\n",
    "for item in user_features:\n",
    "    list_ = eval(item)\n",
    "    ans.append(list(map(lambda x: x[16:], list_)))\n",
    "    \n",
    "print(ans)\n",
    "target_df = max_val_accuracy_by_users_features(report_df_ngram_lexicon_linguistic_users_only)\n",
    "target_df['users_trans'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a2969b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llr}\n",
      "\\toprule\n",
      "{} &                                      users\\_trans &  val\\_accuracy \\\\\n",
      "\\midrule\n",
      "15 &             [political\\_align, gender\\_user\\_align] &      0.786967 \\\\\n",
      "8  &          [religious\\_align, education\\_user\\_align] &      0.766917 \\\\\n",
      "7  &               [religious\\_align, political\\_align] &      0.766917 \\\\\n",
      "14 &              [political\\_align, party\\_user\\_align] &      0.766917 \\\\\n",
      "5  &       [cosine\\_similarity , ethnicity\\_user\\_align] &      0.764411 \\\\\n",
      "16 &          [political\\_align, ethnicity\\_user\\_align] &      0.764411 \\\\\n",
      "13 &          [political\\_align, education\\_user\\_align] &      0.764411 \\\\\n",
      "6  &    [cosine\\_similarity , relationship\\_user\\_align] &      0.761905 \\\\\n",
      "20 &     [education\\_user\\_align, ethnicity\\_user\\_align] &      0.761905 \\\\\n",
      "12 &       [religious\\_align, relationship\\_user\\_align] &      0.759398 \\\\\n",
      "18 &         [education\\_user\\_align, party\\_user\\_align] &      0.759398 \\\\\n",
      "11 &          [religious\\_align, ethnicity\\_user\\_align] &      0.756892 \\\\\n",
      "1  &            [cosine\\_similarity , political\\_align] &      0.756892 \\\\\n",
      "17 &       [political\\_align, relationship\\_user\\_align] &      0.756892 \\\\\n",
      "21 &  [education\\_user\\_align, relationship\\_user\\_align] &      0.751880 \\\\\n",
      "9  &              [religious\\_align, party\\_user\\_align] &      0.749373 \\\\\n",
      "26 &     [gender\\_user\\_align, relationship\\_user\\_align] &      0.744361 \\\\\n",
      "10 &             [religious\\_align, gender\\_user\\_align] &      0.744361 \\\\\n",
      "24 &      [party\\_user\\_align, relationship\\_user\\_align] &      0.744361 \\\\\n",
      "0  &            [cosine\\_similarity , religious\\_align] &      0.744361 \\\\\n",
      "3  &           [cosine\\_similarity , party\\_user\\_align] &      0.744361 \\\\\n",
      "19 &        [education\\_user\\_align, gender\\_user\\_align] &      0.741855 \\\\\n",
      "27 &  [ethnicity\\_user\\_align, relationship\\_user\\_align] &      0.741855 \\\\\n",
      "2  &       [cosine\\_similarity , education\\_user\\_align] &      0.739348 \\\\\n",
      "25 &        [gender\\_user\\_align, ethnicity\\_user\\_align] &      0.739348 \\\\\n",
      "4  &          [cosine\\_similarity , gender\\_user\\_align] &      0.739348 \\\\\n",
      "23 &         [party\\_user\\_align, ethnicity\\_user\\_align] &      0.736842 \\\\\n",
      "22 &            [party\\_user\\_align, gender\\_user\\_align] &      0.734336 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex = target_df.loc[:, ['users_trans', 'val_accuracy']].to_latex()\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "00f7f3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_trans</th>\n",
       "      <th>lexicon_trans</th>\n",
       "      <th>linguistic_trans</th>\n",
       "      <th>users_trans</th>\n",
       "      <th>train_report</th>\n",
       "      <th>val_report</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'swear_words']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7689119170984456, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7389558232931727, 'recal...</td>\n",
       "      <td>0.769424</td>\n",
       "      <td>0.750628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7771911298838438, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7330677290836654, 'recal...</td>\n",
       "      <td>0.764411</td>\n",
       "      <td>0.754397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7635416666666667, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7269076305220884, 'recal...</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.742462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7522842639593909, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7198443579766537, 'recal...</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.736809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7722980062959076, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7276422764227642, 'recal...</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.750628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'swear_words']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7689873417721519, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7295081967213115, 'recal...</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7664921465968586, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7333333333333333, 'recal...</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7623456790123457, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7176470588235294, 'recal...</td>\n",
       "      <td>0.749373</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7642782969885774, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7176470588235294, 'recal...</td>\n",
       "      <td>0.749373</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'reference_to_opponent']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7762312633832976, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7246963562753036, 'recal...</td>\n",
       "      <td>0.749373</td>\n",
       "      <td>0.748744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7664233576642335, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7217741935483871, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.745603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7607361963190185, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7115384615384616, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7675619834710744, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7182539682539683, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7569803516028956, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.71484375, 'recall': 0.86...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.736809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7667386609071274, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7235772357723578, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.734925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7698833510074231, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7188755020080321, 'recal...</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7690700104493208, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7142857142857143, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.748116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['questions', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7610810810810811, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7125984251968503, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.728015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['questions', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7632398753894081, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7109375, 'recall': 0.862...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.743090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['reference_to_opponent', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7715846994535519, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.717741935483871, 'recall...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.736809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7676130389064143, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7142857142857143, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7495069033530573, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7, 'recall': 0.895734597...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.742462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.774331550802139, 'recall...</td>\n",
       "      <td>{'0': {'precision': 0.717741935483871, 'recall...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.746859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7730646871686108, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7154471544715447, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.748116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['reference_to_opponent', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7631296891747053, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7086614173228346, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.733040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7608040201005025, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6981132075471698, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.750628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7801268498942917, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7091633466135459, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.757538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7686567164179104, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7131147540983607, 'recal...</td>\n",
       "      <td>0.731830</td>\n",
       "      <td>0.741206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['questions', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7440711462450593, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6914498141263941, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.734925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['swear_words', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7592190889370932, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7003891050583657, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.724874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['number', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7597402597402597, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7019607843137254, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.726131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7608465608465609, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7068273092369478, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.734296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7659352142110762, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7068273092369478, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['exclamation', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7600872410032715, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7007874015748031, 'recal...</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.724246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['questions', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7575431034482759, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6976744186046512, 'recal...</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.724874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['exclamation', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7562296858071506, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6937984496124031, 'recal...</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.721734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram_trans    lexicon_trans  \\\n",
       "44  ['trigram']          ['vad']   \n",
       "51  ['trigram']          ['vad']   \n",
       "55  ['trigram']          ['vad']   \n",
       "52  ['trigram']          ['vad']   \n",
       "47  ['trigram']          ['vad']   \n",
       "37  ['trigram']          ['vad']   \n",
       "56  ['trigram']          ['vad']   \n",
       "60  ['trigram']          ['vad']   \n",
       "66  ['trigram']          ['vad']   \n",
       "36  ['trigram']          ['vad']   \n",
       "45  ['trigram']          ['vad']   \n",
       "49  ['trigram']          ['vad']   \n",
       "57  ['trigram']          ['vad']   \n",
       "59  ['trigram']          ['vad']   \n",
       "2   ['trigram']  ['connotation']   \n",
       "67  ['trigram']          ['vad']   \n",
       "53  ['trigram']          ['vad']   \n",
       "29  ['trigram']  ['connotation']   \n",
       "62  ['trigram']          ['vad']   \n",
       "14  ['trigram']  ['connotation']   \n",
       "42  ['trigram']          ['vad']   \n",
       "46  ['trigram']          ['vad']   \n",
       "68  ['trigram']          ['vad']   \n",
       "40  ['trigram']          ['vad']   \n",
       "12  ['trigram']  ['connotation']   \n",
       "61  ['trigram']          ['vad']   \n",
       "58  ['trigram']          ['vad']   \n",
       "43  ['trigram']          ['vad']   \n",
       "64  ['trigram']          ['vad']   \n",
       "18  ['trigram']  ['connotation']   \n",
       "35  ['trigram']  ['connotation']   \n",
       "39  ['trigram']          ['vad']   \n",
       "41  ['trigram']          ['vad']   \n",
       "33  ['trigram']  ['connotation']   \n",
       "27  ['trigram']  ['connotation']   \n",
       "34  ['trigram']  ['connotation']   \n",
       "\n",
       "                                  linguistic_trans users_trans  \\\n",
       "44        ['reference_to_opponent', 'swear_words']          []   \n",
       "51            ['swear_words', 'personal_pronouns']          []   \n",
       "55                       ['swear_words', 'number']          []   \n",
       "52                    ['swear_words', 'questions']          []   \n",
       "47           ['reference_to_opponent', 'websites']          []   \n",
       "37                       ['length', 'swear_words']          []   \n",
       "56                   ['swear_words', 'modal_verb']          []   \n",
       "60                 ['personal_pronouns', 'number']          []   \n",
       "66                     ['websites', 'exclamation']          []   \n",
       "36             ['length', 'reference_to_opponent']          []   \n",
       "45  ['reference_to_opponent', 'personal_pronouns']          []   \n",
       "49             ['reference_to_opponent', 'number']          []   \n",
       "57              ['personal_pronouns', 'questions']          []   \n",
       "59            ['personal_pronouns', 'exclamation']          []   \n",
       "2                  ['length', 'personal_pronouns']          []   \n",
       "67                          ['websites', 'number']          []   \n",
       "53                     ['swear_words', 'websites']          []   \n",
       "29                     ['questions', 'modal_verb']          []   \n",
       "62                       ['questions', 'websites']          []   \n",
       "14         ['reference_to_opponent', 'modal_verb']          []   \n",
       "42                            ['length', 'number']          []   \n",
       "46          ['reference_to_opponent', 'questions']          []   \n",
       "68                      ['websites', 'modal_verb']          []   \n",
       "40                          ['length', 'websites']          []   \n",
       "12        ['reference_to_opponent', 'exclamation']          []   \n",
       "61             ['personal_pronouns', 'modal_verb']          []   \n",
       "58               ['personal_pronouns', 'websites']          []   \n",
       "43                        ['length', 'modal_verb']          []   \n",
       "64                         ['questions', 'number']          []   \n",
       "18                  ['swear_words', 'exclamation']          []   \n",
       "35                        ['number', 'modal_verb']          []   \n",
       "39                         ['length', 'questions']          []   \n",
       "41                       ['length', 'exclamation']          []   \n",
       "33                       ['exclamation', 'number']          []   \n",
       "27                    ['questions', 'exclamation']          []   \n",
       "34                   ['exclamation', 'modal_verb']          []   \n",
       "\n",
       "                                         train_report  \\\n",
       "44  {'0': {'precision': 0.7689119170984456, 'recal...   \n",
       "51  {'0': {'precision': 0.7771911298838438, 'recal...   \n",
       "55  {'0': {'precision': 0.7635416666666667, 'recal...   \n",
       "52  {'0': {'precision': 0.7522842639593909, 'recal...   \n",
       "47  {'0': {'precision': 0.7722980062959076, 'recal...   \n",
       "37  {'0': {'precision': 0.7689873417721519, 'recal...   \n",
       "56  {'0': {'precision': 0.7664921465968586, 'recal...   \n",
       "60  {'0': {'precision': 0.7623456790123457, 'recal...   \n",
       "66  {'0': {'precision': 0.7642782969885774, 'recal...   \n",
       "36  {'0': {'precision': 0.7762312633832976, 'recal...   \n",
       "45  {'0': {'precision': 0.7664233576642335, 'recal...   \n",
       "49  {'0': {'precision': 0.7607361963190185, 'recal...   \n",
       "57  {'0': {'precision': 0.7675619834710744, 'recal...   \n",
       "59  {'0': {'precision': 0.7569803516028956, 'recal...   \n",
       "2   {'0': {'precision': 0.7667386609071274, 'recal...   \n",
       "67  {'0': {'precision': 0.7698833510074231, 'recal...   \n",
       "53  {'0': {'precision': 0.7690700104493208, 'recal...   \n",
       "29  {'0': {'precision': 0.7610810810810811, 'recal...   \n",
       "62  {'0': {'precision': 0.7632398753894081, 'recal...   \n",
       "14  {'0': {'precision': 0.7715846994535519, 'recal...   \n",
       "42  {'0': {'precision': 0.7676130389064143, 'recal...   \n",
       "46  {'0': {'precision': 0.7495069033530573, 'recal...   \n",
       "68  {'0': {'precision': 0.774331550802139, 'recall...   \n",
       "40  {'0': {'precision': 0.7730646871686108, 'recal...   \n",
       "12  {'0': {'precision': 0.7631296891747053, 'recal...   \n",
       "61  {'0': {'precision': 0.7608040201005025, 'recal...   \n",
       "58  {'0': {'precision': 0.7801268498942917, 'recal...   \n",
       "43  {'0': {'precision': 0.7686567164179104, 'recal...   \n",
       "64  {'0': {'precision': 0.7440711462450593, 'recal...   \n",
       "18  {'0': {'precision': 0.7592190889370932, 'recal...   \n",
       "35  {'0': {'precision': 0.7597402597402597, 'recal...   \n",
       "39  {'0': {'precision': 0.7608465608465609, 'recal...   \n",
       "41  {'0': {'precision': 0.7659352142110762, 'recal...   \n",
       "33  {'0': {'precision': 0.7600872410032715, 'recal...   \n",
       "27  {'0': {'precision': 0.7575431034482759, 'recal...   \n",
       "34  {'0': {'precision': 0.7562296858071506, 'recal...   \n",
       "\n",
       "                                           val_report  val_accuracy  \\\n",
       "44  {'0': {'precision': 0.7389558232931727, 'recal...      0.769424   \n",
       "51  {'0': {'precision': 0.7330677290836654, 'recal...      0.764411   \n",
       "55  {'0': {'precision': 0.7269076305220884, 'recal...      0.754386   \n",
       "52  {'0': {'precision': 0.7198443579766537, 'recal...      0.754386   \n",
       "47  {'0': {'precision': 0.7276422764227642, 'recal...      0.751880   \n",
       "37  {'0': {'precision': 0.7295081967213115, 'recal...      0.751880   \n",
       "56  {'0': {'precision': 0.7333333333333333, 'recal...      0.751880   \n",
       "60  {'0': {'precision': 0.7176470588235294, 'recal...      0.749373   \n",
       "66  {'0': {'precision': 0.7176470588235294, 'recal...      0.749373   \n",
       "36  {'0': {'precision': 0.7246963562753036, 'recal...      0.749373   \n",
       "45  {'0': {'precision': 0.7217741935483871, 'recal...      0.746867   \n",
       "49  {'0': {'precision': 0.7115384615384616, 'recal...      0.746867   \n",
       "57  {'0': {'precision': 0.7182539682539683, 'recal...      0.746867   \n",
       "59  {'0': {'precision': 0.71484375, 'recall': 0.86...      0.746867   \n",
       "2   {'0': {'precision': 0.7235772357723578, 'recal...      0.746867   \n",
       "67  {'0': {'precision': 0.7188755020080321, 'recal...      0.744361   \n",
       "53  {'0': {'precision': 0.7142857142857143, 'recal...      0.741855   \n",
       "29  {'0': {'precision': 0.7125984251968503, 'recal...      0.741855   \n",
       "62  {'0': {'precision': 0.7109375, 'recall': 0.862...      0.741855   \n",
       "14  {'0': {'precision': 0.717741935483871, 'recall...      0.741855   \n",
       "42  {'0': {'precision': 0.7142857142857143, 'recal...      0.741855   \n",
       "46  {'0': {'precision': 0.7, 'recall': 0.895734597...      0.741855   \n",
       "68  {'0': {'precision': 0.717741935483871, 'recall...      0.741855   \n",
       "40  {'0': {'precision': 0.7154471544715447, 'recal...      0.736842   \n",
       "12  {'0': {'precision': 0.7086614173228346, 'recal...      0.736842   \n",
       "61  {'0': {'precision': 0.6981132075471698, 'recal...      0.734336   \n",
       "58  {'0': {'precision': 0.7091633466135459, 'recal...      0.734336   \n",
       "43  {'0': {'precision': 0.7131147540983607, 'recal...      0.731830   \n",
       "64  {'0': {'precision': 0.6914498141263941, 'recal...      0.729323   \n",
       "18  {'0': {'precision': 0.7003891050583657, 'recal...      0.729323   \n",
       "35  {'0': {'precision': 0.7019607843137254, 'recal...      0.729323   \n",
       "39  {'0': {'precision': 0.7068273092369478, 'recal...      0.729323   \n",
       "41  {'0': {'precision': 0.7068273092369478, 'recal...      0.729323   \n",
       "33  {'0': {'precision': 0.7007874015748031, 'recal...      0.726817   \n",
       "27  {'0': {'precision': 0.6976744186046512, 'recal...      0.726817   \n",
       "34  {'0': {'precision': 0.6937984496124031, 'recal...      0.721805   \n",
       "\n",
       "    train_accuracy  \n",
       "44        0.750628  \n",
       "51        0.754397  \n",
       "55        0.742462  \n",
       "52        0.736809  \n",
       "47        0.750628  \n",
       "37        0.744975  \n",
       "56        0.744347  \n",
       "60        0.744975  \n",
       "66        0.744347  \n",
       "36        0.748744  \n",
       "45        0.745603  \n",
       "49        0.744975  \n",
       "57        0.750000  \n",
       "59        0.736809  \n",
       "2         0.734925  \n",
       "67        0.744347  \n",
       "53        0.748116  \n",
       "29        0.728015  \n",
       "62        0.743090  \n",
       "14        0.736809  \n",
       "42        0.744347  \n",
       "46        0.742462  \n",
       "68        0.746859  \n",
       "40        0.748116  \n",
       "12        0.733040  \n",
       "61        0.750628  \n",
       "58        0.757538  \n",
       "43        0.741206  \n",
       "64        0.734925  \n",
       "18        0.724874  \n",
       "35        0.726131  \n",
       "39        0.734296  \n",
       "41        0.744347  \n",
       "33        0.724246  \n",
       "27        0.724874  \n",
       "34        0.721734  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val_accuracy_by_linguistic_features(linguistic_report_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc2ed36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_trans</th>\n",
       "      <th>lexicon_trans</th>\n",
       "      <th>linguistic_trans</th>\n",
       "      <th>users_trans</th>\n",
       "      <th>train_report</th>\n",
       "      <th>val_report</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['swear_words', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8252947481243301, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7416666666666667, 'recal...</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.805905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['websites', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8487654320987654, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7233201581027668, 'recal...</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.850503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['questions', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8577319587628865, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.724, 'recall': 0.8578199...</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.860553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reference_to_opponent', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8571428571428571, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.726530612244898, 'recall...</td>\n",
       "      <td>0.749373</td>\n",
       "      <td>0.864322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['length', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8108395324123273, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7217741935483871, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.792085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['swear_words', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8670756646216768, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7217741935483871, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.875628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reference_to_opponent', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8297872340425532, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7235772357723578, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.833543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['number', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8273453093812375, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.706766917293233, 'recall...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.836683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['exclamation', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8517766497461929, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7171314741035857, 'recal...</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.859925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['personal_pronouns', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8310880829015544, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7224489795918367, 'recal...</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.826005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['swear_words', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.851063829787234, 'recall...</td>\n",
       "      <td>{'0': {'precision': 0.716, 'recall': 0.8483412...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.859925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['questions', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8612538540596094, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7195121951219512, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.866206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['questions', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8656410256410256, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.717741935483871, 'recall...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.872487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['length', 'reference_to_opponent']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8323045267489712, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7142857142857143, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.830402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['length', 'swear_words']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8162217659137577, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.714859437751004, 'recall...</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.811558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['length', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7713097713097713, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7098039215686275, 'recal...</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.752513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['exclamation', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8679245283018868, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.720164609053498, 'recall...</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.865578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['length', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8216494845360824, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7183673469387755, 'recal...</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.816583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reference_to_opponent', 'swear_words']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8738269030239834, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.720164609053498, 'recall...</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['websites', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.85, 'recall': 0.90938864...</td>\n",
       "      <td>{'0': {'precision': 0.7137096774193549, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.855528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reference_to_opponent', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8680981595092024, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7137096774193549, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.876884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reference_to_opponent', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8033932135728543, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6981132075471698, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.806533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reference_to_opponent', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8638211382113821, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7142857142857143, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.874372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['length', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8226141078838174, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7108433734939759, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.815327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['personal_pronouns', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.822429906542056, 'recall...</td>\n",
       "      <td>{'0': {'precision': 0.7042801556420234, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.814698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['questions', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8693877551020408, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7108433734939759, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.879397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['personal_pronouns', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8088531187122736, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.703125, 'recall': 0.8530...</td>\n",
       "      <td>0.731830</td>\n",
       "      <td>0.810302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['swear_words', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8588832487309644, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7096774193548387, 'recal...</td>\n",
       "      <td>0.731830</td>\n",
       "      <td>0.868719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['length', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8093781855249745, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.708, 'recall': 0.8388625...</td>\n",
       "      <td>0.731830</td>\n",
       "      <td>0.805905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['websites', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8640973630831643, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.708502024291498, 'recall...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.875628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['length', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8179012345679012, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7068273092369478, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.812814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reference_to_opponent', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8531187122736419, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.704, 'recall': 0.8341232...</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.865578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['swear_words', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8582995951417004, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6996047430830039, 'recal...</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.869347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['swear_words', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.8525252525252526, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6980392156862745, 'recal...</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.863065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['personal_pronouns', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7514177693761814, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6630824372759857, 'recal...</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.758794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['personal_pronouns', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.6605042016806723, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6171617161716172, 'recal...</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.664573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram_trans lexicon_trans                                linguistic_trans  \\\n",
       "15  ['trigram']            []            ['swear_words', 'personal_pronouns']   \n",
       "31  ['trigram']            []                          ['websites', 'number']   \n",
       "28  ['trigram']            []                         ['questions', 'number']   \n",
       "14  ['trigram']            []         ['reference_to_opponent', 'modal_verb']   \n",
       "3   ['trigram']            []                         ['length', 'questions']   \n",
       "18  ['trigram']            []                  ['swear_words', 'exclamation']   \n",
       "13  ['trigram']            []             ['reference_to_opponent', 'number']   \n",
       "35  ['trigram']            []                        ['number', 'modal_verb']   \n",
       "34  ['trigram']            []                   ['exclamation', 'modal_verb']   \n",
       "22  ['trigram']            []               ['personal_pronouns', 'websites']   \n",
       "20  ['trigram']            []                   ['swear_words', 'modal_verb']   \n",
       "29  ['trigram']            []                     ['questions', 'modal_verb']   \n",
       "26  ['trigram']            []                       ['questions', 'websites']   \n",
       "0   ['trigram']            []             ['length', 'reference_to_opponent']   \n",
       "1   ['trigram']            []                       ['length', 'swear_words']   \n",
       "2   ['trigram']            []                 ['length', 'personal_pronouns']   \n",
       "33  ['trigram']            []                       ['exclamation', 'number']   \n",
       "4   ['trigram']            []                          ['length', 'websites']   \n",
       "8   ['trigram']            []        ['reference_to_opponent', 'swear_words']   \n",
       "32  ['trigram']            []                      ['websites', 'modal_verb']   \n",
       "12  ['trigram']            []        ['reference_to_opponent', 'exclamation']   \n",
       "9   ['trigram']            []  ['reference_to_opponent', 'personal_pronouns']   \n",
       "11  ['trigram']            []           ['reference_to_opponent', 'websites']   \n",
       "7   ['trigram']            []                        ['length', 'modal_verb']   \n",
       "23  ['trigram']            []            ['personal_pronouns', 'exclamation']   \n",
       "27  ['trigram']            []                    ['questions', 'exclamation']   \n",
       "21  ['trigram']            []              ['personal_pronouns', 'questions']   \n",
       "16  ['trigram']            []                    ['swear_words', 'questions']   \n",
       "6   ['trigram']            []                            ['length', 'number']   \n",
       "30  ['trigram']            []                     ['websites', 'exclamation']   \n",
       "5   ['trigram']            []                       ['length', 'exclamation']   \n",
       "10  ['trigram']            []          ['reference_to_opponent', 'questions']   \n",
       "17  ['trigram']            []                     ['swear_words', 'websites']   \n",
       "19  ['trigram']            []                       ['swear_words', 'number']   \n",
       "25  ['trigram']            []             ['personal_pronouns', 'modal_verb']   \n",
       "24  ['trigram']            []                 ['personal_pronouns', 'number']   \n",
       "\n",
       "   users_trans                                       train_report  \\\n",
       "15          []  {'0': {'precision': 0.8252947481243301, 'recal...   \n",
       "31          []  {'0': {'precision': 0.8487654320987654, 'recal...   \n",
       "28          []  {'0': {'precision': 0.8577319587628865, 'recal...   \n",
       "14          []  {'0': {'precision': 0.8571428571428571, 'recal...   \n",
       "3           []  {'0': {'precision': 0.8108395324123273, 'recal...   \n",
       "18          []  {'0': {'precision': 0.8670756646216768, 'recal...   \n",
       "13          []  {'0': {'precision': 0.8297872340425532, 'recal...   \n",
       "35          []  {'0': {'precision': 0.8273453093812375, 'recal...   \n",
       "34          []  {'0': {'precision': 0.8517766497461929, 'recal...   \n",
       "22          []  {'0': {'precision': 0.8310880829015544, 'recal...   \n",
       "20          []  {'0': {'precision': 0.851063829787234, 'recall...   \n",
       "29          []  {'0': {'precision': 0.8612538540596094, 'recal...   \n",
       "26          []  {'0': {'precision': 0.8656410256410256, 'recal...   \n",
       "0           []  {'0': {'precision': 0.8323045267489712, 'recal...   \n",
       "1           []  {'0': {'precision': 0.8162217659137577, 'recal...   \n",
       "2           []  {'0': {'precision': 0.7713097713097713, 'recal...   \n",
       "33          []  {'0': {'precision': 0.8679245283018868, 'recal...   \n",
       "4           []  {'0': {'precision': 0.8216494845360824, 'recal...   \n",
       "8           []  {'0': {'precision': 0.8738269030239834, 'recal...   \n",
       "32          []  {'0': {'precision': 0.85, 'recall': 0.90938864...   \n",
       "12          []  {'0': {'precision': 0.8680981595092024, 'recal...   \n",
       "9           []  {'0': {'precision': 0.8033932135728543, 'recal...   \n",
       "11          []  {'0': {'precision': 0.8638211382113821, 'recal...   \n",
       "7           []  {'0': {'precision': 0.8226141078838174, 'recal...   \n",
       "23          []  {'0': {'precision': 0.822429906542056, 'recall...   \n",
       "27          []  {'0': {'precision': 0.8693877551020408, 'recal...   \n",
       "21          []  {'0': {'precision': 0.8088531187122736, 'recal...   \n",
       "16          []  {'0': {'precision': 0.8588832487309644, 'recal...   \n",
       "6           []  {'0': {'precision': 0.8093781855249745, 'recal...   \n",
       "30          []  {'0': {'precision': 0.8640973630831643, 'recal...   \n",
       "5           []  {'0': {'precision': 0.8179012345679012, 'recal...   \n",
       "10          []  {'0': {'precision': 0.8531187122736419, 'recal...   \n",
       "17          []  {'0': {'precision': 0.8582995951417004, 'recal...   \n",
       "19          []  {'0': {'precision': 0.8525252525252526, 'recal...   \n",
       "25          []  {'0': {'precision': 0.7514177693761814, 'recal...   \n",
       "24          []  {'0': {'precision': 0.6605042016806723, 'recal...   \n",
       "\n",
       "                                           val_report  val_accuracy  \\\n",
       "15  {'0': {'precision': 0.7416666666666667, 'recal...      0.761905   \n",
       "31  {'0': {'precision': 0.7233201581027668, 'recal...      0.754386   \n",
       "28  {'0': {'precision': 0.724, 'recall': 0.8578199...      0.751880   \n",
       "14  {'0': {'precision': 0.726530612244898, 'recall...      0.749373   \n",
       "3   {'0': {'precision': 0.7217741935483871, 'recal...      0.746867   \n",
       "18  {'0': {'precision': 0.7217741935483871, 'recal...      0.746867   \n",
       "13  {'0': {'precision': 0.7235772357723578, 'recal...      0.746867   \n",
       "35  {'0': {'precision': 0.706766917293233, 'recall...      0.746867   \n",
       "34  {'0': {'precision': 0.7171314741035857, 'recal...      0.744361   \n",
       "22  {'0': {'precision': 0.7224489795918367, 'recal...      0.744361   \n",
       "20  {'0': {'precision': 0.716, 'recall': 0.8483412...      0.741855   \n",
       "29  {'0': {'precision': 0.7195121951219512, 'recal...      0.741855   \n",
       "26  {'0': {'precision': 0.717741935483871, 'recall...      0.741855   \n",
       "0   {'0': {'precision': 0.7142857142857143, 'recal...      0.741855   \n",
       "1   {'0': {'precision': 0.714859437751004, 'recall...      0.739348   \n",
       "2   {'0': {'precision': 0.7098039215686275, 'recal...      0.739348   \n",
       "33  {'0': {'precision': 0.720164609053498, 'recall...      0.739348   \n",
       "4   {'0': {'precision': 0.7183673469387755, 'recal...      0.739348   \n",
       "8   {'0': {'precision': 0.720164609053498, 'recall...      0.739348   \n",
       "32  {'0': {'precision': 0.7137096774193549, 'recal...      0.736842   \n",
       "12  {'0': {'precision': 0.7137096774193549, 'recal...      0.736842   \n",
       "9   {'0': {'precision': 0.6981132075471698, 'recal...      0.734336   \n",
       "11  {'0': {'precision': 0.7142857142857143, 'recal...      0.734336   \n",
       "7   {'0': {'precision': 0.7108433734939759, 'recal...      0.734336   \n",
       "23  {'0': {'precision': 0.7042801556420234, 'recal...      0.734336   \n",
       "27  {'0': {'precision': 0.7108433734939759, 'recal...      0.734336   \n",
       "21  {'0': {'precision': 0.703125, 'recall': 0.8530...      0.731830   \n",
       "16  {'0': {'precision': 0.7096774193548387, 'recal...      0.731830   \n",
       "6   {'0': {'precision': 0.708, 'recall': 0.8388625...      0.731830   \n",
       "30  {'0': {'precision': 0.708502024291498, 'recall...      0.729323   \n",
       "5   {'0': {'precision': 0.7068273092369478, 'recal...      0.729323   \n",
       "10  {'0': {'precision': 0.704, 'recall': 0.8341232...      0.726817   \n",
       "17  {'0': {'precision': 0.6996047430830039, 'recal...      0.724311   \n",
       "19  {'0': {'precision': 0.6980392156862745, 'recal...      0.724311   \n",
       "25  {'0': {'precision': 0.6630824372759857, 'recal...      0.699248   \n",
       "24  {'0': {'precision': 0.6171617161716172, 'recal...      0.649123   \n",
       "\n",
       "    train_accuracy  \n",
       "15        0.805905  \n",
       "31        0.850503  \n",
       "28        0.860553  \n",
       "14        0.864322  \n",
       "3         0.792085  \n",
       "18        0.875628  \n",
       "13        0.833543  \n",
       "35        0.836683  \n",
       "34        0.859925  \n",
       "22        0.826005  \n",
       "20        0.859925  \n",
       "29        0.866206  \n",
       "26        0.872487  \n",
       "0         0.830402  \n",
       "1         0.811558  \n",
       "2         0.752513  \n",
       "33        0.865578  \n",
       "4         0.816583  \n",
       "8         0.875000  \n",
       "32        0.855528  \n",
       "12        0.876884  \n",
       "9         0.806533  \n",
       "11        0.874372  \n",
       "7         0.815327  \n",
       "23        0.814698  \n",
       "27        0.879397  \n",
       "21        0.810302  \n",
       "16        0.868719  \n",
       "6         0.805905  \n",
       "30        0.875628  \n",
       "5         0.812814  \n",
       "10        0.865578  \n",
       "17        0.869347  \n",
       "19        0.863065  \n",
       "25        0.758794  \n",
       "24        0.664573  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val_accuracy_by_linguistic_features(linguistic_report_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "206b0347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_trans</th>\n",
       "      <th>lexicon_trans</th>\n",
       "      <th>linguistic_trans</th>\n",
       "      <th>users_trans</th>\n",
       "      <th>train_report</th>\n",
       "      <th>val_report</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'swear_words']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7689119170984456, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7389558232931727, 'recal...</td>\n",
       "      <td>0.769424</td>\n",
       "      <td>0.750628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7771911298838438, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7330677290836654, 'recal...</td>\n",
       "      <td>0.764411</td>\n",
       "      <td>0.754397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7635416666666667, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7269076305220884, 'recal...</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.742462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7522842639593909, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7198443579766537, 'recal...</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.736809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7722980062959076, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7276422764227642, 'recal...</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.750628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'swear_words']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7689873417721519, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7295081967213115, 'recal...</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7664921465968586, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7333333333333333, 'recal...</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7623456790123457, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7176470588235294, 'recal...</td>\n",
       "      <td>0.749373</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7642782969885774, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7176470588235294, 'recal...</td>\n",
       "      <td>0.749373</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'reference_to_opponent']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7762312633832976, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7246963562753036, 'recal...</td>\n",
       "      <td>0.749373</td>\n",
       "      <td>0.748744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7664233576642335, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7217741935483871, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.745603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7607361963190185, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7115384615384616, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7675619834710744, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7182539682539683, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7569803516028956, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.71484375, 'recall': 0.86...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.736809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7667386609071274, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7235772357723578, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.734925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7698833510074231, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7188755020080321, 'recal...</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['swear_words', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7690700104493208, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7142857142857143, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.748116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['questions', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7610810810810811, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7125984251968503, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.728015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['questions', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7632398753894081, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7109375, 'recall': 0.862...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.743090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['reference_to_opponent', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7715846994535519, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.717741935483871, 'recall...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.736809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7676130389064143, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7142857142857143, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['reference_to_opponent', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7495069033530573, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7, 'recall': 0.895734597...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.742462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.774331550802139, 'recall...</td>\n",
       "      <td>{'0': {'precision': 0.717741935483871, 'recall...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.746859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7730646871686108, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7154471544715447, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.748116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['reference_to_opponent', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7631296891747053, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7086614173228346, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.733040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7608040201005025, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6981132075471698, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.750628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['personal_pronouns', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7801268498942917, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7091633466135459, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.757538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7686567164179104, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7131147540983607, 'recal...</td>\n",
       "      <td>0.731830</td>\n",
       "      <td>0.741206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['questions', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7440711462450593, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6914498141263941, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.734925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['swear_words', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7592190889370932, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7003891050583657, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.724874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['number', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7597402597402597, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7019607843137254, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.726131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7608465608465609, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7068273092369478, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.734296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['length', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7659352142110762, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7068273092369478, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['exclamation', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7600872410032715, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7007874015748031, 'recal...</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.724246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['questions', 'exclamation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7575431034482759, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6976744186046512, 'recal...</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.724874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['exclamation', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7562296858071506, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6937984496124031, 'recal...</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.721734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram_trans    lexicon_trans  \\\n",
       "44  ['trigram']          ['vad']   \n",
       "51  ['trigram']          ['vad']   \n",
       "55  ['trigram']          ['vad']   \n",
       "52  ['trigram']          ['vad']   \n",
       "47  ['trigram']          ['vad']   \n",
       "37  ['trigram']          ['vad']   \n",
       "56  ['trigram']          ['vad']   \n",
       "60  ['trigram']          ['vad']   \n",
       "66  ['trigram']          ['vad']   \n",
       "36  ['trigram']          ['vad']   \n",
       "45  ['trigram']          ['vad']   \n",
       "49  ['trigram']          ['vad']   \n",
       "57  ['trigram']          ['vad']   \n",
       "59  ['trigram']          ['vad']   \n",
       "2   ['trigram']  ['connotation']   \n",
       "67  ['trigram']          ['vad']   \n",
       "53  ['trigram']          ['vad']   \n",
       "29  ['trigram']  ['connotation']   \n",
       "62  ['trigram']          ['vad']   \n",
       "14  ['trigram']  ['connotation']   \n",
       "42  ['trigram']          ['vad']   \n",
       "46  ['trigram']          ['vad']   \n",
       "68  ['trigram']          ['vad']   \n",
       "40  ['trigram']          ['vad']   \n",
       "12  ['trigram']  ['connotation']   \n",
       "61  ['trigram']          ['vad']   \n",
       "58  ['trigram']          ['vad']   \n",
       "43  ['trigram']          ['vad']   \n",
       "64  ['trigram']          ['vad']   \n",
       "18  ['trigram']  ['connotation']   \n",
       "35  ['trigram']  ['connotation']   \n",
       "39  ['trigram']          ['vad']   \n",
       "41  ['trigram']          ['vad']   \n",
       "33  ['trigram']  ['connotation']   \n",
       "27  ['trigram']  ['connotation']   \n",
       "34  ['trigram']  ['connotation']   \n",
       "\n",
       "                                  linguistic_trans users_trans  \\\n",
       "44        ['reference_to_opponent', 'swear_words']          []   \n",
       "51            ['swear_words', 'personal_pronouns']          []   \n",
       "55                       ['swear_words', 'number']          []   \n",
       "52                    ['swear_words', 'questions']          []   \n",
       "47           ['reference_to_opponent', 'websites']          []   \n",
       "37                       ['length', 'swear_words']          []   \n",
       "56                   ['swear_words', 'modal_verb']          []   \n",
       "60                 ['personal_pronouns', 'number']          []   \n",
       "66                     ['websites', 'exclamation']          []   \n",
       "36             ['length', 'reference_to_opponent']          []   \n",
       "45  ['reference_to_opponent', 'personal_pronouns']          []   \n",
       "49             ['reference_to_opponent', 'number']          []   \n",
       "57              ['personal_pronouns', 'questions']          []   \n",
       "59            ['personal_pronouns', 'exclamation']          []   \n",
       "2                  ['length', 'personal_pronouns']          []   \n",
       "67                          ['websites', 'number']          []   \n",
       "53                     ['swear_words', 'websites']          []   \n",
       "29                     ['questions', 'modal_verb']          []   \n",
       "62                       ['questions', 'websites']          []   \n",
       "14         ['reference_to_opponent', 'modal_verb']          []   \n",
       "42                            ['length', 'number']          []   \n",
       "46          ['reference_to_opponent', 'questions']          []   \n",
       "68                      ['websites', 'modal_verb']          []   \n",
       "40                          ['length', 'websites']          []   \n",
       "12        ['reference_to_opponent', 'exclamation']          []   \n",
       "61             ['personal_pronouns', 'modal_verb']          []   \n",
       "58               ['personal_pronouns', 'websites']          []   \n",
       "43                        ['length', 'modal_verb']          []   \n",
       "64                         ['questions', 'number']          []   \n",
       "18                  ['swear_words', 'exclamation']          []   \n",
       "35                        ['number', 'modal_verb']          []   \n",
       "39                         ['length', 'questions']          []   \n",
       "41                       ['length', 'exclamation']          []   \n",
       "33                       ['exclamation', 'number']          []   \n",
       "27                    ['questions', 'exclamation']          []   \n",
       "34                   ['exclamation', 'modal_verb']          []   \n",
       "\n",
       "                                         train_report  \\\n",
       "44  {'0': {'precision': 0.7689119170984456, 'recal...   \n",
       "51  {'0': {'precision': 0.7771911298838438, 'recal...   \n",
       "55  {'0': {'precision': 0.7635416666666667, 'recal...   \n",
       "52  {'0': {'precision': 0.7522842639593909, 'recal...   \n",
       "47  {'0': {'precision': 0.7722980062959076, 'recal...   \n",
       "37  {'0': {'precision': 0.7689873417721519, 'recal...   \n",
       "56  {'0': {'precision': 0.7664921465968586, 'recal...   \n",
       "60  {'0': {'precision': 0.7623456790123457, 'recal...   \n",
       "66  {'0': {'precision': 0.7642782969885774, 'recal...   \n",
       "36  {'0': {'precision': 0.7762312633832976, 'recal...   \n",
       "45  {'0': {'precision': 0.7664233576642335, 'recal...   \n",
       "49  {'0': {'precision': 0.7607361963190185, 'recal...   \n",
       "57  {'0': {'precision': 0.7675619834710744, 'recal...   \n",
       "59  {'0': {'precision': 0.7569803516028956, 'recal...   \n",
       "2   {'0': {'precision': 0.7667386609071274, 'recal...   \n",
       "67  {'0': {'precision': 0.7698833510074231, 'recal...   \n",
       "53  {'0': {'precision': 0.7690700104493208, 'recal...   \n",
       "29  {'0': {'precision': 0.7610810810810811, 'recal...   \n",
       "62  {'0': {'precision': 0.7632398753894081, 'recal...   \n",
       "14  {'0': {'precision': 0.7715846994535519, 'recal...   \n",
       "42  {'0': {'precision': 0.7676130389064143, 'recal...   \n",
       "46  {'0': {'precision': 0.7495069033530573, 'recal...   \n",
       "68  {'0': {'precision': 0.774331550802139, 'recall...   \n",
       "40  {'0': {'precision': 0.7730646871686108, 'recal...   \n",
       "12  {'0': {'precision': 0.7631296891747053, 'recal...   \n",
       "61  {'0': {'precision': 0.7608040201005025, 'recal...   \n",
       "58  {'0': {'precision': 0.7801268498942917, 'recal...   \n",
       "43  {'0': {'precision': 0.7686567164179104, 'recal...   \n",
       "64  {'0': {'precision': 0.7440711462450593, 'recal...   \n",
       "18  {'0': {'precision': 0.7592190889370932, 'recal...   \n",
       "35  {'0': {'precision': 0.7597402597402597, 'recal...   \n",
       "39  {'0': {'precision': 0.7608465608465609, 'recal...   \n",
       "41  {'0': {'precision': 0.7659352142110762, 'recal...   \n",
       "33  {'0': {'precision': 0.7600872410032715, 'recal...   \n",
       "27  {'0': {'precision': 0.7575431034482759, 'recal...   \n",
       "34  {'0': {'precision': 0.7562296858071506, 'recal...   \n",
       "\n",
       "                                           val_report  val_accuracy  \\\n",
       "44  {'0': {'precision': 0.7389558232931727, 'recal...      0.769424   \n",
       "51  {'0': {'precision': 0.7330677290836654, 'recal...      0.764411   \n",
       "55  {'0': {'precision': 0.7269076305220884, 'recal...      0.754386   \n",
       "52  {'0': {'precision': 0.7198443579766537, 'recal...      0.754386   \n",
       "47  {'0': {'precision': 0.7276422764227642, 'recal...      0.751880   \n",
       "37  {'0': {'precision': 0.7295081967213115, 'recal...      0.751880   \n",
       "56  {'0': {'precision': 0.7333333333333333, 'recal...      0.751880   \n",
       "60  {'0': {'precision': 0.7176470588235294, 'recal...      0.749373   \n",
       "66  {'0': {'precision': 0.7176470588235294, 'recal...      0.749373   \n",
       "36  {'0': {'precision': 0.7246963562753036, 'recal...      0.749373   \n",
       "45  {'0': {'precision': 0.7217741935483871, 'recal...      0.746867   \n",
       "49  {'0': {'precision': 0.7115384615384616, 'recal...      0.746867   \n",
       "57  {'0': {'precision': 0.7182539682539683, 'recal...      0.746867   \n",
       "59  {'0': {'precision': 0.71484375, 'recall': 0.86...      0.746867   \n",
       "2   {'0': {'precision': 0.7235772357723578, 'recal...      0.746867   \n",
       "67  {'0': {'precision': 0.7188755020080321, 'recal...      0.744361   \n",
       "53  {'0': {'precision': 0.7142857142857143, 'recal...      0.741855   \n",
       "29  {'0': {'precision': 0.7125984251968503, 'recal...      0.741855   \n",
       "62  {'0': {'precision': 0.7109375, 'recall': 0.862...      0.741855   \n",
       "14  {'0': {'precision': 0.717741935483871, 'recall...      0.741855   \n",
       "42  {'0': {'precision': 0.7142857142857143, 'recal...      0.741855   \n",
       "46  {'0': {'precision': 0.7, 'recall': 0.895734597...      0.741855   \n",
       "68  {'0': {'precision': 0.717741935483871, 'recall...      0.741855   \n",
       "40  {'0': {'precision': 0.7154471544715447, 'recal...      0.736842   \n",
       "12  {'0': {'precision': 0.7086614173228346, 'recal...      0.736842   \n",
       "61  {'0': {'precision': 0.6981132075471698, 'recal...      0.734336   \n",
       "58  {'0': {'precision': 0.7091633466135459, 'recal...      0.734336   \n",
       "43  {'0': {'precision': 0.7131147540983607, 'recal...      0.731830   \n",
       "64  {'0': {'precision': 0.6914498141263941, 'recal...      0.729323   \n",
       "18  {'0': {'precision': 0.7003891050583657, 'recal...      0.729323   \n",
       "35  {'0': {'precision': 0.7019607843137254, 'recal...      0.729323   \n",
       "39  {'0': {'precision': 0.7068273092369478, 'recal...      0.729323   \n",
       "41  {'0': {'precision': 0.7068273092369478, 'recal...      0.729323   \n",
       "33  {'0': {'precision': 0.7007874015748031, 'recal...      0.726817   \n",
       "27  {'0': {'precision': 0.6976744186046512, 'recal...      0.726817   \n",
       "34  {'0': {'precision': 0.6937984496124031, 'recal...      0.721805   \n",
       "\n",
       "    train_accuracy  \n",
       "44        0.750628  \n",
       "51        0.754397  \n",
       "55        0.742462  \n",
       "52        0.736809  \n",
       "47        0.750628  \n",
       "37        0.744975  \n",
       "56        0.744347  \n",
       "60        0.744975  \n",
       "66        0.744347  \n",
       "36        0.748744  \n",
       "45        0.745603  \n",
       "49        0.744975  \n",
       "57        0.750000  \n",
       "59        0.736809  \n",
       "2         0.734925  \n",
       "67        0.744347  \n",
       "53        0.748116  \n",
       "29        0.728015  \n",
       "62        0.743090  \n",
       "14        0.736809  \n",
       "42        0.744347  \n",
       "46        0.742462  \n",
       "68        0.746859  \n",
       "40        0.748116  \n",
       "12        0.733040  \n",
       "61        0.750628  \n",
       "58        0.757538  \n",
       "43        0.741206  \n",
       "64        0.734925  \n",
       "18        0.724874  \n",
       "35        0.726131  \n",
       "39        0.734296  \n",
       "41        0.744347  \n",
       "33        0.724246  \n",
       "27        0.724874  \n",
       "34        0.721734  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val_accuracy_by_linguistic_features(linguistic_report_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "02b7eb09",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d8a52fb56424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreport_df_ngram_lexicon_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_df_ngram_lexicon_only\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_report'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_report'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ngram_trans'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linguistic_trans'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'users_trans'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_latex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "563d4206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrr}\n",
      "\\toprule\n",
      "{} &    lexicon\\_trans &                                linguistic\\_trans &  val\\_accuracy &  train\\_accuracy \\\\\n",
      "\\midrule\n",
      "44 &          ['vad'] &        ['reference\\_to\\_opponent', 'swear\\_words'] &      0.769424 &        0.750628 \\\\\n",
      "51 &          ['vad'] &            ['swear\\_words', 'personal\\_pronouns'] &      0.764411 &        0.754397 \\\\\n",
      "55 &          ['vad'] &                       ['swear\\_words', 'number'] &      0.754386 &        0.742462 \\\\\n",
      "52 &          ['vad'] &                    ['swear\\_words', 'questions'] &      0.754386 &        0.736809 \\\\\n",
      "47 &          ['vad'] &           ['reference\\_to\\_opponent', 'websites'] &      0.751880 &        0.750628 \\\\\n",
      "37 &          ['vad'] &                       ['length', 'swear\\_words'] &      0.751880 &        0.744975 \\\\\n",
      "56 &          ['vad'] &                   ['swear\\_words', 'modal\\_verb'] &      0.751880 &        0.744347 \\\\\n",
      "60 &          ['vad'] &                 ['personal\\_pronouns', 'number'] &      0.749373 &        0.744975 \\\\\n",
      "66 &          ['vad'] &                     ['websites', 'exclamation'] &      0.749373 &        0.744347 \\\\\n",
      "36 &          ['vad'] &             ['length', 'reference\\_to\\_opponent'] &      0.749373 &        0.748744 \\\\\n",
      "45 &          ['vad'] &  ['reference\\_to\\_opponent', 'personal\\_pronouns'] &      0.746867 &        0.745603 \\\\\n",
      "49 &          ['vad'] &             ['reference\\_to\\_opponent', 'number'] &      0.746867 &        0.744975 \\\\\n",
      "57 &          ['vad'] &              ['personal\\_pronouns', 'questions'] &      0.746867 &        0.750000 \\\\\n",
      "59 &          ['vad'] &            ['personal\\_pronouns', 'exclamation'] &      0.746867 &        0.736809 \\\\\n",
      "2  &  ['connotation'] &                 ['length', 'personal\\_pronouns'] &      0.746867 &        0.734925 \\\\\n",
      "67 &          ['vad'] &                          ['websites', 'number'] &      0.744361 &        0.744347 \\\\\n",
      "53 &          ['vad'] &                     ['swear\\_words', 'websites'] &      0.741855 &        0.748116 \\\\\n",
      "29 &  ['connotation'] &                     ['questions', 'modal\\_verb'] &      0.741855 &        0.728015 \\\\\n",
      "62 &          ['vad'] &                       ['questions', 'websites'] &      0.741855 &        0.743090 \\\\\n",
      "14 &  ['connotation'] &         ['reference\\_to\\_opponent', 'modal\\_verb'] &      0.741855 &        0.736809 \\\\\n",
      "42 &          ['vad'] &                            ['length', 'number'] &      0.741855 &        0.744347 \\\\\n",
      "46 &          ['vad'] &          ['reference\\_to\\_opponent', 'questions'] &      0.741855 &        0.742462 \\\\\n",
      "68 &          ['vad'] &                      ['websites', 'modal\\_verb'] &      0.741855 &        0.746859 \\\\\n",
      "40 &          ['vad'] &                          ['length', 'websites'] &      0.736842 &        0.748116 \\\\\n",
      "12 &  ['connotation'] &        ['reference\\_to\\_opponent', 'exclamation'] &      0.736842 &        0.733040 \\\\\n",
      "61 &          ['vad'] &             ['personal\\_pronouns', 'modal\\_verb'] &      0.734336 &        0.750628 \\\\\n",
      "58 &          ['vad'] &               ['personal\\_pronouns', 'websites'] &      0.734336 &        0.757538 \\\\\n",
      "43 &          ['vad'] &                        ['length', 'modal\\_verb'] &      0.731830 &        0.741206 \\\\\n",
      "64 &          ['vad'] &                         ['questions', 'number'] &      0.729323 &        0.734925 \\\\\n",
      "18 &  ['connotation'] &                  ['swear\\_words', 'exclamation'] &      0.729323 &        0.724874 \\\\\n",
      "35 &  ['connotation'] &                        ['number', 'modal\\_verb'] &      0.729323 &        0.726131 \\\\\n",
      "39 &          ['vad'] &                         ['length', 'questions'] &      0.729323 &        0.734296 \\\\\n",
      "41 &          ['vad'] &                       ['length', 'exclamation'] &      0.729323 &        0.744347 \\\\\n",
      "33 &  ['connotation'] &                       ['exclamation', 'number'] &      0.726817 &        0.724246 \\\\\n",
      "27 &  ['connotation'] &                    ['questions', 'exclamation'] &      0.726817 &        0.724874 \\\\\n",
      "34 &  ['connotation'] &                   ['exclamation', 'modal\\_verb'] &      0.721805 &        0.721734 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(max_val_accuracy_by_linguistic_features(report_df_ngram_lexicon_linguistic_only).drop(columns=['train_report', 'ngram_trans', 'val_report', 'users_trans']).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a0af86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_trans</th>\n",
       "      <th>lexicon_trans</th>\n",
       "      <th>linguistic_trans</th>\n",
       "      <th>users_trans</th>\n",
       "      <th>train_report</th>\n",
       "      <th>val_report</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.817047817047817, 'recall...</td>\n",
       "      <td>{'0': {'precision': 0.7075098814229249, 'recal...</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>0.807789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7622682660850599, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7035573122529645, 'recal...</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.726759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ngram_trans    lexicon_trans linguistic_trans users_trans  \\\n",
       "1  ['trigram']          ['vad']               []          []   \n",
       "0  ['trigram']  ['connotation']               []          []   \n",
       "\n",
       "                                        train_report  \\\n",
       "1  {'0': {'precision': 0.817047817047817, 'recall...   \n",
       "0  {'0': {'precision': 0.7622682660850599, 'recal...   \n",
       "\n",
       "                                          val_report  val_accuracy  \\\n",
       "1  {'0': {'precision': 0.7075098814229249, 'recal...      0.734336   \n",
       "0  {'0': {'precision': 0.7035573122529645, 'recal...      0.729323   \n",
       "\n",
       "   train_accuracy  \n",
       "1        0.807789  \n",
       "0        0.726759  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val_accuracy_by_lexicon_features(lexicon_report_df[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58528a",
   "metadata": {},
   "source": [
    "print(max_val_accuracy_by_lexicon_features(linguistic_report_df[0]).drop(columns=['train_report', 'val_report', 'ngram_trans', 'linguistic_trans', 'users_trans']).to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('env_nlp': conda)",
   "language": "python",
   "name": "python3613jvsc74a57bd0f78e94ca1a29e9011c2866c841de859bf08fcc5b57f07b9ffb161018ea406f8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
