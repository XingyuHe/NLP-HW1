{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7003901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from numpy.lib.function_base import vectorize\n",
    "import pandas as pd \n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy import sparse\n",
    "from scipy.spatial import distance\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from better_profanity import profanity\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2712fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTITION_REPORT_PATH = './resources/report/partition/'\n",
    "PARTITION_NGRAM_ONLY = PARTITION_REPORT_PATH + 'ngram_only.csv'\n",
    "PARTITION_NGRAM_LEXICON_ONLY = PARTITION_REPORT_PATH + 'ngram_lexicon_only.csv'\n",
    "PARTITION_NGRAM_LEXICON_LINGUISTIC_ONLY = PARTITION_REPORT_PATH + 'ngram_lexicon_linguistic_only.csv'\n",
    "PARTITION_NGRAM_LINGUISTIC_ONLY = PARTITION_REPORT_PATH + 'ngram_linguistic_only.csv'\n",
    "PARTITION_NGRAM_LEXICON_LINGUISTIC_USERS_ONLY = PARTITION_REPORT_PATH + 'ngram_lexicon_linguistic_users_only.csv'\n",
    "\n",
    "partition_report_df_ngram_only = pd.read_csv(PARTITION_NGRAM_ONLY, index_col=0)\n",
    "partition_report_df_ngram_lexicon_only = pd.read_csv(PARTITION_NGRAM_LEXICON_ONLY, index_col=0)\n",
    "partition_report_df_ngram_linguistic_only = pd.read_csv(PARTITION_NGRAM_LINGUISTIC_ONLY, index_col=0)\n",
    "partition_report_df_ngram_lexicon_linguistic_only = pd.read_csv(PARTITION_NGRAM_LEXICON_LINGUISTIC_ONLY, index_col=0)\n",
    "# partition_report_df_ngram_lexicon_linguistic_users_only = pd.read_csv(PARTITION_NGRAM_LEXICON_LINGUISTIC_USERS_ONLY, index_col=0)\n",
    "\n",
    "partition_all_report_df = [\n",
    "                            partition_report_df_ngram_lexicon_linguistic_only, \n",
    "                            partition_report_df_ngram_lexicon_only, \n",
    "                            partition_report_df_ngram_linguistic_only,\n",
    "                            partition_report_df_ngram_only\n",
    "#                             partition_report_df_ngram_lexicon_linguistic_users_only                \n",
    "                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b53d44fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_trans</th>\n",
       "      <th>lexicon_trans</th>\n",
       "      <th>linguistic_trans</th>\n",
       "      <th>users_trans</th>\n",
       "      <th>train_report_partition_0</th>\n",
       "      <th>val_report_partition_0</th>\n",
       "      <th>train_report_partition_1</th>\n",
       "      <th>val_report_partition_1</th>\n",
       "      <th>val_report_partition_0_accuracy</th>\n",
       "      <th>val_report_partition_1_accuracy</th>\n",
       "      <th>train_report_partition_0_accuracy</th>\n",
       "      <th>train_report_partition_1_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'reference_to_opponent']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7784172661870503, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7172131147540983, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7520661157024794, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5862068965517241, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.750409</td>\n",
       "      <td>0.724324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'swear_words']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7766272189349113, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7219917012448133, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7615062761506276, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5964912280701754, 'recal...</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.739771</td>\n",
       "      <td>0.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7774524158125915, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7037037037037037, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7672413793103449, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6607142857142857, 'recal...</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.743863</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7692307692307693, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7208333333333333, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7542372881355932, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6274509803921569, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.737316</td>\n",
       "      <td>0.718919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7769679300291545, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7280334728033473, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7617021276595745, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6, 'recall': 0.785714285...</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.727027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7793296089385475, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7235772357723578, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7426160337552743, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6349206349206349, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.761047</td>\n",
       "      <td>0.705405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7842857142857143, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7213114754098361, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7458333333333333, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5873015873015873, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.759411</td>\n",
       "      <td>0.713514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['exclamation', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7366459627329193, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6884057971014492, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7520661157024794, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5625, 'recall': 0.857142...</td>\n",
       "      <td>0.731830</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.745499</td>\n",
       "      <td>0.724324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['exclamation', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7453183520599251, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6851851851851852, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7450199203187251, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5645161290322581, 'recal...</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.727027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['number', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7740112994350282, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.725, 'recall': 0.8246445...</td>\n",
       "      <td>{'0': {'precision': 0.7185185185185186, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5352112676056338, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.751227</td>\n",
       "      <td>0.713514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram_trans    lexicon_trans                     linguistic_trans  \\\n",
       "0   ['trigram']  ['connotation']  ['length', 'reference_to_opponent']   \n",
       "1   ['trigram']  ['connotation']            ['length', 'swear_words']   \n",
       "2   ['trigram']  ['connotation']      ['length', 'personal_pronouns']   \n",
       "3   ['trigram']  ['connotation']              ['length', 'questions']   \n",
       "4   ['trigram']  ['connotation']               ['length', 'websites']   \n",
       "..          ...              ...                                  ...   \n",
       "67  ['trigram']          ['vad']               ['websites', 'number']   \n",
       "68  ['trigram']          ['vad']           ['websites', 'modal_verb']   \n",
       "69  ['trigram']          ['vad']            ['exclamation', 'number']   \n",
       "70  ['trigram']          ['vad']        ['exclamation', 'modal_verb']   \n",
       "71  ['trigram']          ['vad']             ['number', 'modal_verb']   \n",
       "\n",
       "   users_trans                           train_report_partition_0  \\\n",
       "0           []  {'0': {'precision': 0.7784172661870503, 'recal...   \n",
       "1           []  {'0': {'precision': 0.7766272189349113, 'recal...   \n",
       "2           []  {'0': {'precision': 0.7774524158125915, 'recal...   \n",
       "3           []  {'0': {'precision': 0.7692307692307693, 'recal...   \n",
       "4           []  {'0': {'precision': 0.7769679300291545, 'recal...   \n",
       "..         ...                                                ...   \n",
       "67          []  {'0': {'precision': 0.7793296089385475, 'recal...   \n",
       "68          []  {'0': {'precision': 0.7842857142857143, 'recal...   \n",
       "69          []  {'0': {'precision': 0.7366459627329193, 'recal...   \n",
       "70          []  {'0': {'precision': 0.7453183520599251, 'recal...   \n",
       "71          []  {'0': {'precision': 0.7740112994350282, 'recal...   \n",
       "\n",
       "                               val_report_partition_0  \\\n",
       "0   {'0': {'precision': 0.7172131147540983, 'recal...   \n",
       "1   {'0': {'precision': 0.7219917012448133, 'recal...   \n",
       "2   {'0': {'precision': 0.7037037037037037, 'recal...   \n",
       "3   {'0': {'precision': 0.7208333333333333, 'recal...   \n",
       "4   {'0': {'precision': 0.7280334728033473, 'recal...   \n",
       "..                                                ...   \n",
       "67  {'0': {'precision': 0.7235772357723578, 'recal...   \n",
       "68  {'0': {'precision': 0.7213114754098361, 'recal...   \n",
       "69  {'0': {'precision': 0.6884057971014492, 'recal...   \n",
       "70  {'0': {'precision': 0.6851851851851852, 'recal...   \n",
       "71  {'0': {'precision': 0.725, 'recall': 0.8246445...   \n",
       "\n",
       "                             train_report_partition_1  \\\n",
       "0   {'0': {'precision': 0.7520661157024794, 'recal...   \n",
       "1   {'0': {'precision': 0.7615062761506276, 'recal...   \n",
       "2   {'0': {'precision': 0.7672413793103449, 'recal...   \n",
       "3   {'0': {'precision': 0.7542372881355932, 'recal...   \n",
       "4   {'0': {'precision': 0.7617021276595745, 'recal...   \n",
       "..                                                ...   \n",
       "67  {'0': {'precision': 0.7426160337552743, 'recal...   \n",
       "68  {'0': {'precision': 0.7458333333333333, 'recal...   \n",
       "69  {'0': {'precision': 0.7520661157024794, 'recal...   \n",
       "70  {'0': {'precision': 0.7450199203187251, 'recal...   \n",
       "71  {'0': {'precision': 0.7185185185185186, 'recal...   \n",
       "\n",
       "                               val_report_partition_1  \\\n",
       "0   {'0': {'precision': 0.5862068965517241, 'recal...   \n",
       "1   {'0': {'precision': 0.5964912280701754, 'recal...   \n",
       "2   {'0': {'precision': 0.6607142857142857, 'recal...   \n",
       "3   {'0': {'precision': 0.6274509803921569, 'recal...   \n",
       "4   {'0': {'precision': 0.6, 'recall': 0.785714285...   \n",
       "..                                                ...   \n",
       "67  {'0': {'precision': 0.6349206349206349, 'recal...   \n",
       "68  {'0': {'precision': 0.5873015873015873, 'recal...   \n",
       "69  {'0': {'precision': 0.5625, 'recall': 0.857142...   \n",
       "70  {'0': {'precision': 0.5645161290322581, 'recal...   \n",
       "71  {'0': {'precision': 0.5352112676056338, 'recal...   \n",
       "\n",
       "    val_report_partition_0_accuracy  val_report_partition_1_accuracy  \\\n",
       "0                          0.736842                         0.655914   \n",
       "1                          0.739348                         0.666667   \n",
       "2                          0.719298                         0.741935   \n",
       "3                          0.736842                         0.688172   \n",
       "4                          0.744361                         0.666667   \n",
       "..                              ...                              ...   \n",
       "67                         0.746867                         0.731183   \n",
       "68                         0.741855                         0.666667   \n",
       "69                         0.731830                         0.634409   \n",
       "70                         0.721805                         0.634409   \n",
       "71                         0.741855                         0.602151   \n",
       "\n",
       "    train_report_partition_0_accuracy  train_report_partition_1_accuracy  \n",
       "0                            0.750409                           0.724324  \n",
       "1                            0.739771                           0.732432  \n",
       "2                            0.743863                           0.729730  \n",
       "3                            0.737316                           0.718919  \n",
       "4                            0.744681                           0.727027  \n",
       "..                                ...                                ...  \n",
       "67                           0.761047                           0.705405  \n",
       "68                           0.759411                           0.713514  \n",
       "69                           0.745499                           0.724324  \n",
       "70                           0.755319                           0.727027  \n",
       "71                           0.751227                           0.713514  \n",
       "\n",
       "[72 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_report_df_ngram_lexicon_linguistic_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0675db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_names = [\n",
    "                'val_report_partition_0',\n",
    "                'val_report_partition_1',\n",
    "                'train_report_partition_0',\n",
    "                'train_report_partition_1']\n",
    "\n",
    "def convert_report_to_dict(report_df):\n",
    "    for col_name in report_names:\n",
    "        report_df.loc[:, col_name] = report_df.loc[:, col_name].apply(lambda row: eval(row))\n",
    "        \n",
    "def add_accuracy(report_df):\n",
    "    for col_name in report_names:\n",
    "        print(col_name + '_accuracy')\n",
    "        report_df[col_name + '_accuracy'] = report_df.loc[:, col_name].apply(lambda row: row['accuracy'])\n",
    "    \n",
    "def max_val_accuracy_by_linguistic_features(report_df):\n",
    "    grouped = report_df.groupby(['linguistic_trans'])\n",
    "    max_val_accuracy_by_linguistic = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        max_idx = group['val_accuracy'].argmax()\n",
    "        max_row = group.iloc[max_idx, :]\n",
    "        max_val_accuracy_by_linguistic.append(max_row)\n",
    "\n",
    "    df_max_val_accuracy_by_linguistic = pd.DataFrame(max_val_accuracy_by_linguistic)\n",
    "    return df_max_val_accuracy_by_linguistic.sort_values(by=['val_accuracy'], ascending=False)\n",
    "def max_val_accuracy_by_lexicon_features(report_df):\n",
    "    grouped = report_df.groupby(['lexicon_trans'])\n",
    "    max_val_accuracy_by_linguistic = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        max_idx = group['val_accuracy'].argmax()\n",
    "        max_row = group.iloc[max_idx, :]\n",
    "        max_val_accuracy_by_linguistic.append(max_row)\n",
    "\n",
    "    df_max_val_accuracy_by_lexicon = pd.DataFrame(max_val_accuracy_by_linguistic)\n",
    "    return df_max_val_accuracy_by_lexicon.sort_values(by=['val_accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2053d90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_trans</th>\n",
       "      <th>lexicon_trans</th>\n",
       "      <th>linguistic_trans</th>\n",
       "      <th>users_trans</th>\n",
       "      <th>train_report_partition_0</th>\n",
       "      <th>val_report_partition_0</th>\n",
       "      <th>train_report_partition_1</th>\n",
       "      <th>val_report_partition_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.896978021978022, 'recall...</td>\n",
       "      <td>{'0': {'precision': 0.704, 'recall': 0.8341232...</td>\n",
       "      <td>{'0': {'precision': 0.8615384615384616, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5616438356164384, 'recal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ngram_trans lexicon_trans linguistic_trans users_trans  \\\n",
       "0  ['trigram']            []               []          []   \n",
       "\n",
       "                            train_report_partition_0  \\\n",
       "0  {'0': {'precision': 0.896978021978022, 'recall...   \n",
       "\n",
       "                              val_report_partition_0  \\\n",
       "0  {'0': {'precision': 0.704, 'recall': 0.8341232...   \n",
       "\n",
       "                            train_report_partition_1  \\\n",
       "0  {'0': {'precision': 0.8615384615384616, 'recal...   \n",
       "\n",
       "                              val_report_partition_1  \n",
       "0  {'0': {'precision': 0.5616438356164384, 'recal...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_report_df_ngram_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28b2c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_report_partition_0_accuracy\n",
      "val_report_partition_1_accuracy\n",
      "train_report_partition_0_accuracy\n",
      "train_report_partition_1_accuracy\n",
      "val_report_partition_0_accuracy\n",
      "val_report_partition_1_accuracy\n",
      "train_report_partition_0_accuracy\n",
      "train_report_partition_1_accuracy\n",
      "val_report_partition_0_accuracy\n",
      "val_report_partition_1_accuracy\n",
      "train_report_partition_0_accuracy\n",
      "train_report_partition_1_accuracy\n",
      "val_report_partition_0_accuracy\n",
      "val_report_partition_1_accuracy\n",
      "train_report_partition_0_accuracy\n",
      "train_report_partition_1_accuracy\n"
     ]
    }
   ],
   "source": [
    "for report_df in partition_all_report_df:\n",
    "    convert_report_to_dict(report_df)\n",
    "    add_accuracy(report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45eae02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  religious validation accuracy &  non religious validation accuracy &  validation accuracy \\\\\n",
      "\\midrule\n",
      "47 &                       0.751880 &                           0.741935 &             0.744253 \\\\\n",
      "44 &                       0.761905 &                           0.731183 &             0.738344 \\\\\n",
      "53 &                       0.759398 &                           0.731183 &             0.737759 \\\\\n",
      "2  &                       0.719298 &                           0.741935 &             0.736659 \\\\\n",
      "67 &                       0.746867 &                           0.731183 &             0.734839 \\\\\n",
      "62 &                       0.734336 &                           0.731183 &             0.731918 \\\\\n",
      "66 &                       0.726817 &                           0.731183 &             0.730165 \\\\\n",
      "38 &                       0.761905 &                           0.720430 &             0.730097 \\\\\n",
      "40 &                       0.749373 &                           0.709677 &             0.718930 \\\\\n",
      "39 &                       0.736842 &                           0.709677 &             0.716009 \\\\\n",
      "45 &                       0.736842 &                           0.709677 &             0.716009 \\\\\n",
      "51 &                       0.764411 &                           0.698925 &             0.714188 \\\\\n",
      "36 &                       0.746867 &                           0.698925 &             0.710099 \\\\\n",
      "57 &                       0.744361 &                           0.698925 &             0.709515 \\\\\n",
      "64 &                       0.731830 &                           0.698925 &             0.706594 \\\\\n",
      "60 &                       0.764411 &                           0.688172 &             0.705942 \\\\\n",
      "37 &                       0.746867 &                           0.688172 &             0.701853 \\\\\n",
      "59 &                       0.741855 &                           0.688172 &             0.700685 \\\\\n",
      "3  &                       0.736842 &                           0.688172 &             0.699516 \\\\\n",
      "58 &                       0.734336 &                           0.688172 &             0.698932 \\\\\n",
      "7  &                       0.729323 &                           0.688172 &             0.697764 \\\\\n",
      "52 &                       0.754386 &                           0.677419 &             0.695359 \\\\\n",
      "9  &                       0.751880 &                           0.677419 &             0.694775 \\\\\n",
      "61 &                       0.749373 &                           0.677419 &             0.694191 \\\\\n",
      "42 &                       0.749373 &                           0.677419 &             0.694191 \\\\\n",
      "49 &                       0.744361 &                           0.677419 &             0.693022 \\\\\n",
      "56 &                       0.736842 &                           0.677419 &             0.691270 \\\\\n",
      "54 &                       0.721805 &                           0.677419 &             0.687765 \\\\\n",
      "4  &                       0.744361 &                           0.666667 &             0.684776 \\\\\n",
      "68 &                       0.741855 &                           0.666667 &             0.684192 \\\\\n",
      "55 &                       0.739348 &                           0.666667 &             0.683608 \\\\\n",
      "1  &                       0.739348 &                           0.666667 &             0.683608 \\\\\n",
      "65 &                       0.729323 &                           0.666667 &             0.681271 \\\\\n",
      "50 &                       0.759398 &                           0.655914 &             0.680034 \\\\\n",
      "15 &                       0.741855 &                           0.655914 &             0.675945 \\\\\n",
      "0  &                       0.736842 &                           0.655914 &             0.674777 \\\\\n",
      "5  &                       0.726817 &                           0.655914 &             0.672440 \\\\\n",
      "63 &                       0.719298 &                           0.655914 &             0.670688 \\\\\n",
      "6  &                       0.736842 &                           0.645161 &             0.666531 \\\\\n",
      "43 &                       0.734336 &                           0.645161 &             0.665946 \\\\\n",
      "19 &                       0.734336 &                           0.645161 &             0.665946 \\\\\n",
      "46 &                       0.734336 &                           0.645161 &             0.665946 \\\\\n",
      "48 &                       0.731830 &                           0.645161 &             0.665362 \\\\\n",
      "30 &                       0.714286 &                           0.645161 &             0.661273 \\\\\n",
      "11 &                       0.734336 &                           0.634409 &             0.657700 \\\\\n",
      "33 &                       0.731830 &                           0.634409 &             0.657116 \\\\\n",
      "69 &                       0.731830 &                           0.634409 &             0.657116 \\\\\n",
      "23 &                       0.731830 &                           0.634409 &             0.657116 \\\\\n",
      "24 &                       0.729323 &                           0.634409 &             0.656532 \\\\\n",
      "41 &                       0.729323 &                           0.634409 &             0.656532 \\\\\n",
      "22 &                       0.729323 &                           0.634409 &             0.656532 \\\\\n",
      "26 &                       0.729323 &                           0.634409 &             0.656532 \\\\\n",
      "21 &                       0.726817 &                           0.634409 &             0.655947 \\\\\n",
      "70 &                       0.721805 &                           0.634409 &             0.654779 \\\\\n",
      "31 &                       0.734336 &                           0.623656 &             0.649453 \\\\\n",
      "25 &                       0.734336 &                           0.623656 &             0.649453 \\\\\n",
      "8  &                       0.749373 &                           0.612903 &             0.644712 \\\\\n",
      "28 &                       0.744361 &                           0.612903 &             0.643544 \\\\\n",
      "27 &                       0.736842 &                           0.612903 &             0.641791 \\\\\n",
      "12 &                       0.724311 &                           0.612903 &             0.638870 \\\\\n",
      "71 &                       0.741855 &                           0.602151 &             0.634713 \\\\\n",
      "13 &                       0.736842 &                           0.602151 &             0.633545 \\\\\n",
      "20 &                       0.741855 &                           0.591398 &             0.626467 \\\\\n",
      "17 &                       0.739348 &                           0.591398 &             0.625883 \\\\\n",
      "35 &                       0.736842 &                           0.591398 &             0.625298 \\\\\n",
      "32 &                       0.724311 &                           0.591398 &             0.622378 \\\\\n",
      "29 &                       0.741855 &                           0.580645 &             0.618220 \\\\\n",
      "16 &                       0.731830 &                           0.580645 &             0.615884 \\\\\n",
      "34 &                       0.729323 &                           0.580645 &             0.615299 \\\\\n",
      "10 &                       0.744361 &                           0.569892 &             0.610558 \\\\\n",
      "14 &                       0.739348 &                           0.569892 &             0.609390 \\\\\n",
      "18 &                       0.739348 &                           0.569892 &             0.609390 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xhe/opt/anaconda3/envs/env_nlp/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "rel_df = partition_report_df_ngram_lexicon_linguistic_only.sort_values(by=['val_report_partition_1_accuracy'], ascending=False)\n",
    "report = rel_df[['val_report_partition_0_accuracy', 'val_report_partition_1_accuracy']]\n",
    "report.columns = ['religious validation accuracy', 'non religious validation accuracy']\n",
    "report['validation accuracy'] = (report.iloc[:, 0] * 93 + report.iloc[:, 1] * 306) / (399)\n",
    "print(report.sort_values(by=['validation accuracy'], ascending=False).to_latex())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0574abb",
   "metadata": {},
   "source": [
    "nonrel_df = partition_report_df_ngram_lexicon_linguistic_only.sort_values(by=['val_report_partition_0_accuracy'], ascending=False)\n",
    "nonrel_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('env_nlp': conda)",
   "language": "python",
   "name": "python3613jvsc74a57bd0f78e94ca1a29e9011c2866c841de859bf08fcc5b57f07b9ffb161018ea406f8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
