{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b96b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from numpy.lib.function_base import vectorize\n",
    "import pandas as pd \n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy import sparse\n",
    "from scipy.spatial import distance\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from better_profanity import profanity\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b83721bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTITION_REPORT_PATH = './resources/report/partition/'\n",
    "PARTITION_NGRAM_ONLY = PARTITION_REPORT_PATH + 'ngram_only.csv'\n",
    "PARTITION_NGRAM_LEXICON_ONLY = PARTITION_REPORT_PATH + 'ngram_lexicon_only.csv'\n",
    "PARTITION_NGRAM_LEXICON_LINGUISTIC_ONLY = PARTITION_REPORT_PATH + 'ngram_lexicon_linguistic_only.csv'\n",
    "PARTITION_NGRAM_LINGUISTIC_ONLY = PARTITION_REPORT_PATH + 'ngram_linguistic_only.csv'\n",
    "PARTITION_NGRAM_LEXICON_LINGUISTIC_USERS_ONLY = PARTITION_REPORT_PATH + 'ngram_lexicon_linguistic_users_only.csv'\n",
    "\n",
    "partition_report_df_ngram_only = pd.read_csv(PARTITION_NGRAM_ONLY, index_col=0)\n",
    "partition_report_df_ngram_lexicon_only = pd.read_csv(PARTITION_NGRAM_LEXICON_ONLY, index_col=0)\n",
    "partition_report_df_ngram_linguistic_only = pd.read_csv(PARTITION_NGRAM_LINGUISTIC_ONLY, index_col=0)\n",
    "partition_report_df_ngram_lexicon_linguistic_only = pd.read_csv(PARTITION_NGRAM_LEXICON_LINGUISTIC_ONLY, index_col=0)\n",
    "# partition_report_df_ngram_lexicon_linguistic_users_only = pd.read_csv(PARTITION_NGRAM_LEXICON_LINGUISTIC_USERS_ONLY, index_col=0)\n",
    "\n",
    "partition_all_report_df = [\n",
    "                            partition_report_df_ngram_lexicon_linguistic_only, \n",
    "                            partition_report_df_ngram_lexicon_only, \n",
    "                            partition_report_df_ngram_linguistic_only,\n",
    "                            partition_report_df_ngram_only\n",
    "#                             partition_report_df_ngram_lexicon_linguistic_users_only                \n",
    "                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06c84888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_trans</th>\n",
       "      <th>lexicon_trans</th>\n",
       "      <th>linguistic_trans</th>\n",
       "      <th>users_trans</th>\n",
       "      <th>train_report_partition_0</th>\n",
       "      <th>val_report_partition_0</th>\n",
       "      <th>train_report_partition_1</th>\n",
       "      <th>val_report_partition_1</th>\n",
       "      <th>val_report_partition_0_accuracy</th>\n",
       "      <th>val_report_partition_1_accuracy</th>\n",
       "      <th>train_report_partition_0_accuracy</th>\n",
       "      <th>train_report_partition_1_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'reference_to_opponent']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7784172661870503, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7172131147540983, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7520661157024794, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5862068965517241, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.750409</td>\n",
       "      <td>0.724324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'swear_words']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7766272189349113, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7219917012448133, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7615062761506276, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5964912280701754, 'recal...</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.739771</td>\n",
       "      <td>0.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'personal_pronouns']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7774524158125915, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7037037037037037, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7672413793103449, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6607142857142857, 'recal...</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.743863</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'questions']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7692307692307693, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7208333333333333, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7542372881355932, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6274509803921569, 'recal...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.737316</td>\n",
       "      <td>0.718919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['connotation']</td>\n",
       "      <td>['length', 'websites']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7769679300291545, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7280334728033473, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7617021276595745, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6, 'recall': 0.785714285...</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.727027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7793296089385475, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7235772357723578, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7426160337552743, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6349206349206349, 'recal...</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.761047</td>\n",
       "      <td>0.705405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['websites', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7842857142857143, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7213114754098361, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7458333333333333, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5873015873015873, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.759411</td>\n",
       "      <td>0.713514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['exclamation', 'number']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7366459627329193, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6884057971014492, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7520661157024794, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5625, 'recall': 0.857142...</td>\n",
       "      <td>0.731830</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.745499</td>\n",
       "      <td>0.724324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['exclamation', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7453183520599251, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.6851851851851852, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.7450199203187251, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5645161290322581, 'recal...</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.727027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>['vad']</td>\n",
       "      <td>['number', 'modal_verb']</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.7740112994350282, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.725, 'recall': 0.8246445...</td>\n",
       "      <td>{'0': {'precision': 0.7185185185185186, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5352112676056338, 'recal...</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.751227</td>\n",
       "      <td>0.713514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram_trans    lexicon_trans                     linguistic_trans  \\\n",
       "0   ['trigram']  ['connotation']  ['length', 'reference_to_opponent']   \n",
       "1   ['trigram']  ['connotation']            ['length', 'swear_words']   \n",
       "2   ['trigram']  ['connotation']      ['length', 'personal_pronouns']   \n",
       "3   ['trigram']  ['connotation']              ['length', 'questions']   \n",
       "4   ['trigram']  ['connotation']               ['length', 'websites']   \n",
       "..          ...              ...                                  ...   \n",
       "67  ['trigram']          ['vad']               ['websites', 'number']   \n",
       "68  ['trigram']          ['vad']           ['websites', 'modal_verb']   \n",
       "69  ['trigram']          ['vad']            ['exclamation', 'number']   \n",
       "70  ['trigram']          ['vad']        ['exclamation', 'modal_verb']   \n",
       "71  ['trigram']          ['vad']             ['number', 'modal_verb']   \n",
       "\n",
       "   users_trans                           train_report_partition_0  \\\n",
       "0           []  {'0': {'precision': 0.7784172661870503, 'recal...   \n",
       "1           []  {'0': {'precision': 0.7766272189349113, 'recal...   \n",
       "2           []  {'0': {'precision': 0.7774524158125915, 'recal...   \n",
       "3           []  {'0': {'precision': 0.7692307692307693, 'recal...   \n",
       "4           []  {'0': {'precision': 0.7769679300291545, 'recal...   \n",
       "..         ...                                                ...   \n",
       "67          []  {'0': {'precision': 0.7793296089385475, 'recal...   \n",
       "68          []  {'0': {'precision': 0.7842857142857143, 'recal...   \n",
       "69          []  {'0': {'precision': 0.7366459627329193, 'recal...   \n",
       "70          []  {'0': {'precision': 0.7453183520599251, 'recal...   \n",
       "71          []  {'0': {'precision': 0.7740112994350282, 'recal...   \n",
       "\n",
       "                               val_report_partition_0  \\\n",
       "0   {'0': {'precision': 0.7172131147540983, 'recal...   \n",
       "1   {'0': {'precision': 0.7219917012448133, 'recal...   \n",
       "2   {'0': {'precision': 0.7037037037037037, 'recal...   \n",
       "3   {'0': {'precision': 0.7208333333333333, 'recal...   \n",
       "4   {'0': {'precision': 0.7280334728033473, 'recal...   \n",
       "..                                                ...   \n",
       "67  {'0': {'precision': 0.7235772357723578, 'recal...   \n",
       "68  {'0': {'precision': 0.7213114754098361, 'recal...   \n",
       "69  {'0': {'precision': 0.6884057971014492, 'recal...   \n",
       "70  {'0': {'precision': 0.6851851851851852, 'recal...   \n",
       "71  {'0': {'precision': 0.725, 'recall': 0.8246445...   \n",
       "\n",
       "                             train_report_partition_1  \\\n",
       "0   {'0': {'precision': 0.7520661157024794, 'recal...   \n",
       "1   {'0': {'precision': 0.7615062761506276, 'recal...   \n",
       "2   {'0': {'precision': 0.7672413793103449, 'recal...   \n",
       "3   {'0': {'precision': 0.7542372881355932, 'recal...   \n",
       "4   {'0': {'precision': 0.7617021276595745, 'recal...   \n",
       "..                                                ...   \n",
       "67  {'0': {'precision': 0.7426160337552743, 'recal...   \n",
       "68  {'0': {'precision': 0.7458333333333333, 'recal...   \n",
       "69  {'0': {'precision': 0.7520661157024794, 'recal...   \n",
       "70  {'0': {'precision': 0.7450199203187251, 'recal...   \n",
       "71  {'0': {'precision': 0.7185185185185186, 'recal...   \n",
       "\n",
       "                               val_report_partition_1  \\\n",
       "0   {'0': {'precision': 0.5862068965517241, 'recal...   \n",
       "1   {'0': {'precision': 0.5964912280701754, 'recal...   \n",
       "2   {'0': {'precision': 0.6607142857142857, 'recal...   \n",
       "3   {'0': {'precision': 0.6274509803921569, 'recal...   \n",
       "4   {'0': {'precision': 0.6, 'recall': 0.785714285...   \n",
       "..                                                ...   \n",
       "67  {'0': {'precision': 0.6349206349206349, 'recal...   \n",
       "68  {'0': {'precision': 0.5873015873015873, 'recal...   \n",
       "69  {'0': {'precision': 0.5625, 'recall': 0.857142...   \n",
       "70  {'0': {'precision': 0.5645161290322581, 'recal...   \n",
       "71  {'0': {'precision': 0.5352112676056338, 'recal...   \n",
       "\n",
       "    val_report_partition_0_accuracy  val_report_partition_1_accuracy  \\\n",
       "0                          0.736842                         0.655914   \n",
       "1                          0.739348                         0.666667   \n",
       "2                          0.719298                         0.741935   \n",
       "3                          0.736842                         0.688172   \n",
       "4                          0.744361                         0.666667   \n",
       "..                              ...                              ...   \n",
       "67                         0.746867                         0.731183   \n",
       "68                         0.741855                         0.666667   \n",
       "69                         0.731830                         0.634409   \n",
       "70                         0.721805                         0.634409   \n",
       "71                         0.741855                         0.602151   \n",
       "\n",
       "    train_report_partition_0_accuracy  train_report_partition_1_accuracy  \n",
       "0                            0.750409                           0.724324  \n",
       "1                            0.739771                           0.732432  \n",
       "2                            0.743863                           0.729730  \n",
       "3                            0.737316                           0.718919  \n",
       "4                            0.744681                           0.727027  \n",
       "..                                ...                                ...  \n",
       "67                           0.761047                           0.705405  \n",
       "68                           0.759411                           0.713514  \n",
       "69                           0.745499                           0.724324  \n",
       "70                           0.755319                           0.727027  \n",
       "71                           0.751227                           0.713514  \n",
       "\n",
       "[72 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_report_df_ngram_lexicon_linguistic_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3b0a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_names = [\n",
    "                'val_report_partition_0',\n",
    "                'val_report_partition_1',\n",
    "                'train_report_partition_0',\n",
    "                'train_report_partition_1']\n",
    "\n",
    "def convert_report_to_dict(report_df):\n",
    "    for col_name in report_names:\n",
    "        report_df.loc[:, col_name] = report_df.loc[:, col_name].apply(lambda row: eval(row))\n",
    "        \n",
    "def add_accuracy(report_df):\n",
    "    for col_name in report_names:\n",
    "        print(col_name + '_accuracy')\n",
    "        report_df[col_name + '_accuracy'] = report_df.loc[:, col_name].apply(lambda row: row['accuracy'])\n",
    "    \n",
    "def max_val_accuracy_by_linguistic_features(report_df):\n",
    "    grouped = report_df.groupby(['linguistic_trans'])\n",
    "    max_val_accuracy_by_linguistic = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        max_idx = group['val_accuracy'].argmax()\n",
    "        max_row = group.iloc[max_idx, :]\n",
    "        max_val_accuracy_by_linguistic.append(max_row)\n",
    "\n",
    "    df_max_val_accuracy_by_linguistic = pd.DataFrame(max_val_accuracy_by_linguistic)\n",
    "    return df_max_val_accuracy_by_linguistic.sort_values(by=['val_accuracy'], ascending=False)\n",
    "def max_val_accuracy_by_lexicon_features(report_df):\n",
    "    grouped = report_df.groupby(['lexicon_trans'])\n",
    "    max_val_accuracy_by_linguistic = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        max_idx = group['val_accuracy'].argmax()\n",
    "        max_row = group.iloc[max_idx, :]\n",
    "        max_val_accuracy_by_linguistic.append(max_row)\n",
    "\n",
    "    df_max_val_accuracy_by_lexicon = pd.DataFrame(max_val_accuracy_by_linguistic)\n",
    "    return df_max_val_accuracy_by_lexicon.sort_values(by=['val_accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aface259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram_trans</th>\n",
       "      <th>lexicon_trans</th>\n",
       "      <th>linguistic_trans</th>\n",
       "      <th>users_trans</th>\n",
       "      <th>train_report_partition_0</th>\n",
       "      <th>val_report_partition_0</th>\n",
       "      <th>train_report_partition_1</th>\n",
       "      <th>val_report_partition_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['trigram']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': {'precision': 0.896978021978022, 'recall...</td>\n",
       "      <td>{'0': {'precision': 0.704, 'recall': 0.8341232...</td>\n",
       "      <td>{'0': {'precision': 0.8615384615384616, 'recal...</td>\n",
       "      <td>{'0': {'precision': 0.5616438356164384, 'recal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ngram_trans lexicon_trans linguistic_trans users_trans  \\\n",
       "0  ['trigram']            []               []          []   \n",
       "\n",
       "                            train_report_partition_0  \\\n",
       "0  {'0': {'precision': 0.896978021978022, 'recall...   \n",
       "\n",
       "                              val_report_partition_0  \\\n",
       "0  {'0': {'precision': 0.704, 'recall': 0.8341232...   \n",
       "\n",
       "                            train_report_partition_1  \\\n",
       "0  {'0': {'precision': 0.8615384615384616, 'recal...   \n",
       "\n",
       "                              val_report_partition_1  \n",
       "0  {'0': {'precision': 0.5616438356164384, 'recal...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_report_df_ngram_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a40b732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_report_partition_0_accuracy\n",
      "val_report_partition_1_accuracy\n",
      "train_report_partition_0_accuracy\n",
      "train_report_partition_1_accuracy\n",
      "val_report_partition_0_accuracy\n",
      "val_report_partition_1_accuracy\n",
      "train_report_partition_0_accuracy\n",
      "train_report_partition_1_accuracy\n",
      "val_report_partition_0_accuracy\n",
      "val_report_partition_1_accuracy\n",
      "train_report_partition_0_accuracy\n",
      "train_report_partition_1_accuracy\n",
      "val_report_partition_0_accuracy\n",
      "val_report_partition_1_accuracy\n",
      "train_report_partition_0_accuracy\n",
      "train_report_partition_1_accuracy\n"
     ]
    }
   ],
   "source": [
    "for report_df in partition_all_report_df:\n",
    "    convert_report_to_dict(report_df)\n",
    "    add_accuracy(report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = partition_report_df_ngram_lexicon_linguistic_only.sort_values(by=['val_report_partition_1_accuracy'], ascending=False)\n",
    "report = rel_df[['val_report_partition_0_accuracy', 'val_report_partition_1_accuracy']]\n",
    "report.columns = ['religious validation accuracy', 'non religious validation accuracy']\n",
    "report['validation accuracy'] = (report.iloc[:, 0] * 93 + report.iloc[:, 1] * 306) / (399)\n",
    "print(report.sort_values(by=['validation accuracy'], ascending=False).to_latex())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c3ae3cb",
   "metadata": {},
   "source": [
    "nonrel_df = partition_report_df_ngram_lexicon_linguistic_only.sort_values(by=['val_report_partition_0_accuracy'], ascending=False)\n",
    "nonrel_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('env_nlp': conda)",
   "language": "python",
   "name": "python3613jvsc74a57bd0f78e94ca1a29e9011c2866c841de859bf08fcc5b57f07b9ffb161018ea406f8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
